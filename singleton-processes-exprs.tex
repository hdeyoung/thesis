\chapter{A computational interpretation of the semi-axiomatic\\singleton sequent calculus as session-typed communicating chains}\label{ch:process-chains}

In the previous \lcnamecref{ch:singleton-logic}, we took a purely proof-theoretic view of singleton logic and its semi-axiomatic sequent calculus.
The proof terms assigned to semi-axiomatic sequent proofs were simply syntactic objects,
% and the proof of the admissibility of non-analytic cuts\parencref{lem:singleton-logic:hilbert:cut-admissible} described a meta-level function for manipulating these syntactic objects.
and the proof of non-analytic cut elimination~\parencref{thm:singleton:hilbert:cutelim} described a meta-level function for normalizing these syntactic objects.

Even in a purely proof-theoretic setting, however, the computational suggestions of these syntactic manipulations were too strong to ignore:
% In proving the admissibility of non-analytic cuts\parencref{lem:singleton-logic:hilbert:cut-admissible},
We saw that the principal cases in the proof of admissibility of non-analytic cuts~\parencref{lem:singleton-logic:hilbert:cut-admissibility}%
\marginnote{%
  \vspace*{-\abovedisplayskip}
  \begin{align*}
    \nspawn{\selectR{\kay}}{\caseL[\ell \in L]{\ell => M_{\ell}}}
      &= M_{\kay}
    \\
    \nspawn{\caseR[\ell \in L]{\ell => N_{\ell}}}{\selectL{\kay}}
      &= N_{\kay}
  \end{align*}
% \end{marginfigure}
}
are reminiscent of asynchronous message-passing communication.
Following the rich tradition of Curry--Howard isomorphisms between logics and computational systems, this \lcnamecref{ch:process-chains} therefore pursues a concurrent computational interpretation of the semi-axiomatic sequent calculus for singleton logic.

In particular, we will see that singleton propositions can be interpreted as session types that describe patterns of interprocess communication~\parencref{sec:process-chains:typed-processes}; semi-axiomatic sequent proofs can be interpreted as chains of session-typed processes~\parencref{sec:process-chains:typed-chains}; and cut reduction can be interpreted as asynchronous message-passing communication~\parencref{sec:process-chains:reductions}.
% \footnote{As we will see in \cref{??}, Hilbert-style proofs may also be viewed as well-behaved chains of the communicating automata familiar from \cref{??}.}
For instance, a proof of $\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}$ corresponds to a process that sends a message carrying some label $\kay \in L$ and then continues communicating according to pattern $A_{\kay}$.

This roughly parallels a recent line of research into a Curry--Howard isomorphism, dubbed SILL, between the intuitionistic linear sequent calculus and session-typed concurrent computation\autocites{Caires+:MSCS16}{Caires+:TLDI12} -- with two key differences.
First, unlike SILL, we use singleton logic, not intuitionistic linear logic.
% However, as sketched in \cref{??}, 
Second and most importantly, we use the \emph{semi-axiomatic} sequent calculus, rather than a standard sequent calculus like SILL does.
% Third, and most importantly,
The use of semi-axiomatic sequent proofs enables a clean and direct interpretation of cut reductions as asynchronous communication, unlike the cut-reductions-as-synchronous-communication view espoused by SILL.%
\footnote{It is possible to give a rather ad hoc treatment of asynchronous communication using SILL's sequent proofs~\parencite{DeYoung+:CSL12}, but, in our view, the treatment of asynchronous communication using semi-axiomatic sequent proofs is far more elegant.}


% In particular, this parallels a recent line of research into a Curry--Howard isomorphism between the intuitionistic linear sequent calculus and session-typed concurrent computation\autocites{Caires+:MSCS16}{Caires+:TLDI12}.
% In that work, linear propositions are interpreted as session types that describe patterns of interprocess communication; sequent proofs, as session-typed processes; and cut reduction, as synchronous message-passing communication.
% For instance, a proof of $A \lolli B$ corresponds to a process that inputs a channel that communicates according to the pattern $A$, and then continues connumicating according to pattern $B$.


% We will see that 
% propositions can be interpreted as session types that specify patterns of communication; Hilbert-style proofs, as chains of session-typed processes; and cut reduction, as asynchronous message-passing communication.

% Alternatively, Hilbert-style proofs can be seen as well-behaved chains of communicating automata from \cref{??}.


\newthought{We begin}, in \cref{sec:process-chains:untyped-chains}, by introducing process chains in their untyped form as finite sequences of processes arranged in a linear topoloogy.
Then, in \cref{sec:process-chains:typed-processes}, we describe the structure of well-typed process expressions that may be used in these chains, and show that the session-typing rules for process expressions correspond to the rules of the semi-axiomatic sequent calculus;
\cref{sec:process-chains:typed-chains} presents session-typing rules for the process chains themselves.
In \cref{sec:process-chains:reductions}, we assign an operational semantics to process chains; this operational semantics arises naturally from the semi-axiomatic proof normalization procedure given in the previous \lcnamecref{ch:singleton-logic}.
Lastly, \cref{sec:process-chains:coinductive} describes coinductively defined type and process definitions.


\section{Process chains and process expressions}\label{sec:process-chains:interpretation}

\subsection{Untyped process chains}\label{sec:process-chains:untyped-chains}

We envision a process chain, $\chn$, as a (possibly empty) finite sequence of processes $(P_i)_{i=1}^{n}$, each with its own independent thread of control and arranged in a linear topology.
As depicted in the adjacent \lcnamecref{fig:singleton-processes:chain-topology},%
%
\begin{marginfigure}
  \centering
  \begin{tikzpicture}
    \graph [math nodes, nodes={circle, draw}] {
      P_0 / [coordinate]
       --
      P_1
       --
      / \dotsb [rectangle, text height=1ex, draw=none]
       --
      P_i
       --
      / \dotsb [rectangle, text height=1ex, draw=none]
       --
      P_n
       --
      / [coordinate];
    };
    \node [fit=(P_1) (P_i) (P_n), inner xsep=.5em,
           draw=gray,
           label distance=2em, label={[gray]$\chn$}] {};
  \end{tikzpicture}
  \caption{A prototypical process chain, $\chn$}\label{fig:singleton-processes:chain-topology}
\end{marginfigure}
%
% each process $P_i$ shares a unique channel with its left-hand neighbor and a unique channel with its right-hand neighbor.
each process $P_i$ shares unique channels with its left- and right-hand neighbors.
Along these channels, neighboring processes may interact and react, changing their own internal state.
Because process chains always maintain a linear topology, the channels need not be named -- they can instead be referred to as simply the left- and right-hand channels of $P_i$.

A chain $\chn$ does not compute in isolation, however.
The left-hand channel of $P_1$ and the right-hand channel of $P_n$ enable the chain to interact with its surroundings.
Because these two channels are the only ones exposed to the external environment, they may be referred to as the left- and right-hand channels of $\chn$.

Chains may even be composed end to end by conjoining the right-hand channel of one chain with the left-hand channel of another.

As finite sequences of processes $P_i$, chains form a free monoid:
\begin{equation*}
  \chn,\chn* \Coloneqq (\chn_1 \cc \chn_2) \mid (\chne) \mid P
  \,,
\end{equation*}
where $\cc$ denotes end-to-end composition of chains and $(\chne)$ denotes the empty chain.
As a monoid, chains are subject to associativity and unit laws (see adjacent \lcnamecref{fig:chains:monoid-laws}).
\begin{marginfigure}
\begin{gather*}
  (\chn_1 \cc \chn_2) \cc \chn_3 = \chn_1 \cc (\chn_2 \cc \chn_3) \\
  (\chne) \cc \chn = \chn = \chn \cc (\chne)
\end{gather*}
\caption{Monoid laws for process chains}\label{fig:chains:monoid-laws}
\end{marginfigure}
We do not distinguish chains that are equivalent up to these laws, instead treating such chains as syntactically identical.

The notation for a composition $\chn_1 \cc \chn_2$ is intended to recall parallel composition of $\pi$-calculus processes, $P_1 \mid P_2$.
However, unlike $\pi$-calculus composition, parallel composition of chains is \emph{not} commutative because the sequential order of processes within a chain matters.


\subsection{Session-typed process expressions}\label{sec:process-chains:typed-processes}

Thus far, we have examined the overall structure of (untyped) process chains without detailing the internal structure of individual processes.
% Thus far, we have diligently avoided describing the specific internals of processes.
We now turn to the specifics of well-typed processes.

As previously alluded, each of a chain's processes constitutes its own, independent thread of control dedicated to executing the instructions described by a process expression $P$.
Processes are thus dynamic realizations of the static process expressions, in the same way that executables run source code.\footnote{It is occasionally convenient to blur this distinction, so we sometimes abuse terminology and refer to a process expression $P$ as a \enquote{process}.}

% To follow a Curry--Howard isomorphism, we will adopt the propositions as session types; Hilbert-style proof terms as process expressions; and Hilbert system's inference rules as session-typing rules.

% To describe the patterns by which a process $P$ communicates with its left- and right-hand neighbors, % we will use a session-typing judgment
\newthought{Reinterpreting the proof-term judgment} of singleton logic's semi-axiomatic sequent calculus, we arrive at a session-typing judgment for process expressions.
The judgment
\begin{equation*}
  \slof{A |- P : B} % \,,
\end{equation*}
now means that $P$ is the expression for a process that
% that the process $P$
offers, along its right-hand channel, the service described by the session type $B$, while concurrently using, along its left-hand channel, the service described by the type $A$.
In other words, the right-hand neighbor acts as a client of service $B$ from $P$, while the left-hand neighbor of process $P$ acts as a provider of service $A$ to $P$.

Session types describe the patterns by which a process is permitted to communicate with its left- and right-hand neighbors.

Under this reinterpretation of the basic judgment, the proof rules of the singleton Hilbert system become session-typing rules for process expressions.
Specifically, the right rules define what it means for a provider to offer a particular service, while the left rules show how a client may use that service.


\begin{table}[tbp]
  \aboverulesep=1.25ex
  \belowrulesep=1.25ex
  \renewcommand{\arraystretch}{1.2}
  \centering
  \begin{tabular}{@{}lll@{}}
    \toprule
    % \quad & \emph{Process expressions} & \emph{Description}
    % \\ \midrule
    \rlap{\emph{Judgmental rules}} \\
      & $\spawn{P_1}{P_2}$
          & \renewcommand{\arraystretch}{0.95}%
            \begin{tabular}[t]{@{}l@{}}
              Spawn new, neighboring threads of control for $P_1$ and\\
              \quad $P_2$, then terminate the current thread of control
            \end{tabular} \\
      & $\fwd$ & Terminate the current thread of control
    \\ \midrule
    \rlap{\emph{Internal choice, $\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}$}} \\
      & $\selectR{\kay}$, with $\kay \in L$
          & A message to the right-hand client, carrying label $\kay$ \\
      & $\caseL[\ell \in L]{\ell => P_{\ell}}$
          & \renewcommand{\arraystretch}{0.95}%
            \begin{tabular}[t]{@{}l@{}}
              Await a message $\selectR{\kay}$ from the left-hand provider,\\
              \quad then continue as $P_{\kay}$
            \end{tabular}
    \\ \midrule
    \rlap{\emph{External choice, $\with*[sub=_{\ell \in L}]{\ell:A_{\ell}}$}} \\
      & $\caseR[\ell \in L]{\ell => P_{\ell}}$
          & \renewcommand{\arraystretch}{0.95}%
            \begin{tabular}[t]{@{}l@{}}
              Await a message $\selectL{\kay}$ from the right-hand client,\\
              \quad then continue as $P_{\kay}$
            \end{tabular} \\
      & $\selectL{\kay}$, with $\kay \in L$ & A message to the left-hand provider, carrying label $\kay$
    \\ \bottomrule    
  \end{tabular}
  \caption{Singleton session types}\label{tab:singleton-processes:types}%
\end{table}

% \begin{table*}[tbp]
%   \centering
%   \begin{tabular}{lll}
%     \toprule
%     \emph{Type} & \emph{Process expressions} & \emph{Description}
%     \\ \midrule
%     -- & $\spawn{P_1}{P_2}$ & Spawn new, neighboring threads of control for $P_1$ and $P_2$
%     \\
%     -- & $\fwd$ & Terminate the current thread of control
%     \\
%     $\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}$
%       & $\selectR{\kay}$ & message \\
%       & $\caseL[\ell \in L]{\ell => P_{\ell}}$ & Await a message $\selectR{\kay}$ from the left
%     \\
%     $\with*[sub=_{\ell \in L}]{\ell:A_{\ell}}$
%       & $\caseR[\ell \in L]{\ell => P_{\ell}}$ & Await a message $\selectL{\kay}$ from the right \\
%       & $\selectL{\kay}$ & message
%     \\ \bottomrule    
%   \end{tabular}
%   \caption{Singleton session types}\label{tab:singleton-processes:types}
% \end{table*}


% As an example, consider additive disjunction and its proof rules.
% From a computational perspective, additive disjunction is interpreted as \emph{internal choice}.
% The service ... is 
% The internal choice $\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}$ is the service in which the provider chooses which one of the services $(A_{\ell})_{\ell \in L}$ it will offer its client.

% type of a process that sends some label $\kay \in L$ to its right-hand client and then behaves like $A_{\kay}$.

As an example, consider additive disjunction and its proof rules.
% Consider the rules involving additive disjunction, for example.
From a computational perspective, an additive disjunction $\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}$ is interpreted as an internal choice, the type of a process that sends some label $\kay \in L$ to its right-hand client and then behaves like $A_{\kay}$.
Recall the $\rrule{\plus}'$ and $\lrule{\plus}$ rules:
% The $\rrule{\plus}'$ and $\lrule{\plus}$ proof rules become session-typing rules for process expressions.
\begin{inferences}
  \infer[\rrule{\plus}']{\slof{A_{\kay} |- \selectR{\kay} : \plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}}}{
    \text{($\kay \in L$)}}
  \and
  \infer[\lrule{\plus}]{\slof{\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}} |- \caseL[\ell \in L]{\ell => P_{\ell}} : C}}{
    \multipremise{\ell \in L}{\slof{A_{\ell} |- P_{\ell} : C}}}
\end{inferences}
The proof term $\selectR{\kay}$ is now reinterpreted as the expression for a message, sent to the right-hand client (as the arrow suggests), that carries the label $\kay$ as its payload.
The proof term $\caseL[\ell \in L]{\ell => P_{\ell}}$ is reinterpreted as the expression for a client process that awaits a message $\selectR{\kay}$ from its left-hand provider and then continues the thread of control with the corresponding branch, $P_{\kay}$.

% Dually, additive conjunction becomes a form of external choice.
% A provider of service $\with*[sub=_{\ell \in L}]{\ell:A_{\ell}}$ offers its client its choice of services $(A_{\ell})_{\ell \in L}$.
% \begin{inferences}
%   \infer[\rrule{\with}]{\slof{A |- \caseR[\ell \in L]{\ell => P_{\ell}} : \with*[sub=_{\ell \in L}]{\ell: C_{\ell}}}}{
%     \multipremise{\ell \in L}{\slof{A |- P_{\ell} : C_{\ell}}}}
%   \and
%   \infer[\lrule{\with}']{\slof{\with*[sub=_{\ell \in L}]{\ell:C_{\ell}} |- \selectL{\kay} : C_{\kay}}}{
%     \text{($\kay \in L$)}}
% \end{inferences}
% The client is a message $\selectL{\kay}$ that uses its payload [of label $k \in L$] to indicate the client's choice.
% The provider, $\caseR[\ell \in L]{\ell => P_{\ell}}$, is an input process that awaits a message indicating the client's choice and then continues along the chosen branch.

Additive conjunction, $\with*[sub=_{\ell \in L}]{\ell:A_{\ell}}$, is interpreted dually as external choice, the type of a process that awaits a label $\kay \in L$ from its client and then behaves like $A_{\kay}$.
\begin{inferences}
  \infer[\rrule{\with}]{\slof{A |- \caseR[\ell \in L]{\ell => P_{\ell}} : \with*[sub=_{\ell \in L}]{\ell: C_{\ell}}}}{
    \multipremise{\ell \in L}{\slof{A |- P_{\ell} : C_{\ell}}}}
  \and
  \infer[\lrule{\with}']{\slof{\with*[sub=_{\ell \in L}]{\ell:C_{\ell}} |- \selectL{\kay} : C_{\kay}}}{
    \text{($\kay \in L$)}}
\end{inferences}
As might be expected, the proof terms $\caseR[\ell \in L]{\ell => P_{\ell}}$ and $\selectL{\kay}$ are interpreted symmetrically to internal choice's $\selectR{\kay}$ and $\caseL[\ell \in L]{\ell => P_{\ell}}$ expressions: $\selectL{\kay}$ is a message to the left-hand provider, and $\caseR[\ell \in L]{\ell => P_{\ell}}$ is an input process that awaits a message from the right-hand client.

The proof term $\spawn{P_1}{P_2}$ for composition of proofs is now reinterpreted as the expression for a process that will spawn new, neighboring threads of control for $P_1$ and $P_2$ and then terminate the original thread of control.
In effect, $\spawn{P_1}{P_2}$ now composes process expressions.
\begin{equation*}
  \infer[\jrule{CUT}^B]{\slof{A |- \spawn{P_1}{P_2} : C}}{
    \slof{A |- P_1 : B} & \slof{B |- P_2 : C}}
\end{equation*}
For $\spawn{P_1}{P_2}$ to be a well-typed composition, $P_1$ must offer the same service that $P_2$ uses.

% Reflecting the intuition 
% \begin{equation*}
%   \infer{\spawn{P_1}{P_2} \reduces P_1 \cc P_2}{}
% \end{equation*}

Proof-theoretically, the identity and cut rules are inverses, so we should expect their process interpretations to be similarly inverse.
The process expression $\spawn{P_1}{P_2}$ spawns threads of control, so $\fwd$, as its inverse, terminates the thread of control.
\begin{equation*}
  \infer[\jrule{ID}^A]{\slof{A |- \fwd : A}}{}
\end{equation*}
% \begin{equation*}
%   \infer{\fwd \reduces \chne}{}
% \end{equation*}


% Additive conjunction, $\with*[sub=_{\ell \in L}]{\ell:A_{\ell}}$, is interpreted dually as external choice.
% \begin{inferences}
%   \infer[\rrule{\with}]{\slof{A |- \caseR[\ell \in L]{\ell => P_{\ell}} : \with*[sub=_{\ell \in L}]{\ell:C_{\ell}}}}{
%     \multipremise{\ell \in L}{\slof{A |- P_{\ell} : C_{\ell}}}}
%   \and
%   \infer[\lrule{\with}']{\slof{\with*[sub=_{\ell \in L}]{\ell:C_{\ell}} |- \selectL{\kay} : C_{\kay}}}{
%     \text{($\kay \in L$)}}
% \end{inferences}
% % \begin{equation*}
% %   \infer{\caseR[\ell \in L]{\ell => P_{\ell}} \cc \selectL{\kay} \reduces P_{\kay}}{
% %     \text{($\kay \in L$)}}
% % \end{equation*}



% Discussion of operational semantics here?

% Interpret additive disjunction as internal choice, and $\selectR{\kay}$ as a message, and $\caseL[\ell \in L]{\ell => P_{\ell}}$ as a process that waits for a message...

% Interpret additive conjunction dually...



% \begin{marginfigure}
%   \begin{tikzpicture}
%     \graph [math nodes, nodes={draw, circle}] {
%       / [coordinate]
%        --
%       k / {\,\smash[b]{\selectR{\kay}}\!}
%        --
%       P / {\caseL[\ell \in L]{\ell => P_{\ell}}} [rounded rectangle]
%        --
%       / [coordinate];
%     };
%   \end{tikzpicture}
% \end{marginfigure}

% Process expressions, $P$, and their session-typing rules are isomorphic to the Hilbert-style proof terms and inference rules of \cref{??}.
% [Propositions are reinterpreted as session types.]


% Additive disjunction, $\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}$, is interpreted as internal choice, the type of a process that sends a label.
% \begin{inferences}
%   \infer[\rrule{\plus}']{\slof{A_{\kay} |- \selectR{\kay} : \plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}}}{
%     \text{($\kay \in L$)}}
%   \and
%   \infer[\lrule{\plus}]{\slof{\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}} |- \caseL[\ell \in L]{\ell => P_{\ell}} : C}}{
%     \multipremise{\ell \in L}{\slof{A_{\ell} |- P_{\ell} : C}}}
% \end{inferences}
% The proof term $\selectR{\kay}$ is now viewed as a message, sent to the right-hand neighbor (as the arrow suggests), that carries the label $\kay$ as its payload.
% % \begin{equation*}
% %   \infer{\selectR{\kay} \cc \caseL[\ell \in L]{\ell => P_{\ell}} \reduces P_{\kay}}{
% %     \text{($\kay \in L$)}}
% % \end{equation*}
% % Clearly reminiscent of the principal cut reduction $\nspawn{\selectR{\kay}}{\caseL[\ell \in L]{\ell => N_{\ell}}} = N_{\kay}$.

\subsection{Session-typed process chains}\label{sec:process-chains:typed-chains}

With the session-typing system for process expressions in hand, session types can be assigned to process chains, too.
We use a session-typing judgment
\begin{equation*}
  \slcof{A |- \chn : B} \,,
\end{equation*}
%
\begin{marginfigure}[-4\baselineskip]
  \centering
  \begin{tikzpicture}
    \graph [math nodes, nodes={draw}] {
      / [coordinate]
       -- ["$A$"]
      P_1 / \phantom{P} [circle] 
       --
      / \dotsb [text height=1ex, text width=1.375em, draw=none]
       --
      P_n / \phantom{P} [circle]
       -- ["$B$"]
      / [coordinate];
    };

    \node [fit=(P_1) (P_n), draw=gray, label=$\chn$] {};
  \end{tikzpicture}
  % \caption{A well-typed process chain that offers service $B$ to its right-hand client, while using service $A$ from its left-hand provider}
  \caption{A well-typed process chain that uses service $A$ to offer service $B$}\label{fig:singleton-processes:well-typed-chain}
\end{marginfigure}%
%
meaning that the chain $\chn$ offers, along its right-hand channel, the service $B$, while concurrently using, along its left-hand channel, the service $A$.
Similar to individual processes, a chain $\chn$ thus enjoys client and provider relationships with its left- and right-hand environments, respectively.

The simplest session-typing rule for chains is the one that types a chain consisting of a single running process $P$:
\begin{equation*}
  \infer[\jrule{C-PROC}]{\slcof{A |- P : B}}{
    \slof{A |- P : B}}
\end{equation*}
%
\begin{marginfigure}[-3\baselineskip]
  \centering
  \begin{tikzpicture}
    \graph [math nodes, nodes={draw}] {
      / [coordinate]
       -- ["$A$"]
      P [circle]
       -- ["$B$"]
      / [coordinate];
    };
 
    \node [fit=(P), draw=gray] {};
  \end{tikzpicture}
  \caption{A chain made of one well-typed process that uses service $A$ to offer service $B$}\label{fig:singleton-processes:single-process-chain}
\end{marginfigure}%
%
In other words, a running process has the same type as its underlying process expression.


The session-typing rule for the empty chain, $(\chne)$, is also fairly direct.
The empty chain offers a service $A$ to its right-hand client by using the service of its left-hand provider:
\begin{equation*}
  \infer[\jrule{C-ID}\smash{^A}]{\slcof{A |- \chne : A}}{}
\end{equation*}
%
\begin{marginfigure}
  \centering
  \begin{tikzpicture}
    \graph [math nodes, nodes={draw}] {
      / [coordinate]
       -- ["$A$"]
      P_1 / \phantom{P} [circle, draw=none]
       -- ["$A$"]
      / [coordinate];

      (P_1.west) -- (P_1.east);
    };
 
    \node [fit=(P_1), draw=gray] {};
  \end{tikzpicture}
  \caption{A well-typed empty chain that uses service $A$ to offer service $A$}\label{fig:singleton-processes:empty-chain}
\end{marginfigure}%
%
Save for the contrasting $\slcof{|-}$ turnstile and the empty chain in place of a forwarding process expression, this mirrors the $\jrule{ID}\smash{^A}$, the identity rule for process expressions.
We will see shortly that this is not a coincidence.

Finally, a parallel composition of chains, $\chn_1 \cc \chn_2$, is well-typed only if $\chn_1$ offers the same service that $\chn_2$ uses, otherwise communication between $\chn_1$ and $\chn_2$ would be mismatched.
This condition is reflected in a cut principle for the session-typing judgment:
\begin{equation*}
  \infer[\jrule{C-CUT}\smash{^B}]{\slcof{A |- \chn_1 \cc \chn_2 : C}}{
    \slcof{A |- \chn_1 : B} & \slcof{B |- \chn_2 : C}}
\end{equation*}
%
\begin{marginfigure}[-4\baselineskip]
  \centering
  % \begin{tikzpicture}
  %   \graph [math nodes, nodes={draw}] {
  %     / [coordinate]
  %      -- ["$A$"]
  %     P_1 / [circle] 
  %      --
  %     / \dotsb [text height=1ex, text width=1.375em, draw=none]
  %      --
  %     P_n / [circle]
  %      -- ["$B$"]
  %     Q_1 / [circle] 
  %      --
  %     / \dotsb [text height=1ex, text width=1.375em, draw=none]
  %      --
  %     Q_n / [circle]
  %      -- ["$C$"]
  %     / [coordinate];
  %   };
  %
  %   \node [fit=(P_1) (P_n), draw, label=$\chn_1$] {};
  %   \node [fit=(Q_1) (Q_n), draw, label=$\chn_2$] {};
  % \end{tikzpicture}
  % \vspace{\baselineskip}
  %
  \begin{tikzpicture}
    \graph [math nodes, nodes={draw}] {
      / [coordinate]
       -- ["$A$"]
      C_1 / \chn_1
       -- ["$B$"]
      C_2 / \chn_2
       -- ["$C$"]
      / [coordinate];
    };

    \node [fit=(C_1) (C_2), draw, dashed, label=below:$\chn_1 \cc \chn_2$] {};
  \end{tikzpicture}
  \caption{A well-typed process chain that uses service $A$ to offer service $B$}\label{fig:singleton-processes:well-typed-cut}
\end{marginfigure}%
%
% The notation $\chn_1 \cc \chn_2$ is intended to recall parallel composition of processes, $P_1 \mid P_2$, in the $\pi$-calculus.
% However, unlike $\pi$-calculus composition, parallel composition of chains is \emph{not} commutative because the sequential order of processes within a chain matters.
%
Once again, there are strong similarities to a process expression -- $\spawn{P_1}{P_2}$ and its $\jrule{CUT}^B$ session-typing rule, in this case.
We can make these similarities explicit by defining a homomorphism, $\pf*{-}$, from chains to process expressions:
\begin{marginfigure}
  \begin{align*}
    \pf*{\chn_1 \cc \chn_2} &= \spawn{\pf{\chn_1}}{\pf{\chn_2}} \\
    \pf*{\chne} &= \fwd \\
    \pf{P} &= P
  \end{align*}
  \caption{A homomorphism from chains to process expressions}
\end{marginfigure}%
%
This homomorphism is type-preserving:
\begin{theorem}
  If $\slcof{A |- \chn : B}$, then $\slof{A |- \pf{\chn} : B}$.
\end{theorem}
\begin{proof}
  By structural induction on the session-typing derivation.
\end{proof}


% The empty chain, $\chne$, offers a service $A$ to its right-hand client by directly using the service of its left-hand provider.
% This is reflected in an identity principle:
% \begin{equation*}
%   \infer[\jrule{C-ID}\smash{^A}]{\slcof{A |- \chne : A}}{}
% \end{equation*}
% %
% \begin{marginfigure}
%   \centering
%   \begin{tikzpicture}
%     \graph [math nodes, nodes={draw}] {
%       / [coordinate]
%        -- ["$A$"]
%       P_1 / \phantom{P} [circle, draw=none]
%        -- ["$A$"]
%       / [coordinate];

%       (P_1.west) -- (P_1.east);
%     };
 
%     \node [fit=(P_1), draw=gray] {};
%   \end{tikzpicture}
%   \caption{A well-typed empty chain that uses service $A$ to offer service $A$}\label{fig:singleton-processes:empty-chain}
% \end{marginfigure}%
% %

% Lastly, a chain consisting of a single process, $P$, offers
% \begin{equation*}
%   \infer[\jrule{C-PROC}]{\slcof{A |- P : B}}{
%     \slof{A |- P : B}}
% \end{equation*}
% %
% \begin{marginfigure}
%   \centering
%   \begin{tikzpicture}
%     \graph [math nodes, nodes={draw}] {
%       / [coordinate]
%        -- ["$A$"]
%       P [circle]
%        -- ["$B$"]
%       / [coordinate];
%     };
 
%     \node [fit=(P), draw=gray] {};
%   \end{tikzpicture}
%   \caption{A chain made of one well-typed process that uses service $A$ to offer service $B$}\label{fig:singleton-processes:single-process-chain}
% \end{marginfigure}%


% This judgment is similar in structure to the singleton sequent $\slseq{A |- B}$, but the difference in turnstile


% \begin{marginfigure}
%   \centering
%   \begin{tikzpicture}
%     \graph [math nodes, nodes={draw}] {
%       / [coordinate]
%        -- ["$A$"]
%       C_1 / \chn_1
%        -- ["$B$" name=B]
%       C_2 / \chn_2
%        -- ["$C$"]
%       / [coordinate];
%     };

%     \node [fit=(C_1) (B) (C_2), draw, dashed,
%            label=$\chn_1 \cc \chn_2$]
%       {};
%   \end{tikzpicture}
%   \caption{A prototypical process chain, $\chn$}\label{fig:singleton-processes:chain-topology}
% \end{marginfigure}

At first, the distinction between offering and using a service may seem a bit odd, given that we placed so much emphasis on the symmetry of singleton sequents $\slseq{A |- B}$.
Singleton sequents are indeed symmetric, as \cref{thm:singleton-logic:symmetry} showed.
But imposing a provider--client, offer--use distinction is useful for placing our process chains and expressions within existing conceptual frameworks for session-typed concurrency.
In particular, the distinction helps to relate this process interpretation of singleton logic back to the SILL interpretation of linear logic\autocite{??}.

% but because we view them as (binary) hypothetical judgments, a judgmental asymmetry between the antecedent and consequent remains.
% It is this judgmental asymmetry that is reflected in the provider--client, offer--use asymmetry.


% If a chain $\chn_1$ offers a service $B$ along its right-hand channel and a chain $\chn_2$ uses the same service $B$ along its left-hand channel, then the two chains may be composed end to end as $\chn_1 \cc \chn_2$:
% \begin{equation*}
%   \infer[\jrule{C-CUT}\smash{^B}]{\slcof{A |- \chn_1 \cc \chn_2 : C}}{
%     \slcof{A |- \chn_1 : B} & \slcof{B |- \chn_2 : C}}
% \end{equation*}
% The notation $\chn_1 \cc \chn_2$ for chain composition is intended to suggest that $\chn_1$ and $\chn_2$ execute in parallel.

% If the left-hand surroundings offer service $A$
% \begin{equation*}
%   \infer[\jrule{C-ID}\smash{^A}]{\slcof{A |- \chne : A}}{}
% \end{equation*}


\begin{figure}[tbp]
  \begin{syntax*}
    Session types & A,B,C &
      \alpha \mid \plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}
             \mid \with*[sub=_{\ell \in L}]{\ell:A_{\ell}}
    \\
    Process chains & \chn,\chn* &
      (\chn_1 \cc \chn_2) \mid \chne \mid P
  \end{syntax*}
  \begin{gather*}
    (\chn_1 \cc \chn_2) \cc \chn_3 = \chn_1 \cc (\chn_2 \cc \chn_3) \\
    (\chne) \cc \chn = \chn = \chn \cc (\chne)
  \end{gather*}
  \begin{inferences}
    \infer[\jrule{C-CUT}\smash{^B}]{\slcof{A |- \chn_1 \cc \chn_2 : C}}{
      \slcof{A |- \chn_1 : B} & \slcof{B |- \chn_2 : C}}
    \and
    \infer[\jrule{C-ID}\smash{^A}]{\slof{A |- \chne : A}}{}
    \and
    \infer[\jrule{C-PROC}]{\slcof{A |- P : B}}{
      \slof{A |- P : B}}
  \end{inferences}

  \begin{syntax*}
    Process expressions & P,Q &
      \spawn{P_1}{P_2} \mid \fwd
      \begin{array}[t]{@{{} \mid {}}l@{}}
        \selectR{\kay} \mid \caseL[\ell \in L]{\ell => P_{\ell}} \\
        \caseR[\ell \in L]{\ell => P_{\ell}} \mid \selectL{\kay}
      \end{array}
  \end{syntax*}
  \begin{inferences}
    \infer[\jrule{CUT}\smash{^B}]{\slof{A |- \spawn{P_1}{P_2} : C}}{
      \slof{A |- P_1 : B} & \slof{B |- P_2 : C}}
    \and
    \infer[\jrule{ID}\smash{^A}]{\slof{A |- \fwd : A}}{}
    \\
    \infer[\rrule{\plus}']{\slof{A_{\kay} |- \selectR{\kay} : \plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}}}{
      \text{($\kay \in L$)}}
    \and
    \infer[\lrule{\plus}]{\slof{\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}} |- \caseL[\ell \in L]{\ell => P_{\ell}} : C}}{
      \multipremise{\ell \in L}{\slof{A_{\ell} |- P_{\ell} : C}}}
    \\
    \infer[\rrule{\with}]{\slof{A |- \caseR[\ell \in L]{\ell => P_{\ell}} : \with*[sub=_{\ell \in L}]{\ell:C_{\ell}}}}{
      \multipremise{\ell \in L}{\slof{A |- P_{\ell} : C_{\ell}}}}
    \and
    \infer[\lrule{\with}']{\slof{\with*[sub=_{\ell \in L}]{\ell:C_{\ell}} |- \selectL{\kay} : C_{\kay}}}{
      \text{($\kay \in L$)}}
  \end{inferences}
  \caption{Well-typed process expressions and process chains}
  \label{fig:process-chains:session-typed-summary}
\end{figure}

\clearpage
\subsection{From admissibility of non-analytic cuts to an operational semantics}\label{sec:process-chains:reductions}

In the previous \lcnamecref{ch:singleton-logic}, we presented a procedure for normalizing semi-axio\-matic sequent proofs in singleton logic.
Proof normalization was important to establish

In this \lcnamecref{ch:process-chains}, however, our perspective has shifted from proof theory to concurrent computation, from proofs to processes.
And so normalization is no longer appropriate -- we now want to expose the concurrent computational behavior, not just normal forms.
The situation is analogous to that of intuitionistic natural deduction and simply-typed functional computation: there, proof normalization occurs in the premise of the implication introduction rule but the usual operational semantics for functional computation does not reduce under function abstractions.

In fact, the difference is even starker here because, once recursive process definitions are introduced~\parencref{sec:process-chains:coinductive}, many useful processes will be nonterminating.
Thus, there is no clear notion of value, as exists in functional computation.
Nevertheless, in good Curry--Howard fashion, the principal cases of semi-axiomatic proof normalization will still directly inform the operational semantics of processes.

\newthought{In the previous \lcnamecref{sec:process-chains:typed-processes},} the description of how proof terms are reinterpreted as process expressions already hinted at a computational strategy.
Here we present that operational semantics in its full detail.

The operational semantics for process chains is centered around \emph{reduction}, a binary relation on chains which we write as $\reduces$;
we will use $\Reduces$ for the reflexive, transitive closure of reduction.
Reductions may occur among any of the chain's processes, and thus the relation is compatible with the monoid operation, $\cc$:
\begin{inferences}
  \infer{\chn_1 \cc \chn_2 \reduces \chn'_1 \cc \chn_2}{
    \chn_1 \reduces \chn'_1}
  \and
  \infer{\chn_1 \cc \chn_2 \reduces \chn_1 \cc \chn'_2}{
    \chn_2 \reduces \chn'_2}
\end{inferences}

At the heart of reduction are two symmetric rules that describe how messages are received:
\begin{inferences}
  \infer{\selectR{\kay} \cc \caseL[\ell \in L]{\ell => P_{\ell}} \reduces P_{\kay}}{
    \text{($\kay \in L$)}}
  \and
  \infer{\caseR[\ell \in L]{\ell => P_{\ell}} \cc \selectL{\kay} \reduces P_{\kay}}{
    \text{($\kay \in L$)}}
\end{inferences}
%
\begin{marginfigure}
  \centering
  \begin{gather*}
    \begin{tikzpicture}
      \graph [math nodes, nodes={draw, circle}] {
        / [coordinate]
         --
        k / \selectR{\kay}
         --
        P / {\caseL[\ell  \in L]{\ell => P_{\ell}}} [rounded rectangle, inner ysep=.5em]
         --
        / [coordinate];
      };
    \end{tikzpicture}
    \\\reduces\\
    \begin{tikzpicture}
      \graph [math nodes, nodes={draw, circle, inner sep=.2em}] {
        / [coordinate]
         --
        P_{\kay}
         --
        / [coordinate];
      };
    \end{tikzpicture}
  \end{gather*}
  \\\text{\emph{and}}\\
  \begin{gather*}
    \begin{tikzpicture}
      \graph [math nodes, nodes={draw, circle}] {
        / [coordinate]
         --
        P / {\caseR[\ell  \in L]{\ell => P_{\ell}}} [rounded rectangle, inner ysep=.5em]
         --
        k / \selectL{\kay}
         --
        / [coordinate];
      };
    \end{tikzpicture}
    \\\reduces\\
    \begin{tikzpicture}
      \graph [math nodes, nodes={draw, circle, inner sep=.2em}] {
        / [coordinate]
         --
        P_{\kay}
         --
        / [coordinate];
      };
    \end{tikzpicture}
  \end{gather*}

  \caption{Pictorial representations of the principal reductions}
\end{marginfigure}%
As suggested earlier, when a process $\caseL[\ell \in L]{\ell => P_{\ell}}$ receives a message from its left-hand provider, it continues the thread of control with the indicated branch, $P_{\kay}$; the rule involving $\caseR[\ell \in L]{\ell => P_{\ell}}$ is symmetric.
These two reduction rules mimic the principal proof normalization steps for singleton logic's semi-axiomatic sequent proofs: $\nspawn{\selectR{\kay}}{\caseL[\ell \in L]{\ell => M_{\ell}}} = M_{\kay}$ and $\nspawn{\caseR[\ell \in L]{\ell => N_{\ell}}}{\selectL{\kay}} = N_{\kay}$.

As suggested earlier, a process $\spawn{P_1}{P_2}$ spawns, in place, new neighboring threads of control for $P_1$ and $P_2$, respectively, while the original thread of control terminates; and a process $\fwd$ terminates its thread of control.
The operational semantics formalizes these notions in rules that decompose $\spawn{P_1}{P_2}$ and $\fwd$:
\begin{inferences}
  \infer{\spawn{P_1}{P_2} \reduces P_1 \cc P_2}{}
  \and
  \infer{\fwd \reduces (\chne)}{}
\end{inferences}
%
\begin{marginfigure}
  \begin{gather*}
    \begin{tikzpicture}
      \graph [math nodes, nodes={draw, circle}] {
        / [coordinate]
         --
        P / \spawn{P_1}{P_2} [rounded rectangle, inner ysep=.5em]
         --
        / [coordinate];
      };
    \end{tikzpicture}
    \\\reduces\\
    \begin{tikzpicture}
      \graph [math nodes, nodes={draw, circle, inner sep=.2em}] {
        / [coordinate]
         --
        P_1
         --
        P_2
         --
        / [coordinate];
      };
    \end{tikzpicture}
  \\\text{\emph{and}}\\
    \begin{tikzpicture}
      \graph [math nodes, nodes={draw, circle, inner sep=.2em}] {
        / [coordinate]
         --
        P / \fwd
         --
        / [coordinate];
      };
    \end{tikzpicture}
    \\\reduces\\
    \begin{tikzpicture}
      \graph [math nodes, nodes={draw, circle, inner sep=.2em}] {
        / [coordinate]
         --
        P / \phantom{\fwd} [draw=none]
         --
        / [coordinate];
        (P.west) -- (P.east);
      };
    \end{tikzpicture}
  \end{gather*}
  \caption{Pictorial representations of the reductions for $\spawn{P_1}{P_2}$ and $\fwd$}
\end{marginfigure}%
Because process chains are always considered up to associativity and unit laws, these reduction rules (along with the above $\cc$-compatibility rules) reflect the associative and identity normalization steps in the proof of admissibility of non-analytic cuts\parencref{lem:singleton-logic:hilbert:cut-admissibility}.
For example, just as
\begin{gather*}
  \nspawn{(\spawn{N_0}{\selectR{\kay}})}{M} = \nspawn{N_0}{(\nspawn{\selectR{\kay}}{M})} \\
%
\intertext{is an associative normalization step,}
%
  (\spawn{P_0}{\selectR{\kay}}) \cc P_1
    \reduces % (P_0 \cc \selectR{\kay}) \cc P_1
    = P_0 \cc (\selectR{\kay} \cc P_1)
\end{gather*}
is a reduction.
Similarly, $\fwd \cc P \reduces= P$ is a reduction that reflects the normalization step $\nspawn{\fwd}{M} = M$.

% For example:
% \begin{align*}
%   (\spawn{P_0}{\selectR{\kay}}) \cc P_1 \reduces= P_0 \cc (\selectR{\kay} \cc P_1)
%   &\quad\text{just as}\quad
%   \nspawn{(\spawn{N_0}{\selectR{\kay}})}{M} = \nspawn{N_0}{(\nspawn{\selectR{\kay}}{M})}
% \shortintertext{and}
%   \fwd \cc P \reduces= % \chne \cc P
%     P
%   &\quad\text{just as}\quad
%   \nspawn{\fwd}{M} = M
%     \,.
% \end{align*}


These rules witness the close connection between proof normalization and the operational semantics of processes%
% and non-analytic cut elimination
, but one class of normalization steps does not have a direct analogue in the operational semantics: the class of commutative normalization steps.
As a prototypical example, recall the step involving $\caseL{}$:
\begin{equation*}
  \nspawn{\caseL[\ell \in L]{\ell => N_{\ell}}}{M} = \caseL[\ell \in L]{\ell => \nspawn{N_{\ell}}{M}}
  \,.
\end{equation*}
As part of proof normalization, this step is quite natural because it progresses toward a normal form by pushing the admissible cut, represented by the $\nspawn{}{}$ constructor, further in and pulling the $\caseL[\ell \in L]{\ell => {-}}$ construction out.
In the operational semantics, however, it would be wrong to have the corresponding
\begin{equation*}
  \caseL[\ell \in L]{\ell => P_{\ell}} \cc \chn \reduces \caseL[\ell \in L]{\ell => P_{\ell} \cc \chn}
\end{equation*}
as a reduction -- it inappropriately mixes dynamic and static objects by bringing the chain $\chn$ within the process expression $\caseL[\ell \in L]{\ell => {-}}$.

% Recall 
% \begin{gather*}
%   \begin{aligned}
%     \nspawn{(\spawn{N_0}{\selectR{\kay}})}{M}
%       &= \nspawn{N_0}{(\nspawn{\selectR{\kay}}{M})}
%     \\
%     \nspawn{N}{(\spawn{\selectL{\kay}}{M_0})}
%       &= \nspawn{(\nspawn{N}{\selectL{\kay}})}{M_0}
%   \end{aligned}
%   \\[2\jot]
%   \begin{aligned}
%     \nspawn{\fwd}{M}
%       &= M
%     \\
%     \nspawn{N}{\fwd}
%       &= N
%   \end{aligned}
%   \\[2\jot]
%   \begin{aligned}
%     \nspawn{\selectR{\kay}}{\caseL[\ell \in L]{\ell => M_{\ell}}}
%       &= M_{\kay}
%     \\
%     \nspawn{\caseR[\ell \in L]{\ell => N_{\ell}}}{\selectL{\kay}}
%       &= N_{\kay}
%   \end{aligned}
%   \\[2\jot]
%   \begin{aligned}
%     \nspawn{(\spawn{\selectL{\kay}}{N_0})}{M}
%       &= \spawn{\selectL{\kay}}{(\nspawn{N_0}{M})}
%     \\
%     \nspawn{N}{(\spawn{M_0}{\selectR{\kay}})}
%       &= \spawn{(\nspawn{N}{M_0})}{\selectR{\kay}}
%     \\
%     \nspawn{\selectL{\kay}}{M}
%       &= \spawn{\selectL{\kay}}{M}
%     \\
%     \nspawn{N}{\selectR{\kay}}
%       &= \spawn{N}{\selectR{\kay}}
%     \\
%     \nspawn{\caseL[\ell \in L]{\ell => N_{\ell}}}{M}
%       &= \caseL[\ell \in L]{\ell => \nspawn{N_{\ell}}{M}}
%     \\
%     \nspawn{N}{\caseR[\ell \in L]{\ell => M_{\ell}}}
%       &= \caseR[\ell \in L]{\ell => \nspawn{N}{M_{\ell}}}
%   \end{aligned}
% \end{gather*}
% etc.

The session-typing rules and operational semantics enjoy preservation and progress theorems.

\begin{theorem}[Preservation]
  If $\slcof{A |- \chn : B}$ and $\chn \reduces \chn'$, then $\slcof{A |- \chn' : B}$.
\end{theorem}
\begin{proof}
  By structural induction on the given reduction, $\chn \reduces \chn'$.
\end{proof}

\begin{theorem}[Progress]
  If $\slcof{A |- \chn : B}$, then either:
  \begin{itemize}[nosep]
  \item chain $\chn$ can reduce, that is, $\chn \reduces \chn'$;
  \item chain $\chn$ is waiting to interact with its right-hand client, that is, $\chn = \chn' \cc \selectR{\kay}$ or $\chn = \chn' \cc \caseR[\ell \in L]{\ell => P_{\ell}}$;
  \item chain $\chn$ is waiting to interact with its left-hand provider, that is, $\chn = \selectL{\kay} \cc \chn'$ or $\chn = \caseL[\ell \in L]{\ell => P_{\ell}} \cc \chn'$; or
  \item chain $\chn$ is empty, that is, $\chn = (\chne)$.
  \end{itemize}
\end{theorem}
\begin{proof}
  By structural induction on the typing derivation, $\slcof{A |- \chn : B}$.
\end{proof}

\clearpage
\section{Coinductively defined types and process expressions}\label{sec:process-chains:coinductive}

Unfortunately, there are many relatively simple computational behaviors that cannot be described by the finitary session types thus far.
For instance, a transducer process that receives, one-by-one, a stream of input symbols and forms an output stream by replacing each $b$ with an $a$ cannot be represented.

The solution is to introduce coinductively defined types, in a manner reminiscent of the coinductively defined propositions, $\n{\defp{p}} \defd \n{A}$, seen in \cref{sec:formula-as-process:coinductive}.
We will often write coinductively defined types with Greek letters, such as $\alpha \defd A$.
Coinductively defined types are not particularly useful if process expressions remain finitary, so we also introduce mutually coinductively defined process expressions: $\slof{A |- \defp{p} : C} \defd P$.

That these definitions are coinductive is guaranteed by requiring that along every cycle among defined types and processes there is a type constructor or process expression constructor.\footnote{This generalizes the local contractivity condition described by \textcite{Gay+Hole:AI05}.}
This justifies an \emph{equi}\-recursive treatment of types in which type definitions may be silently unfolded (or re-folded) at will.

As with coinductively defined propositions, these type and process expression definitions are coinductive in only a syntactic sense.
In particular, the coinductively defined process expressions are not necessarily behaviorally coinductive, \ie, productive.
For example, $\defp{p} \defd \caseL{a => \spawn{\selectR{a}}{p}}$ is not a productive process -- after receiving an initial message $\selectR{a}$, $p$ diverges without sending or receiving any further messages.

Once coinductively defined types and process expressions are added, there is, strictly speaking, no longer a Curry--Howard isomorphism between session-typed process chains and the semi-axiomatic proofs of singleton logic.
% Extending the session-type system for process chains with recursive type and process definitions means that, strictly speaking, there is no longer a Curry--Howard isomorphism with singleton logic's Hilbert system.
Importantly, however, the core system remains unchanged and still enjoys the isomorphism because the unbounded behavior is added modularly.
The situation is once again analogous to the Curry--Howard isomorphism between intuitionistic natural deduction and the simply-typed $\lambda$-calculus:
When the $\lambda$-calculus is extended with recursive types and functions, the meaning of the type constuctor for simple function types remains unchanged and still isomorphic with intuitionistic implication.

Just as a Curry--Howard isomorphism can be recovered in the $\lambda$-calculus when general recursive types are restricted to inductive and coinductive types, work by \textcite{Derakhshan+Pfenning:LMCS20} and \textcite{Somayyajula+Pfenning:20} shows that a Curry--Howard isomorphism between session-typed process chains and (sub-)singleton sequent calculus proofs can be recovered if types are inductive or behaviorally coinductive.


\section{Examples}

\subsection{Binary counter}\label{sec:process-chains:binary-counter}

We can once again revisit binary counters, this time as an example of session-typed process chains.

\paragraph*{Session types}

A natural number in binary will be represented by a process chain of type $\slcof{\ctre |- \ctr}$, where $\ctr$ is a session type that 
describes the service that a counter offers
% offers the client a choice between incrementing and decrementing the counter
and $\ctre$ is a type parameter that represents a terminated counter.

The type $\ctr$ of counters is given by
\begin{equation*}
  \ctr \defd \with*{ i: \ctr , d: \plus*{ z: \ctre , s: \ctr } }
  \,
\end{equation*}
and describes a service that offers the client a choice between incrementing ($i$ branch) and decrementing ($d$ branch) the counter:
\begin{itemize}
\item
  If the client chooses to increment the counter, then the incremented counter again offers the same service, $\ctr$, to the client.
\item
  Otherwise, if the client chooses to decrement the counter, then the provider replies with either $\selectR{z}$ or $\selectR{s}$ depending on the counter's value.
  \begin{itemize}
  \item
    If the counter's value is $0$, it cannot be decremented further and so it emits $\selectR{z}$ and then terminates at type $\ctre$.
  \item
    If the counter's value is some strictly positive natural number $n$, then the provider signals that by emitting $\selectR{s}$ and then continues as a counter of value $n-1$ that offers service $\ctr$.
  \end{itemize}
\end{itemize}
As a shorthand, we can introduce a type $\ctrd$ of decrement responses:
\begin{equation*}
  \begin{lgathered}
    \ctr \defd \with*{ i: \ctr , d: \ctrd } \\
    \ctrd \defd \plus*{ z: \ctre , s: \ctr }
    \,.
  \end{lgathered}
\end{equation*}

\paragraph*{Process expressions}

A counter will be a big-endian chain of processes $\defp{b}_0$ and $\defp{b}_1$, prefixed by a process $\defp{e}$.
For example, the chain $\defp{e} \cc \defp{b}_1 \cc \defp{b}_0$ would represent a counter of value $2$.
For these chains to have type $\slcof{\ctre |- \ctr}$, the process expressions $\defp{b}_0$ and $\defp{b}_1$ must have type $\slof{\ctr |- \ctr}$, while $\defp{e}$ must have type $\slof{\ctre |- \ctr}$.
%
In addition, to implement decrements involving $\defp{b}_0$, it is also convenient to have a coinductively defined process expression $\defp{b}'_0$ of type $\slof{\ctrd |- \ctrd}$.

These process expressions are defined by 
\begin{equation*}
  \begin{lgathered}
    \slof{ \ctre |- \defp{e} : \ctr } \defd
      \caseR{ i => \spawn{\defp{e}}{\defp{b}_1}
            | d => \selectR{z} }
    \\
    \slof{ \ctr |- \defp{b}_0 : \ctr } \defd
      \caseR{ i => \defp{b}_1
            | d => \spawn{\selectL{d}}{\defp{b}'_0} }
    \\
    \slof{ \ctr |- \defp{b}_1 : \ctr } \defd
      \caseR{ i => \spawn{\selectL{i}}{\defp{b}_0}
            | d => \spawn{\defp{b}_0}{\selectR{s}} }
    \\
    \slof{ \ctrd |- \defp{b}'_0 : \ctrd } \defd
      \caseL{ z => \selectR{z}
            | s => \spawn{\defp{b}_1}{\selectR{s}} }
  \end{lgathered}
\end{equation*}
For instance, a $\defp{b}_1$ process that receives the $\selectL{i}$ increment message will spawn, in place, neighboring threads of control for $\selectL{i}$ and $\defp{b}_0$ and then terminate the original thread of control.
In effect, this sends the $\selectL{i}$ increment message to the more significant bits as a carry and flips this bit to $\defp{b}_1$.

As a second example, a $\defp{b}_0$ process that receives the $\selectL{d}$ decrement message should decrement the counter formed by the more significant bits and then analyze the response with a $\defp{b}'_0$ process.
% We need to introduce one more coinductively defined process expression, $\defp{b}'_0$, that serves to analyze the response and then produce its own response; $\defp{b}'_0$ therefore must have type $\slof{\ctrd |- \ctrd}$.
% \begin{equation*}
%   \slof{ \ctrd |- \defp{b}'_0 : \ctrd } \defd
%     \caseL{ z => \selectR{z}
%           | s => \spawn{\defp{b}_1}{\selectR{s}} }
% \end{equation*}
\begin{itemize}
\item If that $\defp{b}'_0$ process receives a response of $\selectR{z}$, then the more significant bits had value $0$ and so must the counter as a whole.
  According to the type $\ctrd$, the current thread of control must produce a response of type $\slof{\ctre |- \ctrd}$, which is easily done by sending $\selectR{z}$.
\item Otherwise, if the $\defp{b}'_0$ process receives a response of $\selectR{s}$, then the more significant bits had value $n+1$, for some $n \geq 0$, and the counter as a whole must have value $2n+1$ after the decrement.
  This is accomplished by emitting $\selectR{s}$ and replacing $\defp{b}'_0$ with a recursive call to $\defp{b}_1$.
\end{itemize}

As an example of these processes in action, observe that $\defp{e} \cc \defp{b}_1 \cc \selectL{i} \cc \selectL{d}$ has the following trace, among others.
\begin{align*}
  \MoveEqLeft[.5]
  \defp{e} \cc \defp{b}_1 \cc \selectL{i} \cc \selectL{d} \\
    &\reduces \defp{e} \cc (\spawn{\selectL{i}}{\defp{b}_0}) \cc \selectL{d}
     \reduces \defp{e} \cc \selectL{i} \cc \defp{b}_0 \cc \selectL{d} \\
    &\reduces \defp{e} \cc \selectL{i} \cc (\spawn{\selectL{d}}{\defp{b}'_0})
     \reduces \defp{e} \cc \selectL{i} \cc \selectL{d} \cc \defp{b}'_0 \\
    &\reduces (\spawn{\defp{e}}{\defp{b}_1}) \cc \selectL{d} \cc \defp{b}'_0
     \reduces \defp{e} \cc \defp{b}_1 \cc \selectL{d} \cc \defp{b}'_0 \\
    &\reduces \defp{e} \cc (\spawn{\defp{b}_0}{\selectR{s}}) \cc \defp{b}'_0
     \reduces \defp{e} \cc \defp{b}_0 \cc \selectR{s} \cc \defp{b}'_0 \\
    &\reduces \defp{e} \cc \defp{b}_0 \cc (\spawn{\defp{b}_1}{\selectR{s}})
     \reduces \defp{e} \cc \defp{b}_0 \cc \defp{b}_1 \cc \selectR{s}
\end{align*}



\begin{equation*}
  \begin{lgathered}
    \defp{\imath} \defd \caseL{e => \spawn{\selectR{e}}{\selectR{b}_1}
                             | b_0 => \selectR{b}_1
                             | b_1 => \spawn{\defp{\imath}}{\selectR{b}_0}}
    \\
    \defp{d} \defd \caseL{e => \selectR{z}
                        | b_0 => \spawn{\defp{d}}{\defp{b}'_0}
                        | b_1 => \spawn{\selectR{b}_0}{\selectR{s}}}
    \\
    \defp{b}'_0 \defd \caseL{z => \selectR{z}
                           | s => \spawn{\defp{d}}{\defp{b}'_0}}
  \end{lgathered}
\end{equation*}



\subsection{Sequential transducers}\label{sec:process-chains:transducer}

By this point in this document, the reader will likely expect either \acp{DFA} or \acp{NFA} as our next example of session-typed process chains.
Instead, we will use sequential transducers, as introduced in \cref{ch:finite-automata}.

\paragraph*{Session types}

We should first construct a type that describes the words over an alphabet $\ialph$, respectively.
However, because the language formulated in this \lcnamecref{ch:process-chains} does not have inductive types, we cannot describe the finite words $\finwds{\ialph}$ alone.
With the inductive session types studied by \textcite{Derakhshan+Pfenning:LMCS20} and \textcite{Somayyajula+Pfenning:20}, that would be possible, but we do not pursue that extension here.

Instead, we will construct a type that describes the \emph{infinite} words over alphabet $\ialph$:
\begin{equation*}
  % \begin{lgathered}
    \infinwds{\ialph} \defd \plus*[sub=_{a \in \ialph}]{ a: \infinwds{\ialph} } % \\
    % \infinwds{\oalph} \defd \plus*[sub=_{b \in \oalph}]{ b: \infinwds{\oalph} }
  \,.
  % \end{lgathered}
\end{equation*}
A process that offers type $\infinwds{\ialph}$ is one that emits a sequence of messages that correspond to an infinite word over $\ialph$.
For instance, when given by the following definition, $\slof{\epsilon |- \defp{w} : \infinwds{\ialph}}$ is a process that corresponds to the infinite word $w = abbabb\dotsm$:
\begin{equation*}
  \slof{\epsilon |- \defp{w} : \infinwds{\ialph}} \defd
    \spawn{\defp{w}}{(\spawn{\spawn{\selectR{b}}{\selectR{b}}}{\selectR{a}})}
  \,.
\end{equation*}
Notice that the type parameter $\epsilon$ is never used directly and could be replaced with any type $A$.

Using this type, we can now implement \emph{infinite}-word sequential transducers with well-typed process expressions.



% Nevertheless, we can use the following types to describe \emph{all} words, finite or infinite, over $\ialph$ and $\oalph$, respectively:
% \begin{equation*}
%   \begin{lgathered}
%     \str \defd \plus*[sub=_{a \in \ialph}]{ a: \str , \eow: \stre } \\
%     \str[\oalph] \defd \plus*[sub=_{b \in \oalph}]{ b: \str[\oalph] , \eow: \stre }
%   \,.
%   \end{lgathered}
% \end{equation*}
% A process of type $\slof{\stre |- \str[\ialph]}$ is then one that emits a sequence of messages that corresponds to a word over $\ialph$.

\paragraph*{Process expressions}

Let $\aut{T} = (Q, \sftnext, \sftout)$ be an infinite-word sequential transducer over the input and output alphabets $\ialph$ and $\oalph$, respectively.
Each state $q \in Q$ maps words from $\infinwds{\ialph}$ to $\infinwds{\oalph}$, and therefore ought to correspond to a process expression $\defp{q}$ of type $\slof{\infinwds{\ialph} |- \infinwds{\oalph}}$:
\begin{equation*}
  \slof{\infinwds{\ialph} |- \defp{q} : \infinwds{\oalph}} \defd
    \caseL[a \in \ialph]{ a => \spawn{\defp{q}'}{\rev{\selectR{w}}} }  \text{\enspace where $\sftnext(q, a) = q'$ and $\sftout(q, a) = w$.}
\end{equation*}
(The anti-homomorphism $\rev{\selectR{w}}$ is defined in the adjacent \lcnamecref{fig:process-chains:transducer-rev}.
It is notationally identical to, but formally distinct from, the anti-homomorphism from words to contexts of right-directed atoms~(\cref{fig:??}).
However, as we will see in \cref{ch:correspond}, the two anti-homomorphisms are conceptually related.)%
\begin{marginfigure}[-5\baselineskip]
  \begin{equation*}
    \rev{\selectR{w}} =
    \begin{cases*}
      \fwd & if $w = \emp$ \\
      \spawn{\rev{\selectR{w}_0}}{\selectR{a}} & if $w = a \wc w_0$
    \end{cases*}
  \end{equation*}
  \caption{An anti-homomorphism from $\finwds{\oalph}$ to processes of type $\slof{\infinwds{\oalph} |- \infinwds{\oalph}}$}\label{fig:process-chains:transducer-rev}
\end{marginfigure}

For a concrete example, recall from \cref{ch:finite-automata} the infinite-word sequential transducer over $\ialph = \oalph = \Set{ a , b }$ (repeated in the adjacent \lcnamecref{fig:process-chains:sft-example}) that compresses each run of $b$s within the input word into a single $b$.%
\begin{marginfigure}[-1\baselineskip]
  \begin{equation*}
    \mathllap{\aut{T} = {}}
    \begin{tikzpicture}[baseline=(q_0.base)]
      \graph [automaton] {
        q_0
         -> [loop above, "$\tio{a | a}$"]
        q_0
         -> [bend left, "$\tio{b | b}$"]
        q_1 [right=-0.5em of q_0]
         -> [loop above, "$\tio{b | \emp}$"]
        q_1
         -> [bend left, "$\tio{a | a}$"]
        q_0 ;
        % e_0 [coordinate, below=-1.75em of q_0.south];
        % e_1 [coordinate, below=-5.25em of q_1.south];
        % (q_0.south) -> ["$\emp$", swap] e_0 ;
        % (q_1.south) -> ["$\vphantom{\emp}\smash{b}$"] e_1 ;
      };
    \end{tikzpicture}
  \end{equation*}
  \caption{An infinite-word sequential transducer that compresses runs of consecutive $b$s.  (Repeated from \cref{fig:finite-automata:sft-example}.)}\label{fig:process-chains:sft-example}
\end{marginfigure}
Because $\ialph = \oalph = \Set{ a , b }$, the types for input and output words are defined as:
\begin{equation*}
  \begin{lgathered}
    \infinwds{\ialph} \defd
      \plus*{ a: \infinwds{\ialph} , b: \infinwds{\ialph} }
    \\
    \infinwds{\oalph} \defd
      \plus*{ a: \infinwds{\oalph} , b: \infinwds{\oalph} }
    \,.
  \end{lgathered}
\end{equation*}
Following the encoding laid out above, the states $q_0$ and $q_1$ become process expressions $\defp{q}_0$ and $\defp{q}_1$ of type $\slof{ \infinwds{\ialph} |- \infinwds{\oalph} }$ defined by:
\begin{equation*}
  \begin{lgathered}
    \slof{ \infinwds{\ialph} |- \defp{q}_0 : \infinwds{\oalph} } \defd
      \caseL{ a => \spawn{\defp{q}_0}{\selectR{a}}
            | b => \spawn{\defp{q}_1}{\selectR{b}} }
    \\
    \slof{ \infinwds{\ialph} |- \defp{q}_1 : \infinwds{\oalph} } \defd
      \caseL{ a => \spawn{\defp{q}_0}{\selectR{a}}
            | b => \spawn{\defp{q}_1}{\fwd} }
    \,.
  \end{lgathered}
\end{equation*}

Sequential transducers are closed under composition\autocite{??}.
To represent the composition of two infinite-word sequential transducers $\aut{T}_1$ and $\aut{T}_2$ as a well-typed process, we could simply construct their composition, $\aut{T} = \aut{T}_2 \circ \aut{T}_1$, as a sequential transducer in its own right and then represent the transducer $\aut{T}$ as a well-typed process.

Even easier, however, is to directly compose the processes that represent the transducers $\aut{T}_1$ and $\aut{T}_2$.
If $\aut{T}_1$ and $\aut{T}_2$ are in states $q$ and $s$, respectively, then the processes $\slof{\infinwds{\ialph} |- \defp{q} : \infinwds{\oalph}}$ and $\slof{\infinwds{\oalph} |- \defp{s} : \infinwds{\Delta}}$ are well-typed and the process $\slof{\infinwds{\ialph} |- \spawn{\defp{q}}{\defp{s}} : \infinwds{\Delta}}$  describes the current state of the composition, $\aut{T} = \aut{T}_2 \circ \aut{T}_1$.
In fact, \textcite{DeYoung+Pfenning:APLAS16} prove -- in a very closely related, if slightly different, framework -- that cut elimination actually constructs a normal-form process for the transducer $\aut{T}$.

\subsection{Turing machines}\label{sec:process-chains:turing-machines}

\paragraph*{Two-way infinite tape Turing machine}

Let $\aut{M} = (Q, \delta)$ be a two-way infinite tape Turing machine over alphabet $\ialph$.
We imagine the two-way infinite tape as divided into two one-way infinite halves with the machine's finite control, or head, sitting between them.
Each of these halves will be represented as a stream of symbols from $\ialph$, directed inward toward $\aut{M}$'s head.
As such, these two one-way infinite halves are described by the following dual types:%
\footnote{The involution $\sym*{}$ was defined in \cref{fig:singleton-logic:involution}, but not for coinductively defined propositions.
  Here we use $\sym*{\infinwds{\ialph}}$ merely as the name of a coinductively defined type, though the choice of name is intended to evoke the duality with the type $\infinwds{\ialph}$.}%
\begin{equation*}
  \begin{lgathered}
    \infinwds{\ialph} \defd \plus*[sub=_{a \in \ialph}]{ a: \infinwds{\ialph} } \\
    \sym*{\infinwds{\ialph}} \defd \with*[sub=_{a \in \ialph}]{ a : \sym*{\infinwds{\ialph}} }
  \,.
  \end{lgathered}
\end{equation*}
% The type $\infinwds{\ialph}$ describes the left half of the two-way infinite tape: a process that offers $\infinwds{\ialph}$ will emit to its right-hand client an infinite stream of tape symbols.
% Dually, the type $\sym*{\infinwds{\ialph}}$ describes the right half of the two-way infinite tape: a process that uses $\sym*{\infinwds{\ialph}}$ will emit to its left-hand provider an infinite stream of tape symbols.
That is, a process of type $\slof{ A |- \infinwds{\ialph} }$, for some $A$, acts as the left-hand one-way infinite half of the tape, whereas a process of the dual type, $\slof{ \sym*{\infinwds{\ialph}} |- B }$ for some $B$, acts as the right-hand one-way infinite half of the tape.

Because the machine's head sits between these two halves of the two-way infinite tape,
% As the finite control sits between the two halves of the two-way infinite tape,
it ought to correspond to a process of type $\slof{\infinwds{\ialph} |- \sym*{\infinwds{\ialph}}}$.
Indeed, for each state $q \in Q$, we will define two process expressions, $\slof{\infinwds{\ialph} |- \tlhead{\defp{q}} : \sym*{\infinwds{\ialph}}}$ and $\slof{\infinwds{\ialph} |- \trhead{\defp{q}} : \sym*{\infinwds{\ialph}}}$, for the two heads possible in state $q$:
\begin{equation*}
  \begin{lgathered}
    \slof{ \infinwds{\ialph} |- \tlhead{\defp{q}} : \sym*{\infinwds{\ialph}} } \defd
      \mathsf{caseL}_{a \in \ialph}\left(
        a \Rightarrow
          \begin{cases*}
            \spawn{\tlhead{\defp{q}'}}{\selectL{b}} & if $\delta(q, a) = (q', b, \mathsf{L})$ \\
            \spawn{\selectR{b}}{\trhead{\defp{q}'}} & if $\delta(q, a) = (q', b, \mathsf{R})$
          \end{cases*} \right)
  \\
    \slof{ \infinwds{\ialph} |- \trhead{\defp{q}} : \sym*{\infinwds{\ialph}} } \defd
      \mathsf{caseR}_{a \in \ialph}\left(
        a \Rightarrow
          \begin{cases*}
            \spawn{\tlhead{\defp{q}'}}{\selectL{b}} & if $\delta(q, a) = (q', b, \mathsf{L})$ \\
            \spawn{\selectR{b}}{\trhead{\defp{q}'}} & if $\delta(q, a) = (q', b, \mathsf{R})$
          \end{cases*} \right)
  \end{lgathered}
\end{equation*}
That is, a left-facing head begins by reading a symbol from its left.
Depending on the symbol that is read, the machine writes a new symbol in its place and then either advances the head to the left or otherwise turns the head to face the right.
Writing a new symbol is accomplished by spawning a message directed toward the head.
Right-facing heads are symmetric.

Notice that the tape in this process implementation is truly two-way infinite.
This is consistent with the model presented in \cref{ch:finite-automata}, but differs from the traditional model of a Turing machine.
In the traditional model, the tape might more accurately be described as two-way \emph{unbounded} -- at any given moment, the tape is finite, but can be extended.
If we wanted to prove the adequacy of our process implementation adequate with respect to traditional Turing machines, we would have to prove adequacy for infinite tapes that behave as merely unbounded, using a distinguished blank symbol.


% Notice a subtle difference between this implementation and the mathematical model described in \cref{ch:??}.
% In the mathematical model, configurations used finite strings to represent the two one-way halves of the two-way infinite tape.
% This was possible because of an invariant on the tape's contents: after a finite number of moves, the tape contained only finitely many non-blank symbols.%
% \footnote{In this sense, the tape might more accurately be described as two-way \emph{unbounded}.}
% However, in the implementation presented here, the types $\infinwds{\ialph}$ and $\sym*{\infinwds{\ialph}}$ do not make the same guarantee -- as previously explained, our language's types do not include the inductive types that would be necessary to enforce the finiteness invariant.
% Instead, we are the mercy of the processes of types $\slof{A |- \infinwds{\ialph}}$ and $\slof{\sym*{\infinwds{\ialph}} |- B}$ that represent the two tape halves to behave properly and eventually emit only blank symbols.

\paragraph*{One-way infinite tape Turing machine}

Because the head of a two-way infinite tape machine corresponds to a process of type $\slof{ \infinwds{\ialph} |- \sym*{\infinwds{\ialph}} }$, it is not possible to easily compose two such machines using cut, as we had done for sequential transducers.
The types simply do not match:
\begin{equation*}
  \slof{ \infinwds{\ialph} |- \tlhead{\defp{q}} : \sym*{\infinwds{\ialph}} } \neq \slof{ \infinwds{\ialph} |- \trhead{\defp{s}} : \sym*{\infinwds{\ialph}} }
  \,.
\end{equation*}
However, if we use one-way infinite tape Turing machines, composition of machines is possible.

We will use the following types.
The type $\infinwds{\ialph}$ is the same as above, but we introduce a type $\sym*{\finwds{\ialph}}$ that will be used in describing the one-way infinite tape's finite end.
\begin{equation*}
  \begin{lgathered}
    \infinwds{\ialph} \defd \plus*[sub=_{a \in \ialph}]{ a : \infinwds{\ialph} } \\
    \sym*{\finwds{\ialph}} \defd \with*[sub=_{a \in \ialph}]{ a : \sym*{\finwds{\ialph}} , \eow : \infinwds{\ialph} }
  \end{lgathered}
\end{equation*}
In particular, the label $\eow$ will be used to mark the tape's finite end.

The type name $\sym*{\finwds{\ialph}}$ was chosen to suggest a left-directed finite string, but should not be taken too literally -- as previously mentioned, the language presented in this \lcnamecref{ch:process-chains} does not have the inductive types that would be necessary to enforce finiteness.
Notice, too, that any process that offers the type $\sym*{\finwds{\ialph}}$ continues by offering $\infinwds{\ialph}$ when $\selectL{\eow}$ is received, which will be crucial in composing machines (although not exactly what would be expected of a strict dual of $\finwds{\ialph}$).

The machine's head ought to correspond to a process of type $\slof{ \infinwds{\ialph} |- \sym*{\finwds{\ialph}} }$.
For each state $q \in Q$, we will define a process $\slof{ \infinwds{\ialph} |- \tlhead{\defp{q}} : \sym*{\finwds{\ialph}} }$ just like we did for the two-way infinite tape machines:
\begin{equation*}
    \slof{ \infinwds{\ialph} |- \tlhead{\defp{q}} : \sym*{\finwds{\ialph}} } \defd
      \mathsf{caseL}_{a \in \ialph}\left(
        a \Rightarrow
          \begin{cases*}
            \spawn{\tlhead{\defp{q}'}}{\selectL{b}} & if $\delta(q, a) = (q', b, \mathsf{L})$ \\
            \spawn{\selectR{b}}{\trhead{\defp{q}'}} & if $\delta(q, a) = (q', b, \mathsf{R})$
          \end{cases*} \right)
\end{equation*}

For each state $q \in Q$, we will also define a process $\slof{ \infinwds{\ialph} |- \trhead{\defp{q}} : \sym*{\finwds{\ialph}} }$ for the right-facing head in state $q$.
This process is mainly like the process definition for a right-facing head in the two-way infinite tape Turing machine.
The difference is that here we have a $\eow$ branch, owing to the presence of label $\eow$ in the type $\sym*{\finwds{\ialph}}$:
\begin{equation*}
    \slof{ \infinwds{\ialph} |- \trhead{\defp{q}} : \sym*{\finwds{\ialph}} } \defd
      \mathsf{caseR}_{a \in \ialph}\left(
        \begin{array}{@{}r@{}l@{}}
          a \Rightarrow {} &
            \begin{cases*}
              \spawn{\tlhead{\defp{q}'}}{\selectL{b}} & if $\delta(q, a) = (q', b, \mathsf{L})$ \\
              \spawn{\selectR{b}}{\trhead{\defp{q}'}} & if $\delta(q, a) = (q', b, \mathsf{R})$
            \end{cases*}
          \\[4\jot]
          \mid \eow \Rightarrow {} &
            \begin{cases*}
              \fwd & if $q \in F$ \\
              \mathrlap{\spawn{\tlhead{\defp{q}}}{\selectL{\eow}}} \hphantom{\spawn{\tlhead{\defp{q}'}}{\selectL{b}}} & otherwise
            \end{cases*}
        \end{array} \right)
\end{equation*}
Just like the mathematical model of a one-way infinite tape Turing machine, the behavior of a right-facing head that reaches the finite end of the tape depends on whether the current state is final.
If it is final, then the forwarding process causes the machine's head to terminate, leaving the tape.
Otherwise, if the state is not final, then the head is turned to the left using $\spawn{\tlhead{\defp{q}}}{\selectL{\eow}}$, where the message $\selectL{\eow}$ is recreated to preserve our marking of the tape's end.

Thus, to start a machine, we would use the process
\begin{equation*}
  \slof{ \infinwds{\ialph} |- \spawn{\tlhead{\defp{q}}}{\selectL{\eow}} : \infinwds{\ialph} }
  \,.
\end{equation*}
Notice that this type can be readily composed.
States $q$ and $s$ from different machines could be easily composed with cut:
\begin{equation*}
  \slof{ \infinwds{\ialph} |- \spawn{(\spawn{\tlhead{\defp{q}}}{\selectL{\eow}})}{(\spawn{\tlhead{\defp{s}}}{\selectL{\eow}})} : \infinwds{\ialph} }
  \,.
\end{equation*}
This form of composition is sequential, not parallel, because the left-facing head $\tlhead{\defp{s}}$ must block until the preceding machine terminates and forwards its tape on to $\tlhead{\defp{s}}$.

% Rather than situating the machine's head below a cell on a two-way infinite tape, it will be convenient to think of the head as \begin{enumerate*}[label=\emph{(\roman*)}] \item occuring between the two one-way halves of the tape, and \item facing either the left half or right half of the tape. \end{enumerate*}
% Thus, each state in the Turing machine will correspond to two processes, $\tlhead{\defp{q}}$ and $\trhead{\defp{q}}$, for the state's left- and right-facing instances, respectively.

% These processes will be typed as $\slof{\tape |- \tlhead{\defp{q}} : \epat}$ and $\slof{\tape |- \trhead{\defp{q}} : \epat}$

% \begin{equation*}
%   \begin{lgathered}
%     \tape \defd \plus*[sub=_{a \in \ialph}]{ a: \tape , \eow: \tapee } \\
%     \epat \defd \with*[sub=_{a \in \ialph}]{ a: \epat , \eow: \tape }
%   \end{lgathered}
% \end{equation*}

% \begin{equation*}
%   \begin{lgathered}
%     \infinwds{\ialph} \defd \plus*[sub=_{a \in \ialph}]{ a: \infinwds{\ialph} } \\
%     \finwds{\ialph}_{\with} \defd \with*[sub=_{a \in \ialph}]{ a: \finwds{\ialph}_{\with} , \eow: \infinwds{\ialph} }
%   \end{lgathered}
% \end{equation*}


% \begin{equation*}
%   \slof{ \infinwds{\ialph} |- \tlhead{\defp{q}} : \finwds{\ialph}_{\with} } \defd
%     \mathsf{caseL}_{a \in \ialph}
%     \left\lparen
%         a \Rightarrow
%           \begin{cases*}
%              \spawn{\tlhead{\defp{q}'_a}}{\selectL{a}'}
%                & if $\delta(q, a) = (q'_a, a', \mathsf{L})$
%              \\
%              \spawn{\selectR{a}'}{\trhead{\defp{q}'_a}}
%                & if $\delta(q, a) = (q'_a, a', \mathsf{R})$
%            \end{cases*}
%     \right\rparen
% \end{equation*}

% \begin{equation*}
%   \slof{ \infinwds{\ialph} |- \trhead{\defp{q}} : \finwds{\ialph}_{\with} } \defd
%     \mathsf{caseR}_{a \in \ialph}
%     \left\lparen
%       \begin{array}{@{}l@{}}
%         \hphantom{\mid {}}
%         a \Rightarrow
%           \begin{cases*}
%             \spawn{\tlhead{\defp{q}'_a}}{\selectL{a}'}
%               & if $\delta(q, a) = (q'_a, a', \mathsf{L})$
%             \\
%             \spawn{\selectR{a}'}{\trhead{\defp{q}'_a}}
%               & if $\delta(q, a) = (q'_a, a', \mathsf{R})$
%           \end{cases*}
%       \\[3ex]
%         \mid \eow \Rightarrow \spawn{\trhead{\defp{q}}}{\selectL{\eow}}
%       \end{array}
%     \right\rparen
% \end{equation*}


% \begin{equation*}
%   \slof{ \tape |- \tlhead{\defp{q}} : \epat } \defd
%     \mathsf{caseL}_{a \in \ialph}
%     \left\lparen
%       \begin{array}{@{}l@{}}
%         \hphantom{\mid {}}
%         a \Rightarrow
%           \begin{cases*}
%              \spawn{\tlhead{\defp{q}'_a}}{\selectL{a}'}
%                & if $\delta(q, a) = (q'_a, a', \mathsf{L})$
%              \\
%              \spawn{\selectR{a}'}{\trhead{\defp{q}'_a}}
%                & if $\delta(q, a) = (q'_a, a', \mathsf{R})$
%            \end{cases*}
%       \\[3ex]
%         \mid \eow \Rightarrow \spawn{\selectR{\eow}}
%                                     {\spawn{\selectR{\tblank}}{\tlhead{\defp{q}}}}
%       \end{array}
%     \right\rparen
% \end{equation*}

% \begin{equation*}
%   \slof{ \tape |- \trhead{\defp{q}} : \epat } \defd
%     \mathsf{caseR}_{a \in \ialph}
%     \left\lparen
%       \begin{array}{@{}l@{}}
%         \hphantom{\mid {}}
%         a \Rightarrow
%           \begin{cases*}
%             \spawn{\tlhead{\defp{q}'_a}}{\selectL{a}'}
%               & if $\delta(q, a) = (q'_a, a', \mathsf{L})$
%             \\
%             \spawn{\selectR{a}'}{\trhead{\defp{q}'_a}}
%               & if $\delta(q, a) = (q'_a, a', \mathsf{R})$
%           \end{cases*}
%       \\[3ex]
%         \mid \eow \Rightarrow \spawn{\spawn{\trhead{\defp{q}}}{\selectL{\tblank}}}
%                                     {\selectL{\eow}}
%       \end{array}
%     \right\rparen
% \end{equation*}


% Tape |- q1 : epaT    q1 reads from either side
% epaT |- q2 : Tape    q2 writes to either side
% Tape |- q3 : Tape    q3 reads from the left and writes to the right
% epaT |- q4 : epaT    q4 writes to the left and reads from the right



% \section{Automata and transducers}

% \begin{equation*}
%   \slof{\infinwds{\Sigma} |- q : \finwds{\Gamma}}
%   \defd
%   \caseL[a \in \Sigma]{a => \spawn{q'_a}{\selectR{w}_{q,a}}}
% \end{equation*}


% \clearpage

% \section{Toward asynchronous SILL}

% Most work on SILL uses a synchronous interpretation of cut reductions as communication.
% \begin{gather*}
%   \infer[\jrule{CUT}]{\lctx'_1, \lctx'_2, \lctx \vdash (\nu x)(x(y).P \mid (\nu y)\overline{x}\langle y\rangle.(Q_1 \mid Q_2)) :: z{:}C}{
%     \infer[\rrule{\lolli}]{\lctx \vdash x(y).P :: x{:}A \lolli B}{
%       \lctx, y{:}A \vdash P :: x{:}B} &
%     \infer[\lrule{\lolli}]{\lctx'_1, \lctx'_2, x{:}A \lolli B \vdash (\nu y)\overline{x}\langle y\rangle.(Q_1 \mid Q_2) :: z{:}C}{
%       \lctx'_1 \vdash Q_1 :: y{:}A &
%       \lctx'_2, x{:}B \vdash Q_2 :: z{:}C}}
%   \\\reduces\\
%   \infer[\jrule{CUT}]{\lctx'_2, \lctx, \lctx'_1 \vdash (\nu x)((\nu y)(Q_1 \mid P) \mid Q_2) :: z{:}C}{
%     \infer[\jrule{CUT}]{\lctx, \lctx'_1 \vdash (\nu y)(Q_1 \mid P) :: x{:}B}{
%       \lctx'_1 \vdash Q_1 :: y{:}A &
%       \lctx, y{:}A \vdash P :: x{:}B} &
%     \lctx'_2, x{:}B \vdash Q_2 :: z{:}C}
% \end{gather*}

% \begin{inferences}
%   \infer[\rrule{\lolli}]{\lctx \vdash x(y,x').P :: x{:}A \lolli B}{
%     \lctx, y{:}A \vdash P :: x'{:}B}
%   \and
%   \infer[\lrule{\lolli}']{x{:}A \lolli B, y{:}A \vdash \overline{x}\langle y,x'\rangle :: x'{:}B}{}
% \end{inferences}

% \begin{inferences}
%   \infer[\rrule{\bang}']{\uctx, u{:}A ; \lctxe \vdash \overline{x}\langle u\rangle :: x{:}\bang A}{}
%   \and
%   \infer[\lrule{\bang}]{\uctx ; \lctx, x{:}\bang A \vdash x(u).P :: z{:}C}{
%     \uctx, u{:}A ; \lctx \vdash P :: z{:}C}
% \end{inferences}

% \begin{inferences}
% %  \infer[\jrule{CUT}
% \infer[\rrule{\bang}']{\uctx, u{:}A ; \lctxe \vdash \overline{x}\langle u\rangle :: x{:}\bang A}{}
%   \and
%   \infer[\lrule{\bang}]{\uctx ; \lctx, x{:}\bang A \vdash x(u).P :: z{:}C}{
%     \uctx, u{:}A ; \lctx \vdash P :: z{:}C}
% \end{inferences}





% \section{}

% \subsection{Process chains}

% % A computational process represents a single thread of control that interacts with its environment.
% %
% % Then,
% By analogy with chains of communicating automata, we envision a process chain, $\chn$, as a (possibly empty) finite sequence of processes $(P_i)_{i=1}^{n}$, each with its own independent thread of control and arranged in a linear topology.
% As depicted in the adjacent \lcnamecref{fig:singleton-processes:chain-topology},%
% %
% \begin{marginfigure}
%   \centering
%   \begin{tikzpicture}
%     \graph [math nodes, nodes={circle, draw}] {
%       P_0 / [coordinate]
%        --
%       P_1
%        --
%       / \dotsb [rectangle, text height=1ex, draw=none]
%        --
%       P_i
%        --
%       / \dotsb [rectangle, text height=1ex, draw=none]
%        --
%       P_n
%        --
%       / [coordinate];
%     };
%     \node [fit=(P_1) (P_i) (P_n), inner xsep=.5em,
%            draw,
%            label distance=2em, label=$\chn$] {};
%   \end{tikzpicture}
%   \caption{A prototypical process chain, $\chn$}\label{fig:singleton-processes:chain-topology}
% \end{marginfigure}
% %
% % each process $P_i$ shares a unique channel with its left-hand neighbor and a unique channel with its right-hand neighbor.
% each process $P_i$ shares unique channels with its left- and right-hand neighbors. %, along which it communicates with those neighbors.
% Along these channels, neighboring processes may interact -- and react, changing their internal state.
% Because process chains always maintain a linear topology, 
% % these
% channels need not be named -- they can instead be referred to as simply the left- and right-hand channels of $P_i$.

% A chain $\chn$ does not compute in isolation, however.
% The left-hand channel of $P_1$ and the right-hand channel of $P_n$ enable the chain to interact with its surroundings.
% Because these two channels are the only ones exposed to the external environment [surroundings], they may be referred to as the left- and right-hand channels of the chain.

% Chains may be composed end to end by conjoining the right-hand channel of one chain with the left-hand channel of another chain.

% \paragraph{Chains as a free monoid}
% % \newthought
% {Moving from} this informal intuition to a more formal characterization, process chains $\chn$ form a free monoid over processes $P$:
% \begin{equation*}
%   \chn \Coloneqq \chne \mid (\chn_1 \cc \chn_2) \mid P
%   \,,
% \end{equation*}
% where $\chne$ denotes the empty chain and $\cc$ denotes the monoid operation, chain composition.
% As the monoid operation, composition is subject to the usual associativity and unit laws%
% \footnote{Unlike composition in most process calculi, chain composition is not commutative.}%
% :
% \begin{gather*}
%   (\chn_1 \cc \chn_2) \cc \chn_3 = \chn_1 \cc (\chn_2 \cc \chn_3) \\
%   \chne \cc \chn = \chn = \chn \cc \chne
% \end{gather*}
% Because these monoid laws may be freely applied, we switch between two alternative views of process chains whenever convenient: the view that a chain $\chn$ is either empty ($\chn = \chne$), a composition ($\chn = \chn_1 \cc \chn_2$), or a single process ($\chn = P$); and 
% % has one of the forms $\chne$, $\chn_1 \cc \chn_2$, or $P$; or
% the view that a chain $\chn$ is a finite sequence of processes ($\chn = P_1 \cc \dotsb \cc P_n$).

% \newthought{To ...}, a session-type system for process chains can be developed.
% to describe how the process chain $\chn$ interacts with its environment, we use a judgment
% \begin{equation*}
%   \slcof{A |- \chn : B}
%   \,,
% \end{equation*}
% meaning that the chain $\chn$ offers service $B$ along its right-hand channel, while concurrently using service $A$ along its left-hand channel.

% For a chain composition $\chn_1 \cc \chn_2$ to be well-typed, the service offered by $\chn_1$ along its right-hand channel must be the same service that $\chn_2$ expects to use along its left-hand channel.
% Otherwise, communication between $\chn_1$ and $\chn_2$
% \begin{equation*}
%   \infer[\jrule{C-CUT}^B]{\slcof{A |- \chn_1 \cc \chn_2 : C}}{
%     \slcof{A |- \chn_1 : B} & \slcof{B |- \chn_2 : C}}
% \end{equation*}

% The empty chain, $\chne$, offers a service $A$ to its right by directly using the same service from its left:
% \begin{equation*}
%   \infer[\jrule{C-ID}^A]{\slcof{A |- \chne : A}}{}
% \end{equation*}

% Lastly, a chain that consists of a single process $P$ is well-typed if its process expression $P$ is well-typed:
% \begin{equation*}
%   \infer[\jrule{C-PROC}]{\slcof{A |- P : C}}{
%     \slof{A |- P : C}}
% \end{equation*}

% \begin{figure}[tbp]
%   \begin{inferences}
%   \infer[\jrule{C-CUT}^B]{\slcof{A |- \chn_1 \cc \chn_2 : C}}{
%     \slcof{A |- \chn_1 : B} & \slcof{B |- \chn_2 : C}}
%   \and
%   \infer[\jrule{C-ID}^A]{\slcof{A |- \chne : A}}{}
%   \and
%   \infer[\jrule{C-PROC}]{\slcof{A |- P : C}}{
%       \slof{A |- P : C}}  
%   \end{inferences}
%   \caption{Process chains and their session-type system}%
%   \label{fig:process-chains:chains}
% \end{figure}

% Offers/uses distinction: retained for consistency with the hypothetical judgement asymmetry and SILL.
% Judgmental asymmetry between antecedents and consequents of a sequent.


% A chain $\chn$ does not compute in isolation, but instead interacts with its environment along two channels:
% % A chain $\chn$ may interact with its environment along two channels:
% to its left along the left-hand channel of $P_1$, and to its right along the right-hand channel of $P_n$.
% Chains can be composed end to end by
% %
% The left-hand channel of $P_1$ and the right-hand channel of 

% More formally, as ordered lists of processes, process chains form a free monoid.

% Alternatively, process chains may be characterized algebraically as forming a free monoid over processes.


% Process chains form a free monoid...

% Process chains communicate with their environment...

% The judgment $\slcof{A |- \chn : B}$ describes the pattern of communication...

% Chain composition
% \begin{equation*}
%   \infer[\jrule{C-CUT}^B]{\slcof{A |- \chn_1 \cc \chn_2 : C}}{
%     \slcof{A |- \chn_1 : B} & \slcof{B |- \chn_2 : C}}
% \end{equation*}

% Empty chain
% \begin{equation*}
%   \infer[\jrule{C-ID}^A]{\slcof{A |- \chne : A}}{}
% \end{equation*}

% Monoid laws applies silently  ...

% Chain consisting of one process
% \begin{equation*}
%   \infer[\jrule{C-PROC}]{\slcof{A |- P : B}}{
%     \slof{A |- P : B}}
% \end{equation*}

% \section{Session-typed asynchronous process chains}

% \begin{itemize}
% \item Foreshadow theorem about relationship with communicating automata
% \end{itemize}

% By analogy with chains of communicating automata, we envision a process chain, $\chn$, as a finite sequence of processes $(P_i)_{i=1}^{n}$, each with its own independent thread of control and arranged in a linear topology.
% As depicted in the adjacent \lcnamecref{fig:singleton-processes:chain-topology},%
% %
% \begin{marginfigure}
%   \centering
%   \begin{tikzpicture}
%     \graph [math nodes, nodes={circle, draw}] {
%       P_0 / [coordinate]
%        --
%       P_1
%        --
%       / \dotsb [rectangle, text height=1ex, draw=none]
%        --
%       P_i
%        --
%       / \dotsb [rectangle, text height=1ex, draw=none]
%        --
%       P_n
%        --
%       / [coordinate];
%     };
%     \node [fit=(P_1) (P_i) (P_n), inner xsep=.5em,
%            draw,
%            label distance=2em, label=$\chn$] {};
%   \end{tikzpicture}
%   \caption{A process chain, $\chn$}\label{fig:singleton-processes:chain-topology}
% \end{marginfigure}
% %
% each process $P_i$ shares a unique channel with its left-hand neighbor and a unique channel with its right-hand neighbor.
% % Because process chains always have a linear topology, 
% These channels need not be named -- they can instead be referred to as simply the left- and right-hand channels of $P_i$.

% Process chains are never isolated from the surrounding environment.
% Both the left-hand channel of $P_1$ and the right-hand channel of $P_n$ continue to allow external communication, even as communication among neighboring processes changes the chain's internal state.


% As a string of processes, 

% Formally, then, process chains $\chn$ form a free monoid over processes $P$:
% % As a free monoidSyntactically, chains are generated by the following grammar.
% \begin{equation*}
%   \chn \Coloneqq \chne \mid (\chn_1 \cc \chn_2) \mid P
%   \,,
% \end{equation*}
% where we write $\chne$ for the empty chain and $\cc$ for the monoid operation, which is subject to the usual associativity and unit laws:
% \begin{gather*}
%   (\chn_1 \cc \chn_2) \cc \chn_3 = \chn_1 \cc (\chn_2 \cc \chn_3) \\
%   \chne \cc \chn = \chn = \chn \cc \chne
% \end{gather*}
% \Cref{fig:process-chains:chain-shapes} gives a graphical depiction of the three basic shapes that chains may take.
% %
% \begin{figure}[tbp]
%   \centering
%   \begin{tikzpicture}
%     \graph [math nodes, nodes={circle}] {
%       / [coordinate]
%        --
%       P_1 / \phantom{P}
%        --
%       / [coordinate];
%       (P_1.west) -- (P_1.east);
%     };
%     \node [fit=(P_1), inner xsep=.5em, draw,
%            label distance=2em, label={$\chn = \chne$}] {};
%   \end{tikzpicture}
%   \qquad
%   \begin{tikzpicture}
%     \graph [math nodes, nodes={circle, draw}] {
%       / [coordinate]
%        --
%       P_1 / P
%        --
%       / [coordinate];
%     };
%     \node [fit=(P_1), inner xsep=.5em, draw,
%            label distance=2em, label={$\chn = P$}] {};
%   \end{tikzpicture}

%   \begin{tikzpicture}
%     \graph [math nodes, nodes={circle, draw}] {
%       / [coordinate]
%        --
%       P_1 /
%        --
%       / \dotsb [rectangle, text height=1ex, draw=none]
%        --
%       P_n /
%        --
%       P_{n+1} /
%        --
%       / \dotsb [rectangle, text height=1ex, draw=none]
%        --
%       P_{n+m} /
%        --
%       / [coordinate];
%     };
%     \node (C1)
%           [fit=(P_1) (P_n), inner xsep=.5em, draw, dashed,
%            label distance=2em, label=$\chn_1$]
%           {};
%     \node (C2)
%           [fit=(P_{n+1}) (P_{n+m}), inner xsep=.5em, draw, dashed,
%            label distance=2em, label=$\chn_2$]
%           {};
%     \node [fit=(C1) (C2), inner xsep=.5em, draw,
%            label distance=2em, label={$\chn = \chn_1 \cc \chn_2$}] {};
%   \end{tikzpicture}
%   \caption{A graphical depiction of process chain constructors}%
%   \label{fig:process-chains:chain-shapes}
% \end{figure}

% \newthought{So far,} this definition of process chains has intentionally abstracted from what exactly a process is, and how exactly communication occurs over channels.


% \begin{figure}[tbp]
%   \vspace*{\dimexpr-\abovedisplayskip-\abovecaptionskip\relax}
%   \begin{syntax*}
%     Session types &
%       A & \alpha \mid \plus*[sub=_{\ell \in L}]{\ell:A_{\ell}} \mid \with*[sub=_{\ell \in L}]{\ell:A_{\ell}}
%     \\
%     Process expressions &
%       P & \spawn{P_1}{P_2} \mid \fwd
%         \begin{array}[t]{@{{} \mid {}}l@{}}
%           \selectR{\kay} \mid \caseL[\ell \in L]{\ell => P_{\ell}} \\
%           \caseR[\ell \in L]{\ell => P_{\ell}} \mid \selectL{\kay}
%         \end{array}
%   \end{syntax*}

%   \begin{inferences}
%     \infer[\jrule{CUT}^B]{\slof{A |- \spawn{P_1}{P_2} : C}}{
%       \slof{A |- P_1 : B} & \slof{B |- P_2 : C}}
%     \and
%     \infer[\jrule{ID}^A]{\slof{A |- \fwd : A}}{}
%     \\
%     \infer[\rrule{\plus}']{\slof{A_{\kay} |- \selectR{\kay} : \plus*[sub=_{\ell \in L}]{\ell:A_{\ell}}}}{
%       \text{($\kay \in L$)}}
%     \and
%     \infer[\lrule{\plus}]{\slof{\plus*[sub=_{\ell \in L}]{\ell:A_{\ell}} |- \caseL[\ell \in L]{\ell => P_{\ell}} : C}}{
%       \multipremise{\ell \in L}{\slof{A_{\ell} |- P_{\ell} : C}}}
%     \\
%     \infer[\rrule{\with}]{\slof{A |- \caseR[\ell \in L]{\ell => P_{\ell}} : \with*[sub=_{\ell \in L}]{\ell:C_{\ell}}}}{
%       \multipremise{\ell \in L}{\slof{A |- P_{\ell} : C_{\ell}}}}
%     \and
%     \infer[\lrule{\with}']{\slof{\with*[sub=_{\ell \in L}]{\ell:C_{\ell}} |- \selectL{\kay} : C_{\kay}}}{
%       \text{($\kay \in L$)}}
%   \end{inferences}
%   \vspace*{-\belowdisplayskip}
%   \caption{Asynchronous process chains and their session-type system}\label{fig:singleton-processes:typing-rules}
% \end{figure}
% %
% \Cref{fig:singleton-processes:typing-rules} presents the syntax of process chains and their session-type system.
% Formally, the session types are identical to the propositions of singleton logic; the process terms, identical to the Hilbert-style proof terms; and the session-typing rules, identical to the Hilbert-style inference rules.
% In fact, the whole of this \lcnamecref{fig:singleton-processes:typing-rules} is identical to \cref{fig:singleton-logic:hilbert}, save for the small difference in terminology.

% This size of this difference, however, belies its significance.
% \begin{itemize}
% \item The proof term $\spawn{P_1}{P_2}$ for composition of proofs is now reinterpreted as the expression for a process that will spawn, to the immediate left, a new thread of control for $P_1$, while the original thread of control continues with $P_2$.
%   In effect, $\spawn{P_1}{P_2}$ now composes process behaviors.

% \item The proof term $\fwd$ is reinterpreted as the expression for a process that terminates its thread of control, excising the process from the chain.

% \item The proof terms $\selectL{\kay}$ and $\selectR{\kay}$ are now viewed as messages carrying the label $\kay$ as their payloads.
%   The direction of the underlying arrow indicates the message's intended recipient: $\selectL{\kay}$ is being sent to the left-hand neighbor; $\selectR{\kay}$, to the right-hand neighbor.

% \item The proof term $\caseL[\ell \in L]{\ell => P_{\ell}}$ is reinterpreted as the expression for a process that waits to receive a message $\selectR{\kay}$ from its left-hand neighbor and then branches on the received label, so that the thread of control continues with $P_{\kay}$.
%   The proof term $\caseR[\ell \in L]{\ell => P_{\ell}}$ is interpreted dually as the expression for a process that branches on a message from its right-hand neighbor.
% \end{itemize}

% Just as session types characterize the communication behavior of individual process expressions, the same types can be used to describe the behavior of entire process chains.
% The judgment $\slcof{A |- \chn : B}$ indicates that the process chain $\chn$ is well-typed, with the left-hand channel of $\chn$ having type $A$ and the right-hand channel having type $B$.
% % Using the session-type system for process expressions, process chains can also be typed.
% % The judgment $\slcof{A |- \chn : C}$ indicates that the left-hand channel of chain $\chn$ has type $A$ and the right-hand channel of $\chn$ has type $C$.

% The simplest chain is the one that consists of a single process $P$; the chain inherits the process's type:
% \begin{equation*}
%   \infer[\jrule{C-PROC}]{\slcof{A |- P : C}}{
%     \slof{A |- P : C}}
% \end{equation*}

% The composition $\chn_1 \cc \chn_2$ is typable if the two chains assign the same type to their shared channel.
% \begin{equation*}
%   \infer[\jrule{C-CUT}^B]{\slcof{A |- \chn_1 \cc \chn_2 : C}}{
%     \slcof{A |- \chn_1 : B} & \slcof{B |- \chn_2 : C}}
% \end{equation*}
% \begin{equation*}
%   \infer[\jrule{C-ID}^A]{\slcof{A |- \chne : A}}{}
% \end{equation*}

% \begin{figure}[tbp]
%   \begin{syntax*}
%     Process chains &
%       \chn & \chne \mid (\chn_1 \cc \chn_2) \mid P
%   \end{syntax*}

%   \begin{inferences}
%     \infer[\jrule{CUT}^B]{\slcof{A |- \chn_1 \cc \chn_2 : C}}{
%       \slcof{A |- \chn_1 : B} & \slcof{B |- \chn_2 : C}}
%     \and
%     \infer[\jrule{ID}^A]{\slcof{A |- \chne : A}}{}
%     \and
%     \infer[\jrule{PROC}]{\slcof{A |- P : C}}{
%       \slof{A |- P : C}}
%   \end{inferences}

%   \begin{gather*}
%     (\chn_1 \cc \chn_2) \cc \chn_3 = \chn_1 \cc (\chn_2 \cc \chn_3) \\
%     \chne \cc \chn = \chn = \chn \cc \chne
%   \end{gather*}
%   \vspace*{-\abovedisplayskip}
%   \caption{Syntax and session-typing rules for process chains}%
%   \label{fig:process-chains:session-types}
% \end{figure}

% Chains can be reified as process expressions.
% Let $\pf*{-}$ be a function from chains to process expressions given by 
% \begin{align*}
%     \pf*{\chne} &= \fwd \\
%     \pf*{\chn_1 \cc \chn_2} &= \spawn{\pf{\chn_1}}{\pf{\chn_2}} \\
%     \pf{P} &= P
% \end{align*}

% \begin{theorem}
%   If $\slcof{A |- \chn : B}$, then $\slof{A |- \pf{\chn} : B}$.
% \end{theorem}

% \subsection{From admissibility of non-analytic cuts to an operational semantics}

% In the previous \lcnamecref{ch:singleton-logic}, we presented a procedure for normalizing Hilbert-style [singleton?] proofs.
% Full proof normalization was important to ...

% In this \lcnamecref{ch:process-chains}, however, our perspective has shifted from proof theory to concurrent computation, from proofs to processes.
% And so full normalization is no longer appropriate -- we now want to expose the concurrent computational behavior, not just ...
% The situation is analogous to that of intuitionistic natural deduction and simply-typed functional computation:

% In fact, the difference is even starker here because, once recursive process definitions are introduced\parencref{sec:??}, many useful processes will be nonterminating.
% Thus, there is no clear notion of value, as exists in functional computation.
% Nevertheless, in good Curry--Howard fashion, the principal cases of Hilbert-style proof normalization will still directly inform the operational semantics of processes.

% \begin{itemize}
% \item Operational semantics does not observe processes, observes only messages
% \end{itemize}

% \newthought{In the previous \lcnamecref{sec:??},} the description of how proof terms are reinterpreted as process expressions already hinted at a computational strategy.
% Here we present that operational semantics in its full detail.


% At the heart of the operational semantics for process chains is \emph{reduction}, a binary relation on chains which we write as $\reduces$.
% Reductions may occur among any of the chain's processes, and thus the relation is compatible with the monoid operation, $\cc$:
% \begin{inferences}
%   \infer{\chn_1 \cc \chn_2 \reduces \chn'_1 \cc \chn_2}{
%     \chn_1 \reduces \chn'_1}
%   \and
%   \infer{\chn_1 \cc \chn_2 \reduces \chn_1 \cc \chn'_2}{
%     \chn_2 \reduces \chn'_2}
% \end{inferences}

% A process $\spawn{P_1}{P_2}$ spawns, to its immediate left, a new thread of control for $P_1$, while the original thread of control continues with $P_2$.
% \begin{equation*}
%   \infer{\spawn{P_1}{P_2} \reduces P_1 \cc P_2}{}
% \end{equation*}
% Because process chains are always ... up to associativity and unit laws, these reductions 

% Recall 
% \begin{gather*}
%   \begin{aligned}
%     \nspawn{(\spawn{N_0}{\selectR{\kay}})}{M}
%       &= \nspawn{N_0}{(\nspawn{\selectR{\kay}}{M})}
%     \\
%     \nspawn{N}{(\spawn{\selectL{\kay}}{M_0})}
%       &= \nspawn{(\nspawn{N}{\selectL{\kay}})}{M_0}
%   \end{aligned}
%   \\[2\jot]
%   \begin{aligned}
%     \nspawn{\fwd}{M}
%       &= M
%     \\
%     \nspawn{N}{\fwd}
%       &= N
%   \end{aligned}
%   \\[2\jot]
%   \begin{aligned}
%     \nspawn{\selectR{\kay}}{\caseL[\ell \in L]{\ell => M_{\ell}}}
%       &= M_{\kay}
%     \\
%     \nspawn{\caseR[\ell \in L]{\ell => N_{\ell}}}{\selectL{\kay}}
%       &= N_{\kay}
%   \end{aligned}
%   \\[2\jot]
%   \begin{aligned}
%     \nspawn{(\spawn{\selectL{\kay}}{N_0})}{M}
%       &= \spawn{\selectL{\kay}}{(\nspawn{N_0}{M})}
%     \\
%     \nspawn{N}{(\spawn{M_0}{\selectR{\kay}})}
%       &= \spawn{(\nspawn{N}{M_0})}{\selectR{\kay}}
%     \\
%     \nspawn{\selectL{\kay}}{M}
%       &= \spawn{\selectL{\kay}}{M}
%     \\
%     \nspawn{N}{\selectR{\kay}}
%       &= \spawn{N}{\selectR{\kay}}
%     \\
%     \nspawn{\caseL[\ell \in L]{\ell => N_{\ell}}}{M}
%       &= \caseL[\ell \in L]{\ell => \nspawn{N_{\ell}}{M}}
%     \\
%     \nspawn{N}{\caseR[\ell \in L]{\ell => M_{\ell}}}
%       &= \caseR[\ell \in L]{\ell => \nspawn{N}{M_{\ell}}}
%   \end{aligned}
% \end{gather*}
% etc.

% \begin{itemize}
% \item The operational semantics uses a particular strategy: $\reduces$ is the least compatible relation that satisfies the following.
%   \begin{gather*}
%     \spawn{P_1}{P_2} \reduces P_1 \cc P_2 \\
%     \fwd \reduces \cnfe \\
%     \selectR{\kay} \cc \caseL[\ell \in L]{\ell => P_{\ell}} \reduces P_{\kay} \\
%     \caseR[\ell \in L]{\ell => P_{\ell}} \cc \selectL{\kay} \reduces P_{\kay}
%   \end{gather*}
%   We denote the reflexive, transitive closure of $\reduces$ by $\Reduces$.

%   \begin{theorem}[Type preservation]
%     If $\slcof{A |- \chn : B}$ and $\chn \reduces \chn'$, then $\slcof{A |- \chn' : B}$.
%   \end{theorem}
%   %
%   \begin{proof}
%     By structural induction on the given chain.
%   \end{proof}


%   \begin{lemma}
%     If $\slcof{A |- \chn : B}$ and $\chn = \chn'$, then $\slcof{A |- \chn' : B}$.
%   \end{lemma}

%   \begin{theorem}[Progress]
%     If $\slcof{A |- \chn : B}$, then either:
%     \begin{itemize}
%     \item $\chn \reduces \chn'$ for some $\chn'$;
%     \item $\chn$ is empty: $\chn = \chne$;
%     \item $\chn$ is ready to communicate along its left-hand channel: $\chn = \selectL{\kay} \cc \chn_0$ or $\chn = \caseL[\ell \in L]{\ell => P_{\ell}} \cc \chn_0$ for some $\chn_0$; or
%     \item $\chn$ is ready to communicate along its right-hand channel: $\chn = \chn_0 \cc \selectR{\kay}$ or $\chn = \chn_0 \cc \caseR[\ell \in L]{\ell => P_{\ell}}$ for some $\chn_0$.
%     \end{itemize}
%   \end{theorem}
%   %
%   \begin{proof}
%     By structural induction on the given process chain.
%   \end{proof}

%   \begin{theorem}
%     $\chn^\sharp \Reduces \chn$ for all $\chn$.
%   \end{theorem}
%   \begin{proof}
%     By structural induction on the given chain.
%   \end{proof}

%   % \begin{conjecture}
%   %   If $\cnf_0 \Reduces \cnf \longarrownot\reduces$, then $\wn{\cnf_0^\sharp} = \cnf^\sharp$.
%   %   \begin{itemize}
%   %   \item If $\cnf_0 \longarrownot\reduces$, then $\wn{\cnf_0^\sharp} = \cnf_0^\sharp$.
%   %   \item If $\cnf_0 \reduces \cnf_1$ and $\wn{\cnf_1^\sharp} = P$, then $\wn{\cnf_0^\sharp} = P$, 
%   %   \end{itemize}
%   % \end{conjecture}

%   % \begin{corollary}
%   %   If $P \Reduces \cnf \longarrownot\reduces$, then $\wn{P} = \cnf^\sharp$.
%   % \end{corollary}
% \end{itemize}




% \begin{example}
%   An expression for a process that will wait for an $a$- or $b$-message to arrive from its left-hand neighbor and then send to its right-hand neighbor either two consecutive $a$-messages or a single $b$-message, respectively, is:
%   \begin{equation*}
%     \slof{
%       \plus*{a:\epsilon, b:\epsilon}
%       |-
%       \caseL{a => \spawn{\selectR{a}}{\selectR{a}}
%            | b => \selectR{b}}
%       :
%       \plus*{a:\plus*{a:\epsilon}, b:\epsilon}
%     }
%     \mathrlap{\,.}
%   \end{equation*}
%   Indeed, the process chain in which that process is sent an $a$-message computes as follows.
%   \begin{equation*}
%     \selectR{a} \cc \caseL{a => \spawn{\selectR{a}}{\selectR{a}}
%                          | b => \selectR{b}}
%       \reduces \spawn{\selectR{a}}{\selectR{a}}
%       \reduces \selectR{a} \cc \selectR{a}
%   \end{equation*}
% \end{example}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
