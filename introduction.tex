\chapter{Introduction}\label{ch:introduction}

\begin{itemize}
\item Computation as deduction: clear, expressive, and provably correct programs
  \begin{itemize}
  \item Examples of sucess stories
  \item Can it be applied to concurrency?
  \end{itemize}
\item Proof constuction and proof reduction views of con currency
  \begin{itemize}
  \item Proof construction: good for specifications 
  \item Proof reduction: good for implementions 
  \end{itemize}
\item Thesis statement: Session types bridge these two views
\item Ordered logic as a proving ground 
  \begin{itemize}
  \item Ordered rewriting for proof construction
  \item Singleton logic (purely additive fragment of ordered logic) for proof reduction
  \end{itemize}
\item Ordered rewriting (chapter 4) for specifications
  \begin{itemize}
  \item DFAs and NFAs 
  \item Binary counters
  \end{itemize}
\item Refinement of ordered rewriting for choreographies (chapter 5)
  \begin{itemize}
  \item Recursive definitions as processes; atoms as messages 
  \item Untyped (mostly, except for directions)
  \item Rewriting bisimilarity for observational equivalence
    \begin{itemize}
    \item Examples
    \end{itemize}
  \end{itemize}
\item Singleton logic and its semi-axiomatic calculus (chapter 6)
\item 
\end{itemize}


Concurrent systems are notoriously difficult to get right.

Beginning with Curry's observation that Hilbert [...] corresponds to a form of computation based on combinatory reduction\autocite{??}, and continuing with Howard's discovery of an isomorphism between [Gentzen's] intuitionistic natural deduction and Church's simply-typed $\lambda$-calculus, computation-as-deduction has been the gold standard for clear, expressive, and provably correct programs.

Computation-as-deduction can be divided into two classes: proof-search-as-computation and proof-reduction-as-computation.
The former provides a logically grounded basis for the backward- and forward-chaining logic programming paradigms, whereas the latter is the foundation for the functional programming paradigm.

Logically grounded concurrent computation 

More recently, a proof-reduction description of concurrency has been discovered by \textcite{??} with \textcite{??}.
In this isomorphism, linear propositions correspond to session types; sequent proofs, to session-typed processes; and cut reduction, to synchronous message-passing communication.

This thesis seeks to bring these two apparently divergent views of concurrency together.
Is there a class of specifications for which well-typed implementations can automatically be extracted?

Thesis statement: Session types form the bridge. 


\section{Proposal introduction}

With the increasingly complex, distributed nature of today's software systems, concurrency is ubiquitous.
Concurrency facilitates distributed computation by structuring systems as nondeterministic compositions of simpler subsystems.
But, concomitant with nondeterminism, concurrent systems are notoriously tricky to get right:
subtle races and deadlocks can occur even in the most rigorously tested of systems.

At the same time, decades of research into connections between proof theory and programming languages have firmly established the principle of \vocab{computation as deduction} as the gold standard [framework] for clear, expressive, and provably correct programs.
Most generally, intuitionistic logic is the bedrock for both the typed functional\autocite{Martin-Lof:LMPS80} and logic programming\autocites{Miller+:PAL91}{Andreoli:JLC92}\fixnote{check refs?} paradigms.
In more specific [...]
Examples abound: lax logic for effectful computation\autocite{Benton:JFP98}, temporal logic for functional reactive programming\autocite{Jeffrey:PLPV12}, and linear logic for graph-based algorithms\autocite{Cruz+:ICLP14}, to name just a few.

Can a computation-as-deduction approach make it similarly easier to clearly and concisely specify, as well as correctly implement, concurrent programs?

\subsection{}

The principle of computation as deduction comes in two flavors: \vocab{proof construction as computation} and \vocab{proof reduction as computation}.
Under a proof-construction-as-computation view, the search for a proof, according to a fixed strategy, forms the basis of computation; it is the foundation for logic programming\autocites{Miller+:PAL91}{Andreoli:JLC92}.
The proof-reduction-as-computation view, on the other hand, revolves around a correspondence, known as the Curry--Howard Isomorphism\autocite{Curry:??}{Howard:??}, between propositions and types, proofs and programs, and proof simplification, or reduction, and program evaluation;
it is the foundation for typed functional programming\autocite{Martin-Lof:LMPS80}.

Both the proof-construction and proof-reduction approaches have been successfully applied to concurrent programming, originally stemming from \citeauthor{Girard:TCS87}'s suggestion of connections between linear logic and concurrency\autocite{Girard:TCS87}.
In the proof-construction vein, \acifused{CLF}{\ac{CLF}\autocite{Watkins+:CMU02}}{the \acf{CLF}\autocite{Watkins+:CMU02}} treats the permutability of inference rules as the source of concurrency.
\Ac{CLF} has been used to specify a variety of concurrent systems, ranging from the $\pi$-calculus to security protocols and even emergent story narratives\autocites{Cervesato+Scedrov:IC09}{Martens+:LPNMR13}.\fixnote{check refs}
Although these same concurrent systems can be simulated according to their \ac{CLF} specifications by the Lollimon\autocite{Lopez+:PPDP05} and Celf\autocite{Schack-Nielsen:ITU11} logic programming engines, the programs ultimately remain specifications, not actual \emph{decentralized} implementations.

Taking the other, proof-reduction tack, \textcite{Abramsky:TCS93}, \textcite{Bellin+Scott:TCS94}, and later \textcite{Caires+Pfenning:CONCUR10} with Toninho\autocites{Caires+:TLDI12}{Caires+:MSCS13} have given correspondences between sequent calculus proofs or proof nets in linear logic and processes; between cut elimination and concurrent process execution.
Moreover, in \citeauthor{Caires+:MSCS13}'s work, the correspondence is a true Curry--Howard isomorphism in that intuitionistic linear propositions are also types -- \vocab{session types}\autocite{Honda:CONCUR93} that describe the interaction protocol to which a process adheres.
Unlike proof construction, the proof-reduction approach yields actual decentralized implementations with independent threads of control\autocites{Toninho+:ESOP13}{Griffith+Pfenning:14}.

In spite of their common basis in linear logic, these proof-construction and proof-reduction approaches to concurrent computation appear at first glance to be strikingly disparate.
They have different dynamics; they offer different guarantees (session fidelity, behavioral type preservation, and deadlock freedom for the proof-reduction approach, but only non-behavioral type preservaton for the proof-construction approach); and, perhaps most importantly, they serve very different roles in programming practice.
Proof construction is better suited to system specification and reasoning, whereas proof reduction is better suited to implementation.

To reduce the possibiity of error when building an implementation from a specification, we would like to minimize the gap between the two.
Despite the apparent disparity between proof construction and proof reduction, is there a class of concurrent specifications from which decentralized concurrent implementations can be automatically extracted?
Stated differently, is there perhaps (some fragment of) a substructural logic in which the computational natures of proof construction and proof reduction coincide?

\subsection{}

The thesis is that, yes, we can indeed have our cake and eat it too:
\begin{quotation}
\normalsize\noindent
Thesis statement.
\itshape Session types form a bridge between distinct notions of concurrency in computational interpretations of ordered logic based on proof construction, on one hand, and proof reduction, on the other hand.
\end{quotation}

\Cref{part:preliminaries} reviews some necessary background information: definitions of nondeterministic and \aclp*{DFA}~\parencref{ch:automata}, and a sequent calculus presentation of ordered logic~\parencref{ch:ordered-logic}.
The reader should feel free to skim or skip these \lcnamecrefs{ch:automata} and return to them 

\newthought{\Cref{part:proof-construction} then delves} into a proof-construction approach to concurrency, beginning with a review of a framework for string rewriting~\parencref{ch:string-rewriting}.
Because disjoint segments of a string may be rewritten independently, string rewriting can be used to specify concurrent systems that have a linear topology.
The \lcnamecref{ch:string-rewriting} concludes with two extended examples of string rewriting specifications:
\aclp*{NFA}\footnote{And, as a special case, deterministic ones, too.}
and binary representations of natural numbers equipped with increment and decrement operations.
These will serve as running examples throughout this document.

Despite being concurrent, string rewriting specifications lack an immediate notion of local execution.
String rewriting presumes the existence of a central conductor that orchestrates the computation, rewriting the string globally.
Global rewriting, although reasonable for concurrent specifications, will not map well to locally executing process implementations that a proof-reduction approach to concurrency suggests -- the gap is simply too large.

Toward this end, \cref{ch:ordered-rewriting} presents an extension of the Lambek calculus\autocite{Lambek:??} in which string rewriting specifications may be refined into \vocab{choreographies}.
Inspired by the process-as-formula view of linear logic\autocites{Miller:??}{Cervesato+Scedrov:IC09}, choreographies exist at a slightly lower level of abstraction than string rewriting specifications in that they begin to introduce a message-passing character.
A choreography partitions a string rewriting specification's symbols into 

Having introduced a message-passing character and stronger notion of process identity, we can then ask when two processes are observationally equivalent.
\Cref{ch:ordered-bisimilarity} develops a notion of bisimilarity for ordered propositions, where the uninterpreted atoms are the only observables.

\subsection{Contributions}

The contributions of this thesis can be viewed from several perspectives.
\begin{itemize}
\item This work can be seen as a proof-theoretic [logical] reconstruction of multiparty session types~\autocite{Honda+:POPL08}.
In multiparty session types, binary session types are generalized to conversations among several parties.
Conversations in their entirety are specified using global session types.
Global types can be projected to binary session types for each pair of participants, which very nearly are implementations.
\item This work can be seen to further understanding of proof construction and proof reduction.
\item Gives types to logic programs.
Guarantees deadlock-freedom.
\end{itemize}
In addition to the practical benefit of 


The remainder of this document aims to establish this thesis as a plausible one.
To do so, we turn our attention from linear logic to (non-modal) intuitionistic ordered logic~\autocites{Lambek:AMM58}{Polakow+Pfenning:MFPS99}---a restriction of linear logic in which the context of hypotheses forms a list rather than a multiset or bag---and defend the thesis in this restricted setting.
The proposed thesis research is to relax the restrictions and expand the ideas in this document to intuitionistic linear logic.

Specifically, this document describes ... as depicted in \cref{fig:outline}.
First, \cref{?} reviews a string rewriting interpretation of proof construction in a [non-modal] fragment of intuitionistic ordered logic~\autocite{Simmons:CMU12}.
String rewriting specifications in this fragment are equipped with a natural notion of concurrency based on treating  as equivalent the different interleavings of independent rewriting steps.
[equivalence classes of proofs.]

Despite being concurrent, these string rewriting specifications lack an immediate notion of \emph{process} or \emph{process identity}.
Toward this end, \cref{?} introduces \vocab{choreographies}, a further restriction of string rewriting specifications obtained when [in which] atomic propositions are assigned roles as either process-like atoms or message-like atoms.
(Message-like atoms, such as  in \cref{fig:outline}, are indicated with an arrow decoration.)
A specification may admit several choreographies, but, as described in \cref{?}, a well-formed choreography must be (lock-step) equivalent with the specification.

Even with process-like atoms, choreographies remain string rewriting specifications, not actual distributed implementations of processes.
Nevertheless, choreographies are a stepping-stone to process implementations. 
In \cref{?}, we develop a session-typed process calculus from a Curry--Howard interpretation of a fragment of linear logic; 
\Cref{?} shows how choreographies can be compiled to 

Choreographies serve as a stepping stone to full-fledged process definitions.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
