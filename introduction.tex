\chapter{Introduction}\label{ch:introduction}

With the increasingly complex, distributed nature of today's software systems, concurrency is ubiquitous.
Concurrency facilitates distributed computation by structuring systems as nondeterministic compositions of simpler subsystems.
But, being nondeterministic, concurrent systems are notoriously difficult to get right: 
subtle races and deadlocks can be lurking in even the most extensively tested of systems.

At the same time, decades of research into connections between proof theory and programming languages -- beginning with \citeauthor{Curry:PNAS34}'s observation that simplification of axiomatic proofs corresponds to combinatory reduction\autocite{Curry:PNAS34}, and notably continuing with \citeauthor{Howard:69}'s discovery of an isomorphism between intuitionistic natural deduction and the simply-typed $\lambda$-calculus\autocite{Howard:69} -- have firmly established the principle of \emph{computation as deduction} as the gold standard for clear, expressive, and provably correct programs.
Computation-as-deduction interpretations of intuitionistic logic, for example, are the foundations for both the typed functional\autocite{Martin-Lof:LMPS82} and logic\autocites{Miller+:PAL91}{Andreoli:JLC92} programming paradigms.

The computation-as-deduction idea has also been successfully applied to concurrent programming, originating from \citeauthor{Girard:TCS87}'s suggestion of possible connections between linear logic and concurrency\autocite{Girard:TCS87}.
These research efforts have been directed along two different proof-theoretic paths: \emph{concurrency as proof reduction} and \emph{concurrency as proof construction}.

% Since \citeauthor{Girard:TCS87} introduced linear logic\autocite{Girard:TCS87} and suggested the possibility of connections with concurrency, researchers have been studying 
% Along two different proof-theoretic paths: \emph{concurrency as proof reduction} and \emph{concurrency as proof construction}.

Under a concurrency-as-proof-reduction view, processes are mapped to linear sequent proofs or proof nets.
Proof reduction, in the form of cut elimination, thus corresponds to concurrent, message-passing communication.
This view was pioneered by \textfootcite{Abramsky:TCS93}, further pursued by \textfootcite{Bellin+Scott:TCS94}, and later extended to a true Curry--Howard isomorphism with the intuitionistic linear sequent calculus by \citeauthor{Caires+Pfenning:CONCUR10} with \citeauthor{Toninho:CMU15}\autocites{Caires+Pfenning:CONCUR10}{Caires+:TLDI12}{Caires+:MSCS16}.
Under this isomorphism, propositions are types -- specifically, binary \emph{session types}\autocite{Honda:CONCUR93} that describe the interaction protocol to which a process adheres.
And concurrency arises when the various interleavings of independent proof reductions are treated indistinguishably.

Under the other, concurrency-as-proof-construction view, computation is the act of building a partial, cut-free proof by nondeterministically applying the inference rules one by one.
% the search for a cut-free proof, according to a fixed, non-backtracking strategy, forms the basis of concurrent computation.%
% [\footnote{A backtracking strategy is possible, but would lead to Prolog-like backward-chain\-ing logic programming.}
% \fixnote{Citation in footnote?}
% Owing to the fixed, non-backtracking strategy, proof search may fail or diverge, so partial proofs, not complete proofs, are the primary objects.]
In our setting, this proof construction tack is perhaps best encapsulated by the \emph{process-as-formula} encoding, in which process constructors are mapped to linear logical connectives\autocite{Miller:ELP92}.
Concurrency is then manifested by the permutability of inference rules within a partial proof.


Despite the various research efforts into proof-reduction and proof-con\-struc\-tion approaches to concurrency as deduction, it appears that relatively little research on the relationship between the two approaches exists in the literature, with an article by \citeauthor{Cervesato+Scedrov:IC09} being the notable instance.\autocite{Cervesato+Scedrov:IC09}
In this document, we undertake a further study of the relationship between proof reduction and proof construction.

\newthought{Specifically, we begin} by noticing that
%
each of these two approaches to concurrency as deduction has its own strengths and weaknesses.
The proof-reduction approach excels at
% is particularly good when it comes to 
implementation.
Under \citeauthor{Caires+:MSCS16}'s isomorphism, proofs are immediately and directly well-typed process implementations.\autocites{Toninho+:ESOP13}{Griffith:UIUC16}
Properties of cut elimination also ensure that the proof-reduction approach enjoys session-type preservation and progress theorems -- well-typed processes will never deadlock.\footnote{But they can livelock or diverge in the presence of recursive types, unless those recursive types are strictly coinductive~\parencite{Derakhshan+Pfenning:LMCS20}.}

However, the proof-reduction approach does have its weaknesses.
Owing to the binary structure of the cut elimination procedure, the proof-reduction approach lends itself more naturally to synchronous communication, whereas asynchronous communication is often more consistent with programming practice and more directly realizable.
Also, because processes are generally long-running or non-terminating, recursion is even more important than in functional programming, and it is not obvious how to incorporate recursion in a logically justified way within the session type isomorphism.%
\footnote{Recursion can be incorporated in functional languages in a logically justified way, using inductive and coinductive types~\parencite{Mendler:LICS87}.
\Textcites{Derakhshan+Pfenning:LMCS20}{Somayyajula+Pfenning:20} are currently investigating logically justified inductive and coinductive session types.}

In contrast to proof reduction, the proof-construction approach excels at the task of specifying the behavior of concurrent systems.
It gives a more global description of the system by focusing on the interactions between processes, without prescribing how those interactions occur.
Because computation is captured by the construction of a partial cut-free proof and each inference rule has a single principal formula, this approach reflects \emph{a}syn\-chronous communication.
Moreover, recursion is relatively easy to incorporate because the logical aspects of proof construction are confined to hypothetical derivability and partial proofs, rather than provability and complete proofs.

On the flip side, however, it is not obvious how to extract well-behaved, local process implementations from these global specifications.
And, being untyped, the proof-construction approach does not enjoy type preservation and progress theorems like the concurrency-as-proof-reduction view does -- computation can easily deadlock or livelock when proof construction fails or diverges, respectively.

In short, the strengths and weaknesses of the proof-reduction and proof-construction approaches are almost exactly opposite each other.
To gain the strengths of both approaches without the weaknesses of either, we would like to identify a kind of intersection between concurrency as proof reduction and concurrency as proof construction.
That is, we want to identify fragments of proof reduction and proof construction that can be put in bijective correspondence.
On these fragments, we will be able to give global specifications of concurrent systems, while still being able to extract, or project, local implementations from them.

\newthought{To focus our attention} on the essential aspects of and relationship between the proof-reduction and proof-construction approaches to concurrency as deduction, we will limit our investigation in this document to processes arranged in chain topologies, as opposed to the more general tree topologies that \citeauthor{Caires+:MSCS16}'s isomorphism supports.
Chain topologies allow us to treat channels namelessly -- each process has exactly two channels, one with its unique left-hand neighbor and one with its right-hand neighbor -- which lifts a large but inessential notational burden.

In both the proof-reduction and proof-construction characterizations of concurrency, chain topologies exist as logically motivated fragments of the general case.
From the proof-construction perspective, chain topologies arise from (modality-free) ordered logic\autocites{Lambek:SLIM61}{Abrusci:MLQ90}{Kanazawa:LLI92}{Polakow+Pfenning:MFPS99}, an extension of the Lambek calculus\autocite{Lambek:AMM58};
from the proof-reduction perspective, chain topologies will arise from \emph{singleton logic}\autocites{Santocanale:FOSSACS02}{Fortier+Santocanale:CSL13}, an \emph{a}struc\-tural fragment of ordered and linear logics in which sequents have exactly one antecedent and one consequent.

Thus, the remainder of this document serves to establish the following thesis statement.
% Thus, we arrive at the following thesis.
\begin{quotation}
  \normalsize
  % Thesis statement.
  \itshape Session types form a bridge between distinct notions of concurrency in computational interpretations of singleton and ordered logics based on proof reduction, on one hand, and proof construction, on the other hand.
\end{quotation}

We also conjecture that the results contained in this document can be generalized in a relatively straightforward way to tree topologies.
This will introduce a moderately large notational overhead, but should present no conceptual difficulties.
The singleton logic used for proof-reduction-as-concurrency would be replaced with propositional linear logic, and the modality-free ordered logic used for proof-construction-as-concurrency would be replaced with first-order linear logic.

% \clearpage
\section{Overview}\label{sec:introduction:overview}

In this \lcnamecref{sec:introduction:overview}, we provide a high-level overview of this document.

\Cref{part:preliminaries} reviews some necessary background information, namely definitions of finite automata~\parencref{ch:finite-automata} and a sequent calculus presentation of ordered logic\autocite{Polakow+Pfenning:MFPS99}~\parencref{ch:ordered-logic}.
The reader who has some familiarity with these topics should feel free to skim or skip these \lcnamecrefs{ch:finite-automata}, returning to them as needed.

\subsection{Concurrency as proof construction}

\Cref{part:proof-construction} then delves into a proof-construction approach to concurrency, beginning in \cref{ch:string-rewriting} with a review of a string rewriting framework for specifying the dynamics of concurrent systems.
Specifically, string rewriting can be used for systems whose components are arranged into a chain topology and have a monoidal structure.
% Concurrency in these string rewriting specifications arises by treating the interleaving of independent rewriting steps, an equivalence sometimes known as concurrent equality\autocite{Watkins+:CMU02}.
Because 
% In string rewriting,
disjoint segments of a string may be rewritten independently,
% and
concurrency arises when the various interleavings of these independent rewritings are treated as equivalent.
String rewriting is an instance of multiset rewriting, so these ideas are not new, but are applied in a new setting.\autocite{Meseguer:TCS92}
% Using string rewriting in this way is 
% % This application of string rewriting can be seen as 
% a restricted instance\fixnote{special case/generalization?} of using multiset rewriting for concurrent specification.\autocite{Meseguer:TCS92}
\Cref{ch:string-rewriting} closes by introducing
% In \cref{sec:string-rewriting:??,sec:string-rewriting:??}, we introduce
specifications for two systems that will be used as running examples throughout this document: \aclp*{NFA}~\parencref{sec:string-rewriting:nfa} and binary counters~\parencref{sec:string-rewriting:binary-counter}.

\Cref{part:proof-construction} purports to give a proof-construction approach to concurrency, but string rewriting, while indeed a framework for concurrency, is not obviously connected to proof construction.
% superficially appears to be unconnected to proof construction.
For that, \cref{ch:ordered-rewriting} turns our attention toward the Lambek calculus and ordered logic.

Implicit in \citeauthor{Lambek:AMM58}'s calculus for categorial grammars is a notion of rewriting for free residuated monoids.%
\footnote{\Citeauthor{Lambek:AMM58}'s calculus was later extended to free residuated lattices~\parencites{Lambek:SLIM61}{Abrusci:MLQ90}{Kanazawa:LLI92}.}
\Cref{ch:ordered-rewriting} presents \emph{ordered rewriting}, a related rewriting framework for free residuated lattices, which we will derive from the ordered sequent calculus.
% [...] that will be derived from the ordered sequent calculus reviewed in \cref{ch:ordered-logic}.
As we will see, the sequent calculus's left rules share a large amount of boilerplate -- only very little of each left rule is devoted to the primary task of decomposing the principal proposition.
In response, we argue for a refactoring of the ordered sequent calculus, introducing a new judgment to decouple decomposition from the surrounding boilerplate~\parencref{sec:ordered-rewriting:boilerplate}.
% , and we then obtain ordered rewriting as a decomposition-centered fragment of the refactored calculus.
Ordered rewriting is then exactly
% falls out as a
the decomposition-centered fragment of the refactored sequent calculus~\parencref{sec:ordered-rewriting:unfocused}.
To the best of our knowledge, our refactoring of the sequent calculus left rules appears to be a new way of deriving rewriting from existing proof theory.
% logically.

As in string rewriting, ordered rewriting permits disjoint segments of the ordered context to be rewritten independently, and concurrency arises when the different interleavings of these independent rewritings are treated indistinguishably~\parencref{sec:ordered-rewriting:concurrency}.
And so ordered rewriting is the proof-construction characterization of concurrency that we were looking for.%
\footnote{Incidentally, this focused ordered rewriting framework is roughly what would be needed to combine the Ordered Logical Framework~\parencite{Polakow:CMU01} with the Concurrent Logical Framework~\parencite{Watkins+:CMU02}.}

\Cref{ch:ordered-rewriting} closes by extending ordered rewriting with ideas from focusing\autocites{Andreoli:JLC92} to better control the atomicity of individual rewriting steps~\parencref{sec:ordered-rewriting:focused,sec:ordered-rewriting:shifts}.
The particular formulation we choose is \citeauthor{Zeilberger:POPL08}'s higher-order focusing\autocite{Zeilberger:POPL08}.
In its focused form, ordered rewriting is closely related to the exponential-free fragment of \citeauthor{Simmons:CMU12}'s SLS framework.\autocite{Simmons:CMU12}

% Algebraically, string rewriting applies to free monoids.
% Implicit in \citeauthor{Lambek:AMM58}'s calculus for categorial grammars is a notion of rewriting that enriches the underlying algebraic structure to free \emph{residuated} monoids;
% \citeauthor{Lambek:AMM58}'s calculus was later extended to free residuated lattices\autocites{Lambek:SLIM61}{Kanazawa:LLI92}.
% \Cref{ch:ordered-rewriting} presents a version of this \emph{ordered rewriting} framework,
% % , which we call \emph{ordered rewriting}.
% deriving it from the ordered sequent calculus reviewed in \cref{ch:ordered-logic}.
% As we will see, the sequent calculus's left rules share a large amount of boilerplate -- only very little of each left rule is devoted to the primary task of decomposing the principal proposition.
% In response, we argue for refactoring the ordered sequent calculus, introducing a new judgment to decouple decomposition from the surrounding boilerplate.
% To the best of our knowledge, this refactoring of the sequent calculus left rules is a new way of justifying

% \Cref{ch:ordered-rewriting} closes by extending ordered rewriting with ideas from focusing\autocites{Andreoli:JLC92} to better control the atomicity of individual rewriting steps.
% The particular formulation, we use the pattern judgments of higher-order focusing\autocite{Zeilberger:POPL08}.


\newthought{Despite being models} of concurrency, both string rewriting and (focused) ordered rewriting lack an immediate notion of local execution.
Both frameworks are global, state-transformation models of concurrency that presume the existence of a central conductor that orchestrates the computation.
This kind of global rewriting, although reasonable for concurrent specifications, will not map well to the locally executing process implementations that a proof-reduction approach to concurrency will eventually suggest in \cref{part:proof-reduction} -- the gap is simply too large.

Strongly inspired by the process-as-formula view of linear logic\autocites{Miller:ELP92}{Cervesato+Scedrov:IC09}, the first part of \cref{ch:formula-as-process} responds to this dilemma by presenting a local, message-passing interpretation of focused ordered rewriting~\parencref{sec:formula-as-process:interpretation}:
non-atomic propositions are viewed as static process expressions; ordered contexts, as runtime process configurations; and atomic propositions, as messages.
Surprisingly, only two simple modifications of \cref{ch:ordered-rewriting}'s focused ordered rewriting framework are required to enable this message-passing interpretation.
% First, atomic propositions are partitioned in two: [...].
% Second, a syntactic restriction is placed on implications: $\atmR{a} \limp \n{B}$ and $\n{B} \pmir \atmL{a}$.

% : assigning a left-to-right or right-to-left direction to each atomic proposition, and placing a [...] syntactic restriction on implications.

With these modifications in place, a local interaction semantics for this message-passing interpretation of (focused) ordered rewriting can be given~\parencref{sec:formula-as-process:local-interaction}.

At this point, we also introduce coinductively defined negative propositions~\parencref{sec:formula-as-process:coinductive}, described with definitions of the form $\n{\defp{p}} \defd \n{A}$.
Traditionally, sub\-struc\-tural frameworks introduce unbounded behavior by way of replication and the $\bang$ exponential.\autocites{Polakow:CMU01}{Watkins+:CMU02}
However, surprisingly subtle interactions between replication and order make recursive definitions a much more suitable choice for bringing unbounded behavior to ordered rewriting in our setting.


% Both string rewriting and (focused) ordered rewriting are global, state-transformation descriptions of concurrency.
% However, in keeping with the above thesis statement, we would like to identify a fragment of (focused) ordered rewriting that acts more like a process calculus -- that is, a fragment that admits a local, \emph{formula-as-process} interpretation.
% \Cref{ch:formula-as-process}
% [...]
% Non-atomic propositions are viewed as static process expressions; ordered contexts, as runtime process configurations; and atomic propositions, as messages.
% Surprisingly few modifications of the focused ordered rewriting framework are required to enable this formula-as-process interpretation: assigning a left-to-right or right-to-left direction to each atom, and placing a [...] syntactic restriction on implications.


\newthought{To summarize} what we have so far, ordered rewriting has provided an explanation of concurrency in terms of proof construction and, looking ahead to our ultimate goal, the message-passing interpretation identifies a fragment of (focused) ordered rewriting that admits a local, process-like model of concurrency.
But how do the string rewriting specifications of \cref{ch:string-rewriting} fit into this puzzle?

The second part of \cref{ch:choreographies} answers that question by providing a procedure for \emph{choreographing} string rewriting specifications into the message-passing interpretation of ordered rewriting~\parencref{sec:choreographies:choreographies}.
The basic idea is that the programmer will assign a role to each of the string rewriting symbols -- a symbol becomes either an atom or a coinductively defined proposition.
Thus, under the message-passing interpretation, each symbol becomes a message or a coinductively defined process.
A choreography then consists of a role assignment together with definitions for each of its coinductively defined propositions.

Not all role assignments will lead to sensible choreographies, however.
A sensible choreography is one in which the coinductive definitions admit rewritings that, up to the role assignment, exactly match the string rewriting specification's axioms.
That is, a choreography is sensible if the role assignment serves as a bisimulation between the string rewriting specification and the message-passing choreography.%
\footnote[][-1.2\baselineskip]{This is the first appearance of a notion of bisimilarity in this document.
Bisimilarity in its various guises will be a recurring theme throughout this document.}
Depending on the particular role assignment, it is possible that no such set of definitions exists.

\Cref{sec:choreographies:informal} describes, informally, the conditions under which a given role assignment fails to yield a sensible choreography.
Then, in \cref{sec:choreographies:choreograph-formal}, we present a procedure for constructing a solution if one exists.
The algorithm is formulated as a judgment on role assignments and string rewriting specifications, and we prove that when a solution exists, the role assignment is indeed a bisimulation between the string rewriting specification and its choreography.

\Cref{ch:choreographies} closes by examining choreographies for the binary counter~\parencref{sec:formula-as-process:counters} and \acsp*{NFA}~\parencref{sec:formula-as-process:nfa}.
We show how to prove the end-to-end adequacy of these choreographies as a composition of the string rewriting specification's adequacy with the adequacy of the choreographing procedure.

In proving the adequacy of the \acs*{NFA} choreography, we find ourselves wishing for an equivalence on ordered contexts that is coarser than mere equality.
So \cref{ch:ordered-bisimilarity} develops a notion of bisimilarity for the message-passing ordered rewriting framework.
It is an observational equivalence in which atomic propositions are observable when they appear at the outside edges of an ordered context, but all other propositions are opaque.
Our ordered rewriting bisimilarity is related to \citeauthor{Deng+:MSCS16}'s contextual preorder for linear logic\autocite{Deng+:MSCS16}, although differing in its formulation (as well as the underlying logic and its structural rules).

The definition of ordered rewriting bisimilarity is suitable for directly proving that two contexts are \emph{not} bisimilar, but it is difficult to directly prove that two contexts \emph{are} bisimilar.
Therefore, \cref{sec:ordered-bisimilarity:labeled-bisim} presents a sound, and surprisingly complete, proof technique for ordered rewriting bisimilarity that is reminiscent of labeled bisimilarity from the $\pi$-calculus\autocite{Sangiorgi+Walker:CUP03} and \citeauthor{Deng+:MSCS16}'s simulation preorder\autocite{Deng+:MSCS16}.

\Cref{ch:ordered-bisimilarity} closes our discussion of bisimilarity and, more broadly, the proof-construction approach to concurrency with two examples of ordered rewriting bisimilarity in action: a proof that the \acs*{NFA} choreography preserves bisimilarity~\parencref{sec:ordered-bisimilarity:nfa}, and a proof that binary counters are bisimilar exactly when they have equal denotations~\parencref{sec:ordered-bisimilarity:counter}.

% \Cref{ch:choreographies} presents one  of the major contributions of this work: a procedure for \emph{choreographing} string rewriting specifications into formula-as-process ordered rewriting [...].
% To choreograph a string rewriting specification, [...].

% However, not all role assignments give rise to sensible choreographies.
% For instance, if both



% \Cref{part:proof-construction} closes with

% \clearpage
\subsection{Concurrency as proof reduction}

\Cref{part:proof-reduction} investigates a different proof-theoretic explanation of concurrency -- concurrency as proof reduction.

\Cref{ch:singleton-logic} begins this investigation by reviewing \emph{singleton logic}\autocites{Santocanale:FOSSACS02}{Fortier+Santocanale:CSL13}, an \emph{a}struc\-tural intuitionistic logic that exhibits many of the symmetries of classical logic by restricting sequents to have exactly one antecedent and one consequent.%
\footnote{\Citeauthor{Fortier+Santocanale:CSL13} were originally motivated by categorical semantic concerns, more so than symmetries.}
Singleton sequents are thus $\slseq{A |- C}$, as opposed to the sequents $\oseq{\octx |- C}$ found in ordered logic, for example.
\Cref{sec:singleton-logic:seq-calc} verifies that singleton logic's sequent calculus satisfies cut and identity elimination, which ensure that singleton logic has a well-defined proof-theoretic semantics.
% \fixnote{Because of the single-antecedent restriction, proof terms for singleton logic are variable-free and form a monoid with the $\jrule{CUT}$ rule as the monoid operation.}
It is quite surprising that such a severe restriction on the structure of sequents yields a well-defined logic that will also prove in \cref{ch:process-chains} to be computationally useful.

Of course, sequent calculi are not the only way to present logics, with natural deduction and axiomatic systems being two notable alternatives.
The \lcnamecref{ch:singleton-logic} continues in \cref{sec:singleton-logic:sax} by introducing a novel presentation of singleton logic -- its \emph{semi-axiomatic sequent calculus}.
As suggested by its name, the semi-axiomatic sequent calculus blends the sequent calculus with axiomatic features.
Its rules are the same as those of the sequent calculus, except that some rules\footnote{Specifically, all right rules for positive connectives and all left rules for negative connectives.} are replaced with axioms.
% For example, 
% \begin{equation*}
%   \infer[\rrule{\plus}_1]{\slseq{A |- B_1 \plus B_2}}{
%     \slseq{A |- B_1}}
%   \text{ is replaced by the axiom }
%   \infer[\rrule{\plus}_1']{\slseq{B_1 |- B_1 \plus B_2}}{}
% \end{equation*}
At first glance, making such replacements might seem unmotivated --
is it even possible to prove cut elimination for such a calculus?
% and perhaps [...].

No, it is not possible to eliminate \emph{all} cuts from semi-axiomatic proofs.
But, interestingly, the cuts that remain are nevertheless well-behaved: they are analytic cuts that satisfy the subformula property.
So, although cut elimination does not, strictly speaking, hold for the semi-axiomatic sequent calculus, a proof normalization result based on cut reduction does hold, as shown in \cref{sec:singleton-logic:sax:cutelim}.
Key to this normalization procedure are several novel \emph{associative cut reductions} and a slightly unusual justification for their termination.

The principal cut reductions that appear in semi-axiomatic proof normalization are also notable.
Because axioms hold such a prominent position in the calculus, none of these principal reductions carry over cuts -- only one of the cut's two constituent proofs contributing to the reduced result.
% the principal cut reductions that appear in semi-axiomatic proof normalization all eliminate their [...] cuts.
% No principal cut reduction ends 
In this way, the principal cut reductions are reminiscent of asynchronous message-passing communication, an observation which will later be crucial.

The essential ideas behind the semi-axiomatic calculus appear to be widely applicable, going beyond singleton logic.
Follow-up work with Pfenning and Pruiksma has extended the concept of semi-axiomatic sequent calculi to intuitionistic propositional logic, where the calculus yields an isomorphism with shared memory concurrency\autocite{DeYoung+:FSCD20}.
We further conjecture that semi-axiomatic sequent calculi exist for all intuitionistic logics with sequent calculi that admit cut elimination, including linear logic and ordered logic.



% \Cref{ch:singleton-logic} begins with a study of the sequent calculus for \emph{singleton logic}, an intuitionistic logic that exhibits many of the symmetries of classical logic by restricting sequents to have exactly one antecedent (and one consequent).
% That such a severe restriction on the structure of sequents yields a well-defined logic that will prove to be computationally useful is quite surprising.
% (An infinitary form of singleton logic was independently identified by \textcite{Santocanale:FOSSACS02} with Fortier\autocite{Fortier+Santocanale:CSL13}, motivated by categorical semantic concerns.)
% As we prove in \cref{??}, 

% Of course, sequent calculi are not the only way to present logics, with natural deduction and axiomatic systems being two notable alternatives.
% \Cref{ch:singleton-logic} continues by introducing a novel presentation of singleton logic -- its \emph{semi-axiomatic sequent calculus}.






\newthought{\Cref{ch:process-chains}}, following up on the observation that the semi-axiomatic sequent calculus's principal cut reductions have the same structure as asynchronous message-passing communication, develops a session-typed process calculus from singleton logic's semi-axiomatic sequent calculus.
% correspondence of semi-axiomatic proofs in singleton logic with session-typed processes that communicate by asynchronous message passing.
Under this Curry--Howard interpretation, propositions correspond to session types that describe a process's behavior; proofs, to processes arranged in a chain topology; and proof reduction, to asynchronous message-passing communication between processes~\parencref{sec:process-chains:interpretation}.

This is very closely related to \acs{SILL}, the Curry--Howard interpretation of the intuitionistic linear sequent calculus as a session-typed $\pi$-calculus discovered by \citeauthor{Caires+:MSCS16}\autocites{Caires+Pfenning:CONCUR10}{Caires+:TLDI12}{Caires+:MSCS16}, but with two key differences.
First, as previously alluded, singleton logic's single-antecedent restriction affects proof structure in such a way that the corresponding processes have a chain topology, as opposed to the tree topology of \ac{SILL} processes.%
\footnote{The idea of restricting processes to have a chain topology is also present in work by \textcite{Dezani-Ciancaglini+:PLACES14}; see \cref{ch:process-chains}.}
Second, and arguably more importantly, the proof reductions of the semi-axiomatic sequent calculus correspond to asynchronous message-passing communication, whereas \ac{SILL}, being based on a standard sequent calculus, most naturally corresponds to synchronous communication.%
\footnote{An earlier paper~\parencite{DeYoung+:CSL12} attempted to give an asynchronous interpretation of the intuitionistic linear sequent calculus, but, in hindsight, that work seems rather ad hoc and unsatisfactory when compared with the asynchronous interpretation of the semi-axiomatic sequent calculus.}

In \cref{sec:process-chains:coinductive}, coinductively defined types and processes are introduced to make unbounded computation possible.
This takes the calculus outside of a true isomorphism, with the coinductive definitions being extralogical.
But research by \textcites{Derakhshan+Pfenning:LMCS20}{Somayyajula+Pfenning:20} on logical justifications for behaviorally inductive and coinductive session types could be adapted here to restore a true isomorphism.

\Cref{ch:process-chains} closes with some example programs.
Process definitions are given for the binary counter~\parencref{sec:process-chains:binary-counter}; infinite-word sequential transducers~\parencref{sec:process-chains:transducer}, as a twist on the recurring \acs*{NFA} example; and Turing machines~\parencref{sec:process-chains:turing-machines}.
In particular, the Turing machine example shows that, when combined with coinductive definitions, the computational interpretation of even a logic as slight and seemingly feeble as singleton logic can be Turing-complete.
% In particular, the Turing machine example shows that the computational interpretation of singleton logic, together with coinductively defined processes, is Turing-complete.

\subsection[Relationship between proof construction and reduction]{Relationship between proof construction and proof reduction}

\Cref{part:comparison} studies the relationship between the two proof-theoretic characterizations of concurrency -- concurrency as proof construction, on the one hand, as exemplified by the (focused) ordered rewriting and choreographies of \cref{part:proof-construction}; and concurrency as proof reduction,  on the other hand, as exemplified by singleton logic's semi-axiomatic sequent calculus and the process chains of \cref{part:proof-reduction}.
\Cref{ch:correspond} begins by formalizing the message-passing view of ordered rewriting by defining an embedding of session-typed process chains into ordered rewriting~\parencref{sec:correspond:embed}.
This embedding serves as a bisimulation between process chains and ordered contexts -- between concurrency as proof reduction and concurrency as proof construction.

The embedding is quite natural in two respects.  
First, it elegantly maps process constructors to ordered logical connectives, with process composition corresponding to ordered conjunction, for example.
Second, as shown in \cref{sec:correspond:embed:examples}, when applied to the example processes from \cref{ch:process-chains}, the embedding results in the same coinductively defined propositions as those used as choreographies in \cref{ch:choreographies}.

Additionally, because the embedding is, syntactically speaking, an injective mapping, its left inverse provides a way to construct processes from a large subset of ordered propositions.
Thus, in \cref{sec:correspond:types}, we use the embedding to reverse-engineer a session type system for ordered rewriting in which well-typed processes correspond to well-typed propositions, and vice versa.

The left-invertible embedding and session type system for ordered rewriting allows us to write global, ordered rewriting specifications of concurrent systems and then extract local, process implementations from them, provided that the specifications are well-typed.
We can have all of the advantages of global specifications, together with all of the advantages of local implementations.

Thus, our results can be seen as a proof-theoretic analogue of multiparty session types.\autocite{Honda+:POPL08}
In multiparty session types, binary session types are generalized to conversations among several parties.
Conversations in their entirety are specified using global session types, which can then be projected to binary session types for each pair of participants; these projections are close to implementations.

Intuitively, global types for multiparty sessions serve the same purpose as our choreographies: both describe the conversation as a whole.
And, because both extract local information from a global description, the projection of local types from global types is related to our embedding of well-typed processes as choreographies.
Moreover, our framework has the advantage of generating implementations directly from choreographies, whereas the multiparty session type discipline generates only local types that programmers must then implement.

\subsection{Concluding thoughts}

\Cref{ch:correspond} provides final witness to the thesis stated earlier.
% session types do indeed bridge the proof-construction and proof-reduction notions of concurrency found in ordered and singleton logics, respectively.
At least for the well-typed fragment, proof construction and proof reduction are truly two sides of the same concurrent coin.

As described further in \cref{ch:conclusion}, this document raises several avenues for future work.
These include the obvious generalization of choreographies and the process embedding to proof-construction and proof-reduction notions of concurrency found in intuitionistic linear logic, an investigation of session-typed nondeterministic choice, a study of how the behaviorally inductive and coinductive types of \textfootcite{Derakhshan+Pfenning:LMCS20} and sized types of \textfootcite{Somayyajula+Pfenning:20} might apply to the proof-construction notion of concurrency, and an exploration of whether generative invariants\autocite{Simmons:CMU12} might relate to session types.

% In addition to the specific technical contributions outlined in the preceding \lcnamecrefs{sec:introduction:overview}, this document contributes one further piece of evidence in favor of beginning \fixnote{include this? where?}
% I have learned to begin with examples that are very simple -- even ones that seem ridiculously so.
% The simplification from linear logic to ordered and singleton logics was critical to developing the key ideas of choreography and semi-axiomatic sequent calculus.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
