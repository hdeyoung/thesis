\chapter{Introduction}\label{ch:introduction}

With the increasingly complex, distributed nature of today's software systems, concurrency is ubiquitous.
Concurrency facilitates distributed computation by structuring systems as nondeterministic compositions of simpler subsystems.
But, being nondeterministic, concurrent systems are notoriously difficult to get right: 
subtle races and deadlocks can occur in even the most rigorously tested of systems.

At the same time, decades of research into connections between proof theory and programming languages -- beginning with \citeauthor{Curry:PNAS34}'s observation that simplification of axiomatic proofs corresponds to a form of computation based on combinatory reduction\autocite{Curry:PNAS34}, and notably continuing with \citeauthor{Howard:69}'s discovery of an isomorphism between intuitionistic natural deduction and the simply-typed $\lambda$-calculus\autocite{Howard:69} -- have firmly established the principle of \emph{computation as deduction} as the gold standard for clear, expressive, and provably correct programs.
Computation-as-deduction interpretations of intuitionistic logic, for example, are the foundations for both the typed functional\autocite{Martin-Lof:LMPS80} and logic\autocites{Miller+:PAL91}{Andreoli:JLC92} programming paradigms.

Since \citeauthor{Girard:TCS87} introduced linear logic\autocite{Girard:TCS87} and suggested the possibility of connections with concurrency, [...].
Along two different proof-theoretic paths: \emph{concurrency as proof reduction} and \emph{concurrency as proof construction}.

Under a concurrency-as-proof-reduction view, processes are mapped to linear sequent proofs or proof nets and cut elimination corresponds to concurrent, message-passing communication.


Under a concurrency-as-proof-construction view, the search for a proof, according to a fixed strategy, forms the basis of computation, with the permutability of inference rules as the source of concurrency.
This proof construction view is perhaps best encapsulated by the \emph{process-as-formula} encoding, in which process constructors correspond to linear logical connectives\autocite{Miller:ELP92}.
 

Each of these two approaches has its own strengths and weaknesses.
The proof-reduction approach excels at
% is particularly good when it comes to 
implementation.
Based on \citeauthor{??}'s isomorphism, proofs are directly process implementations. 
Because cut elimination procedure [...], the proof-reduction approach lends itself more naturally to synchronous, not asynchronous, communication.
Properties of cut elimination ensure that the proof-reduction approach also enjoys session-type preservation and progress theorems -- well-typed processes will never deadlock.\footnote{But can livelock, unless coinductive types are used.}

On the other hand, the proof-construction approach is better suited to the task of specifying the behavior of concurrent systems.
It gives a more global description of the system by focusing on the interactions between processes, without prescribing how those interactions should occur.
Because computation is captured by the search for a proof, the proof-construction approach lends itself more naturally to \emph{a}synchronous communication.

To gain the strengths of both approaches without the weaknesses of either, we would like to identify a kind of intersection between concurrency as proof reduction and concurrency as proof-construction.
We want to identify fragments of proof reduction and proof construction that can be put in bijective correspondence.
\begin{quotation}
  \normalsize
  Thesis statement.
  \itshape [...] form a bridge between distinct notions of concurrency in computational interpretations of ordered logic based on proof construction, on one hand, and proof reduction, on the other hand.
\end{quotation}


\section{Overview}

\Cref{part:preliminaries} reviews some necessary background information: definitions of finite automata~\parencref{ch:finite-automata} and a sequent calculus presentation of ordered logic~\parencref{ch:ordered-logic}.
The reader who has some familiarity with these topics should feel free to skim or skip these \lcnamecrefs{ch:finite-automata}, returning to them only as needed.

\begin{figure}[tp]
  \centering
  \begin{tikzpicture}
    \node [draw, align=center] (sr)
      {\emph{String rewriting specifications}\\
       \emph{of concurrent systems}\\
       (\Cref{ch:string-rewriting})};

    \node [draw, align=center, right=of sr] (or)
      {\emph{Ordered rewriting}\\
       (\Cref{ch:ordered-rewriting})};

    \node [draw, align=center, right=of or] (fp)
      {\emph{Formula-as-process ordered rewriting}\\
       (\Cref{ch:formula-as-process})};

    \draw (sr) edge[<->, bend right=20, edge node={node [below, align=center] {\emph{Choreographies}\\(\Cref{ch:choreographies})}}] (fp);

    \node [draw, align=center, below=of or] (pc)
      {\emph{Process chains}\\(\Cref{ch:process-chains})};
  \end{tikzpicture}
  \caption{A summary of this document}
  \label{fig:introduction:summary}
\end{figure}

% \clearpage
\subsection{Concurrency as proof construction}

\Cref{part:proof-construction} then delves into a proof-construction approach to concurrency, beginning in \cref{ch:string-rewriting} with a review of a string rewriting framework for specifying the dynamics of concurrent systems.
Specifically, string rewriting can be used for systems whose components are arranged into a linear topology and have a monoidal structure.
% Concurrency in these string rewriting specifications arises by treating the interleaving of independent rewriting steps, an equivalence sometimes known as concurrent equality\autocite{Watkins+:CMU02}.
Because 
% In string rewriting,
disjoint segments of a string may be rewritten independently,
% and
concurrency arises when the various interleavings of these independent rewritings are treated as equivalent.
String rewriting is an instance\fixnote{restricted instance, special case, generalization?} of multiset rewriting, so these ideas are not new, but [...].\autocite{Meseguer:TCS92}
% Using string rewriting in this way is 
% % This application of string rewriting can be seen as 
% a restricted instance\fixnote{special case/generalization?} of using multiset rewriting for concurrent specification.\autocite{Meseguer:TCS92}
\Cref{ch:string-rewriting} closes by introducing
% In \cref{sec:string-rewriting:??,sec:string-rewriting:??}, we introduce
specifications for two systems that will be used as running examples throughout this document: \aclp*{NFA}~\parencref{sec:string-rewriting:nfa} and binary counters~\parencref{sec:string-rewriting:binary-counter}.

\Cref{part:proof-construction} purports to give a proof-construction approach to concurrency, but string rewriting, while indeed a model of\fixnote{framework for?} concurrency, is not obviously connected to proof construction.
% superficially appears to be unconnected to proof construction.
For that, \cref{ch:ordered-rewriting} turns our attention toward the Lambek calculus and ordered logic\fixnote{rewriting / sequent calculus?}.

Implicit in \citeauthor{Lambek:AMM58}'s calculus for categorial grammars is a notion of rewriting for free residuated monoids.%
\footnote{\Citeauthor{Lambek:AMM58}'s calculus was later extended to free residuated lattices~\parencites{Lambek:SLIM61}{Kanazawa:LLI92}.}
\Cref{ch:ordered-rewriting} presents \emph{ordered rewriting}, a related rewriting framework for free residuated lattices, which we will derive from the ordered sequent calculus.
% [...] that will be derived from the ordered sequent calculus reviewed in \cref{ch:ordered-logic}.
As we will see, the sequent calculus's left rules share a large amount of boilerplate -- only very little of each left rule is devoted to the primary task of decomposing the principal proposition.
In response, we argue for a refactoring of the ordered sequent calculus, introducing a new judgment to decouple decomposition from the surrounding boilerplate.
% , and we then obtain ordered rewriting as a decomposition-centered fragment of the refactored calculus.
Ordered rewriting is then exactly
% falls out as a
the decomposition-centered fragment of the refactored sequent calculus.
To the best of our knowledge, our refactoring of the sequent calculus left rules appears to be a new way of deriving rewriting from existing proof theory.
% logically.

As in string rewriting, ordered rewriting [...] disjoint segments of the ordered context to be rewritten independently, and concurrency arises when the different interleavings of these independent rewritings are treated indistinguishably.
And so ordered rewriting is the proof-construction characterization of concurrecy that we were looking for.

\Cref{ch:ordered-rewriting} closes by extending ordered rewriting with ideas from focusing\autocites{Andreoli:JLC92} to better control the atomicity of individual rewriting steps.
The particular formulation we choose is \citeauthor{Zeilberger:POPL08}'s higher-order focusing\autocite{Zeilberger:POPL08}.
In its focused form, ordered rewriting is closely related to the exponential-free fragment of \citeauthor{Simmons:CMU12}'s SLS framework.\autocite{Simmons:CMU12}


% Algebraically, string rewriting applies to free monoids.
% Implicit in \citeauthor{Lambek:AMM58}'s calculus for categorial grammars is a notion of rewriting that enriches the underlying algebraic structure to free \emph{residuated} monoids;
% \citeauthor{Lambek:AMM58}'s calculus was later extended to free residuated lattices\autocites{Lambek:SLIM61}{Kanazawa:LLI92}.
% \Cref{ch:ordered-rewriting} presents a version of this \emph{ordered rewriting} framework,
% % , which we call \emph{ordered rewriting}.
% deriving it from the ordered sequent calculus reviewed in \cref{ch:ordered-logic}.
% As we will see, the sequent calculus's left rules share a large amount of boilerplate -- only very little of each left rule is devoted to the primary task of decomposing the principal proposition.
% In response, we argue for refactoring the ordered sequent calculus, introducing a new judgment to decouple decomposition from the surrounding boilerplate.
% To the best of our knowledge, this refactoring of the sequent calculus left rules is a new way of justifying

% \Cref{ch:ordered-rewriting} closes by extending ordered rewriting with ideas from focusing\autocites{Andreoli:JLC92} to better control the atomicity of individual rewriting steps.
% The particular formulation, we use the pattern judgments of higher-order focusing\autocite{Zeilberger:POPL08}.


\newthought{Despite being models} of concurrency, both string rewiting and (focused) ordered rewriting lack an immediate notion of local execution.
Both frameworks are global, state-transformation models [of concurrency] that presume the existence of a central conductor that orchestrates the computation.
Global rewriting, although reasonable for concurrent specifications, will not map well to the locally executing process implementations that a proof-reduction approach to concurrency will eventually suggest in \cref{part:proof-reduction} -- the gap is simply too large.

Strongly inspired by the process-as-formula view of linear logic\autocites{Miller:ELP92}{Cervesato+Scedrov:IC09}, \cref{ch:formula-as-process} responds to this dilemma by presenting a local, message-passing\fixnote{\emph{formula-as-process}?} interpretation of focused ordered rewriting:
non-atomic propositions are viewed as static process expressions; ordered contexts, as runtime process configurations; and atomic propositions, as messages.
Surprisingly, only two simple modifications of \cref{ch:ordered-rewriting}'s focused ordered rewriting framework are required to enable this message-passing interpretation.
% First, atomic propositions are partitioned in two: [...].
% Second, a syntactic restriction is placed on implications: $\atmR{a} \limp \n{B}$ and $\n{B} \pmir \atmL{a}$.

% : assigning a left-to-right or right-to-left direction to each atomic proposition, and placing a [...] syntactic restriction on implications.

[local interaction semantics]

At this point, we also introduce coinductively defined negative propositions~\parencref{sec:formula-as-process:??}, described with definitions $\n{\defp{p}} \defd \n{A}$.
Traditionally, unbounded behavior in substructural frameworks\fixnote{wc?} is introduced by way of replication and its $\bang$ exponential.
However, surprisingly subtle interactions between replication and order make recursive defintions a much more suitable choice for bringing unbounded behavior to ordered rewriting.


% Both string rewriting and (focused) ordered rewriting are global, state-transformation descriptions of concurrency.
% However, in keeping with the above thesis statement, we would like to identify a fragment of (focused) ordered rewriting that acts more like a process calculus -- that is, a fragment that admits a local, \emph{formula-as-process} interpretation.
% \Cref{ch:formula-as-process}
% [...]
% Non-atomic propositions are viewed as static process expressions; ordered contexts, as runtime process configurations; and atomic propositions, as messages.
% Surprisingly few modifications of the focused ordered rewriting framework are required to enable this formula-as-process interpretation: assigning a left-to-right or right-to-left direction to each atom, and placing a [...] syntactic restriction on implications.


\newthought{To summarize} what we have so far, (focused) ordered rewriting has provided an explanation of concurrency as proof construction and, looking ahead to our ultimate goal, the message-passing interpretation identifies a fragment of focused ordered rewriting that admits a local, process-like model of concurrency.
But how do the string rewriting specifications of \cref{ch:string-rewriting} fit into this puzzle?

\Cref{ch:choreographies}


\Cref{ch:choreographies} presents one of the major contributions of this work: a procedure for \emph{choreographing} string rewriting specifications into formula-as-process ordered rewriting [...].
To choreograph a string rewriting specification, [...].

However, not all role assignments give rise to sensible choreographies.
For instance, if both


\Cref{part:proof-construction} closes with


\subsection{Concurrency as proof reduction}

\newthought{\Cref{part:proof-reduction} offers} a different proof-theoretic explanation of concurrency -- concurrency as proof reduction.

\Cref{ch:singleton-logic} presents \emph{singleton logic}, a substructural intuitionistic logic that exhibits many of the symmetries of classical logic by restricting sequents to have exactly one antecedent\footnote{And one consequent.}.
Singleton sequents are thus $\slseq{A |- C}$, as opposed to the sequents $\oseq{\octx |- C}$ found in ordered logic, for example.
(An infinitary variant of singleton logic was independently identified by \citeauthor{Santocanale:FOSSACS02} with Fortier\autocites{Santocanale:FOSSACS02}{Fortier+Santocanale:CSL13}, motivated by categorical semantic concerns.)
\Cref{sec:??} verifies that singleton logic's sequent calculus satisfies cut and identity elimination, which ensure that singleton logic has a well-defined proof-theoretic semantics.

Because of the single-antecedent restriction, proof terms for singleton logic are variable-free and form a monoid with the $\jrule{CUT}$ rule as the monoid operation.
That such a severe restriction on the structure of sequents yields a well-defined logic that will prove to be computationally useful is quite surprising.

Of course, sequent calculi are not the only way to present logics, with natural deduction and axiomatic systems being two notable alternatives.
\Cref{ch:singleton-logic} continues by introducing a novel presentation of singleton logic -- its \emph{semi-axiomatic sequent calculus}.
As suggested by its name, the semi-axiomatic sequent calculus blends the sequent calculus with axiomatic features.
Its rules are the same as those of the sequent calculus, except that all right rules for positive connectives and all left rules for negative connectives are replaced with axioms.
For example, 
\begin{equation*}
  \infer[\rrule{\plus}_1]{\slseq{A |- B_1 \plus B_2}}{
    \slseq{A |- B_1}}
  \text{ is replaced by the axiom }
  \infer[\rrule{\plus}_1']{\slseq{B_1 |- B_1 \plus B_2}}{}
\end{equation*}
At first glance, these replacements might seem unmotivated.
Is it even possible to prove cut elimination for such a system?
% and perhaps [...].

No, it is not possible to eliminate \emph{all} cuts from semi-axiomatic proofs.
But, interestingly, the cuts that remain are nevertheless well-behaved: they are analytic cuts that satisfy the subformula property.
So, although cut elimination does not, strictly speaking, hold for the semi-axiomatic sequent calculus, a proof normalization result does.
Key to this normalization procedure 

The essential ideas behind the semi-axiomatic calculus appear to be widely applicable.
Follow-up work with Pfenning and Pruiksma has extended the concept of semi-axiomatic sequent calculi to intuitionistic propositional logic\autocite{DeYoung+:FSCD20}, and we conjecture that semi-axiomatic sequent calculi exist for all intuitionistic logics with cut-free\fixnote{??} sequent calculi, including linear logic and ordered logic.




% \Cref{ch:singleton-logic} begins with a study of the sequent calculus for \emph{singleton logic}, an intuitionistic logic that exhibits many of the symmetries of classical logic by restricting sequents to have exactly one antecedent (and one consequent).
% That such a severe restriction on the structure of sequents yields a well-defined logic that will prove to be computationally useful is quite surprising.
% (An infinitary form of singleton logic was independently identified by \textcite{Santocanale:FOSSACS02} with Fortier\autocite{Fortier+Santocanale:CSL13}, motivated by categorical semantic concerns.)
% As we prove in \cref{??}, 

% Of course, sequent calculi are not the only way to present logics, with natural deduction and axiomatic systems being two notable alternatives.
% \Cref{ch:singleton-logic} continues by introducing a novel presentation of singleton logic -- its \emph{semi-axiomatic sequent calculus}.


\Cref{ch:process-chains} develops a Curry--Howard interpretation of singleton logic's semi-axiomatic sequent calculus.
% correspondence of semi-axiomatic proofs in singleton logic with session-typed processes that communicate by asynchronous message passing.
Under this interpretation, propositions correspond to session types that describe a process's behavior; proofs, to processes arranged in a linear topology; and proof reduction, to asynchrnous message-passing communication between processes.
This is closely related to \citeauthor{Caires+:MSCS??}'s Curry--Howard interpretation of the intuitionistic linear sequent calculus as a session-typed $\pi$-calculus, but with two key differences.
First, the effect that singleton logic's single-antecedent restriction has on proof structure means that the corresponding processes have a linear topology, as opposed to the tree topology of SILL processes.
Second, and arguably more important, the proof reductions of the semi-axiomatic sequent calculus correspond to asynchronous communication.


\newthought{\Cref{part:comparison} studies} the relationship between these two proof-theoretic characterizations of concurrency -- concurrency as proof construction, on the one hand, as exemplified by the (focused) ordered rewriting and choreographies of \cref{part:proof-construction}; and concurrency as proof reduction, on the other hand, as exemplified by singleton logic's semi-axiomatic sequent calculus and the process chains of \cref{part:proof-reduction}.
\Cref{ch:??} begins by formalizing the formula-as-process view of ordered rewriting by defining an embedding of session-typed process chains into ordered rewriting.
We prove that this embedding serves as a bisimulation between process chains and ordered contexts\fixnote{propositions?} -- between concurrency as proof reduction and concurrency as proof construction.
The embedded is natural [...].



\fixnote{Simple example throughout introduction?}

\begin{itemize}
\item
  Concurrency is notoriously difficult to get right.
  \begin{itemize}[nosep]
  \item For functional programming, Curry--Howard application of proof theory is the gold standard.
  \item Since Girard, efforts to explain concurrency using proof theory.
  \end{itemize}

\item 
  Two proof-theoretic ways to characterize concurrency:
  \begin{itemize}[nosep]
  \item proof construction as concurrency
  \item proof reduction as concurrency
  \end{itemize}
  Each has its own strengths and weaknesses.
  Relatively little (none?) study of the relationship between these characterizations.

\item
  Proof reduction $\cong$ session-typed processes (SILL).
  \begin{itemize}[nosep]
  \item Strengths: behavioral types; preservation and progress; process implementation;
                   logical extensions suggest new features
  \item Weaknesses: very local description (cf.\ local and global session types);
                    synchronous communication; general recursion needed for long-running
                    processes, but not obvious how to do that in a logically justified way
                    (inductive types Martin-Lof)
  \end{itemize}
  Good for implementation.

\item
  Proof construction $\cong$ process-as-formula (Miller et al.),
                             multiset rewriting (Cervesato and Scedrov).
  \begin{itemize}[nosep]
  \item Strengths: more global description (though slightly lower level than global types?);
                   \emph{a}synchronous communication; general recursion is easy here
  \item Weaknesses: untyped; can deadlock; less obviously extensible;
                    specification, but not implementation
  \end{itemize}
  Good for specification.

\item
  Where do the proof reduction and proof construction characterizations intersect?
  \begin{itemize}[nosep]
  \item Intersection will have strengths of both, with weaknesses of neither.
  \item On the intersection, a proof-construction specification can be \enquote{projected} to a proof-reduction implementation.
  \end{itemize}

\item
  To focus our attention on the essential differences between proof reduction and proof construction, we limit our investigation to chain topologies, not the more general tree topologies of SILL.
  \begin{itemize}[nosep]
  \item Chain topologies let us treat channels namelessly, which turns out to lift a large notational burden.
  \item In both the proof reduction and proof construction chacterizations, there are logical justifications for chain topologies.
  \item We conjecture that our results can be straightforwardly generalized to tree topologies, with a large notational overhead, but no conceptual difficulties.
  \item Propositional Ordered logic becomes first-order linear logic; singleton logic becomes propositional linear logic
  \end{itemize}

\item
  Outline of chapters and discussion of contributions

\item
  Abstract rewriting, specifically string rewriting, as a framework for specifying the dynamics of concurrent systems.
  \begin{itemize}[nosep]
  \item Systems with components arranged in a linear topology with a monoidal structure 
  \item Special case of multiset rewriting (Cervesato and Scedrov), so not a contribution of this work
  \item Introduce running examples for the first time: NFAs and binary counters.
    (A review of finite automata can be found in \cref{ch:finite-automata}.)
  \end{itemize}

\item
  Ordered rewriting generalizes string rewriting to a richer set of \enquote{connectives} -- free residuated lattice, not just a free monoid
  \begin{itemize}[nosep]
  \item Based on the ordered sequent calculus of \cref{ch:ordered-logic}
  \item Ordered rewriting justified by refactoring the sequent calculus left rules to eliminate boilerplate.
    \begin{itemize}[nosep]
    \item Rewriting is obtained as a fragment of the refactored calculus
    \item This derivation appears to be an auxiliary contribution of this work
    \end{itemize}
  \item Roughly a special case of (Cervesato and Scedrov)
  \item \emph{Focused} ordered rewriting to control the atomicity of individual rewriting steps
  \item This is roughly what would be needed to combine OLF with CLF.
  \end{itemize}

\item 
  Both string rewriting and (focused) ordered rewriting are global, state transformation systems.
  \begin{itemize}[nosep]
  \item Our goal is to identify a fragment (intersection) that acts like a process calculus -- a local, formula-as-process interpretation.
    \begin{itemize}[nosep]
    \item Propositions as process expressions, contexts as runtime process configurations, atoms as messages 
    \item Surprisingly few changes needed: atom directions and syntactic restriction placed on implications
    \item Not really a contribution?  (Miller et al.)
    \end{itemize}
  \item coinductively defined propositions, not replication, for unbounded rewriting 
 \begin{itemize}[nosep]
    \item Surprisingly subtle interactions between replication and order -- recursive definitions are more suitable 
    \end{itemize}
  \item Major contribution of this chapter: proceedure for choreographing string rewriting specifications into formula-as-process ordered rewriting
    \begin{itemize}[nosep]
    \item Role assignment to each symbol -- message or process
    \item Not all role assignments lead to sensible choreographies
    \item String rewriting axioms used as an evaluation\fixnote{word choice?} -- specification and choreography must be bisimilar.
      [First appearance of a bisimiarity.  States' structures are observable]
    \item Informal description, then formal description 
    \end{itemize}
  \item Choreographies for binary counters and NFAs 
    \begin{itemize}[nosep]
    \item End-to-end adequacy of choreography as a composition of specification's adequacy with bisimilarity of choreography and specification
    \item NFA example leads to a desire for an equivalence coarser than equality 
    \end{itemize}
  \end{itemize}

\item A notion of bisimilarity for ordered rewriting
  \begin{itemize}[nosep]
  \item observational equivalence: propositions/processes are opaque; atoms/messages are observable 
    \begin{itemize}[nosep]
    \item very much dependent on formula-as-process interpretation
    \end{itemize}
  \item Contribution?  Related to (Deng et al.) but our formulation is different
  \item Labeled bisimilarity as a sound (and complete!) proof technique for rewriting bisimilarity
  \item Examples of bisimilarity: NFA encoding preserves bisimilarity; bisimilarity of binary counters coincides with equal denotations 
  \end{itemize}

\item That closes proof construction.  Now for proof reduction.

\item Singleton logic
  \begin{itemize}[nosep]
  \item Independently identified by (Fortier and Santocanale)
  \item A fragment based on a single antecedent restriction (closely related to additive linear/ordered logic) 
    \begin{itemize}[nosep]
    \item Restricted form of cut will lead to chain topology
    \end{itemize}
  \item Semi-axiomatic sequent calculus (contribution)
    \begin{itemize}[nosep]
    \item Replaces positive right rules and negative left rules with axioms (thematically related to the refactoring of the ordered sequent calculus)
    \item Full cut elimination is not possible, but \enquote{non-analytic} cut elimination is 
    \item Novel \enquote{associative} cut reductions are key 
    \item Principal cut reductions match asynchronous communication
    \item Applies as a general principle (FSCD paper)
    \end{itemize}
  \end{itemize}

\item Session-typed process chains
  \begin{itemize}[nosep]
  \item Curry--Howard interpretation of singleton logic's semi-axiomatic sequent calculus
  \item Related to SILL, with some differences
    \begin{itemize}[nosep]
    \item Asynchronous communication based on cut elimination
    \item Chain topology because of single-antecedent restriction
    \end{itemize}
  \item Coinductively defined types and process expressions for unbounded computation
  \item Examples: binary counter (again); infinite-word sequential transducers (twist on NFAs); Turing machines (composable)
    \begin{itemize}[nosep]
    \item Computational interpretation of singleton logic (with coinductively defined process expressions) is Turing-complete
    \end{itemize}
  \end{itemize}

\item That closes proof reduction.

\item Relationship between proof construction and proof reduction (fragment that can be put into bijection)
  \begin{itemize}[nosep]
  \item Make formula-as-process view of ordered rewriting formal by defining an embedding of session-typed processes into ordered rewriting
    \begin{itemize}[nosep]
    \item Mapping is a bisimulation between proof reduction and proof construction
    \item Process constructors map to logical connectives
    \item Embedding of the example process expressions yields the same coinductively defined propositions as used in the choreographies
    \item Injective mapping (syntactically speaking), so also functions as a way to construct processes from (a large subset of) ordered propositions
    \end{itemize}
  \item Use this embedding to reverse engineer a session type system for ordered rewriting
    \begin{itemize}[nosep]
    \item Well-typed processes correspond to well-typed propositions and vice versa
    \end{itemize}
  \end{itemize}

\item Future work sorted into relevant sections
\end{itemize}

 






























































\subsection{}

\begin{itemize}
\item Computation as deduction: clear, expressive, and provably correct programs
  \begin{itemize}
  \item Examples of sucess stories
  \item Can it be applied to concurrency?
  \end{itemize}
\item Proof constuction and proof reduction views of con currency
  \begin{itemize}
  \item Proof construction: good for specifications 
  \item Proof reduction: good for implementions 
  \end{itemize}
\item Thesis statement: Session types bridge these two views
\item Ordered logic as a proving ground 
  \begin{itemize}
  \item Ordered rewriting for proof construction
  \item Singleton logic (purely additive fragment of ordered logic) for proof reduction
  \end{itemize}
\item Ordered rewriting (chapter 4) for specifications
  \begin{itemize}
  \item DFAs and NFAs 
  \item Binary counters
  \end{itemize}
\item Refinement of ordered rewriting for choreographies (chapter 5)
  \begin{itemize}
  \item Recursive definitions as processes; atoms as messages 
  \item Untyped (mostly, except for directions)
  \item Rewriting bisimilarity for observational equivalence
    \begin{itemize}
    \item Examples
    \end{itemize}
  \end{itemize}
\item Singleton logic and its semi-axiomatic calculus (chapter 6)
\item 
\end{itemize}


Concurrent systems are notoriously difficult to get right.

Beginning with Curry's observation that Hilbert [...] corresponds to a form of computation based on combinatory reduction\autocite{??}, and continuing with Howard's discovery of an isomorphism between [Gentzen's] intuitionistic natural deduction and Church's simply-typed $\lambda$-calculus, computation-as-deduction has been the gold standard for clear, expressive, and provably correct programs.

Computation-as-deduction can be divided into two classes: proof-search-as-computation and proof-reduction-as-computation.
The former provides a logically grounded basis for the backward- and forward-chaining logic programming paradigms, whereas the latter is the foundation for the functional programming paradigm.

Logically grounded concurrent computation 

More recently, a proof-reduction description of concurrency has been discovered by \textcite{??} with \textcite{??}.
In this isomorphism, linear propositions correspond to session types; sequent proofs, to session-typed processes; and cut reduction, to synchronous message-passing communication.

This thesis seeks to bring these two apparently divergent views of concurrency together.
Is there a class of specifications for which well-typed implementations can automatically be extracted?

Thesis statement: Session types form the bridge. 


\section{Proposal introduction}

With the increasingly complex, distributed nature of today's software systems, concurrency is ubiquitous.
Concurrency facilitates distributed computation by structuring systems as nondeterministic compositions of simpler subsystems.
But, concomitant with nondeterminism, concurrent systems are notoriously tricky to get right:
subtle races and deadlocks can occur even in the most rigorously tested of systems.

At the same time, decades of research into connections between proof theory and programming languages have firmly established the principle of \vocab{computation as deduction} as the gold standard [framework] for clear, expressive, and provably correct programs.
Most generally, intuitionistic logic is the bedrock for both the typed functional\autocite{Martin-Lof:LMPS80} and logic programming\autocites{Miller+:PAL91}{Andreoli:JLC92}\fixnote{check refs?} paradigms.
In more specific [...]
Examples abound: lax logic for effectful computation\autocite{Benton:JFP98}, temporal logic for functional reactive programming\autocite{Jeffrey:PLPV12}, and linear logic for graph-based algorithms\autocite{Cruz+:ICLP14}, to name just a few.

Can a computation-as-deduction approach make it similarly easier to clearly and concisely specify, as well as correctly implement, concurrent programs?

\subsection{}

The principle of computation as deduction comes in two flavors: \vocab{proof construction as computation} and \vocab{proof reduction as computation}.
Under a proof-construction-as-computation view, the search for a proof, according to a fixed strategy, forms the basis of computation; it is the foundation for logic programming\autocites{Miller+:PAL91}{Andreoli:JLC92}.
The proof-reduction-as-computation view, on the other hand, revolves around a correspondence, known as the Curry--Howard Isomorphism\autocite{Curry:??}{Howard:??}, between propositions and types, proofs and programs, and proof simplification, or reduction, and program evaluation;
it is the foundation for typed functional programming\autocite{Martin-Lof:LMPS80}.

Both the proof-construction and proof-reduction approaches have been successfully applied to concurrent programming, originally stemming from \citeauthor{Girard:TCS87}'s suggestion of connections between linear logic and concurrency\autocite{Girard:TCS87}.
In the proof-construction vein, \acroifusedTF{CLF}{\ac{CLF}\autocite{Watkins+:CMU02}}{the \acf{CLF}\autocite{Watkins+:CMU02}} treats the permutability of inference rules as the source of concurrency.
\Ac{CLF} has been used to specify a variety of concurrent systems, ranging from the $\pi$-calculus to security protocols and even emergent story narratives\autocites{Cervesato+Scedrov:IC09}{Martens+:LPNMR13}.\fixnote{check refs}
Although these same concurrent systems can be simulated according to their \ac{CLF} specifications by the Lollimon\autocite{Lopez+:PPDP05} and Celf\autocite{Schack-Nielsen:ITU11} logic programming engines, the programs ultimately remain specifications, not actual \emph{decentralized} implementations.

Taking the other, proof-reduction tack, \textcite{Abramsky:TCS93}, \textcite{Bellin+Scott:TCS94}, and later \textcite{Caires+Pfenning:CONCUR10} with Toninho\autocites{Caires+:TLDI12}{Caires+:MSCS13} have given correspondences between sequent calculus proofs or proof nets in linear logic and processes; between cut elimination and concurrent process execution.
Moreover, in \citeauthor{Caires+:MSCS13}'s work, the correspondence is a true Curry--Howard isomorphism in that intuitionistic linear propositions are also types -- \vocab{session types}\autocite{Honda:CONCUR93} that describe the interaction protocol to which a process adheres.
Unlike proof construction, the proof-reduction approach yields actual decentralized implementations with independent threads of control\autocites{Toninho+:ESOP13}{Griffith+Pfenning:14}.

In spite of their common basis in linear logic, these proof-construction and proof-reduction approaches to concurrent computation appear at first glance to be strikingly disparate.
They have different dynamics; they offer different guarantees (session fidelity, behavioral type preservation, and deadlock freedom for the proof-reduction approach, but only non-behavioral type preservaton for the proof-construction approach); and, perhaps most importantly, they serve very different roles in programming practice.
Proof construction is better suited to system specification and reasoning, whereas proof reduction is better suited to implementation.

To reduce the possibiity of error when building an implementation from a specification, we would like to minimize the gap between the two.
Despite the apparent disparity between proof construction and proof reduction, is there a class of concurrent specifications from which decentralized concurrent implementations can be automatically extracted?
Stated differently, is there perhaps (some fragment of) a substructural logic in which the computational natures of proof construction and proof reduction coincide?

\subsection{}

The thesis is that, yes, we can indeed have our cake and eat it too:
\begin{quotation}
\normalsize\noindent
Thesis statement.
\itshape Session types form a bridge between distinct notions of concurrency in computational interpretations of ordered logic based on proof construction, on one hand, and proof reduction, on the other hand.
\end{quotation}

\Cref{part:preliminaries} reviews some necessary background information: definitions of nondeterministic and \aclp*{DFA}~\parencref{ch:automata}, and a sequent calculus presentation of ordered logic~\parencref{ch:ordered-logic}.
The reader should feel free to skim or skip these \lcnamecrefs{ch:automata} and return to them 

\newthought{\Cref{part:proof-construction} then delves} into a proof-construction approach to concurrency, beginning with a review of a framework for string rewriting~\parencref{ch:string-rewriting}.
Because disjoint segments of a string may be rewritten independently, string rewriting can be used to specify concurrent systems that have a linear topology.
The \lcnamecref{ch:string-rewriting} concludes with two extended examples of string rewriting specifications:
\aclp*{NFA}\footnote{And, as a special case, deterministic ones, too.}
and binary representations of natural numbers equipped with increment and decrement operations.
These will serve as running examples throughout this document.

Despite being concurrent, string rewriting specifications lack an immediate notion of local execution.
String rewriting presumes the existence of a central conductor that orchestrates the computation, rewriting the string globally.
Global rewriting, although reasonable for concurrent specifications, will not map well to locally executing process implementations that a proof-reduction approach to concurrency suggests -- the gap is simply too large.

Toward this end, \cref{ch:ordered-rewriting} presents an extension of the Lambek calculus\autocite{Lambek:??} in which string rewriting specifications may be refined into \vocab{choreographies}.
Inspired by the process-as-formula view of linear logic\autocites{Miller:??}{Cervesato+Scedrov:IC09}, choreographies exist at a slightly lower level of abstraction than string rewriting specifications in that they begin to introduce a message-passing character.
A choreography partitions a string rewriting specification's symbols into 

Having introduced a message-passing character and stronger notion of process identity, we can then ask when two processes are observationally equivalent.
\Cref{ch:ordered-bisimilarity} develops a notion of bisimilarity for ordered propositions, where the uninterpreted atoms are the only observables.

\subsection{Contributions}

The contributions of this thesis can be viewed from several perspectives.
\begin{itemize}
\item This work can be seen as a proof-theoretic [logical] reconstruction of multiparty session types~\autocite{Honda+:POPL08}.
In multiparty session types, binary session types are generalized to conversations among several parties.
Conversations in their entirety are specified using global session types.
Global types can be projected to binary session types for each pair of participants, which very nearly are implementations.
\item This work can be seen to further understanding of proof construction and proof reduction.
\item Gives types to logic programs.
Guarantees deadlock-freedom.
\end{itemize}
In addition to the practical benefit of 


The remainder of this document aims to establish this thesis as a plausible one.
To do so, we turn our attention from linear logic to (non-modal) intuitionistic ordered logic~\autocites{Lambek:AMM58}{Polakow+Pfenning:MFPS99}---a restriction of linear logic in which the context of hypotheses forms a list rather than a multiset or bag---and defend the thesis in this restricted setting.
The proposed thesis research is to relax the restrictions and expand the ideas in this document to intuitionistic linear logic.

Specifically, this document describes ... as depicted in \cref{fig:outline}.
First, \cref{?} reviews a string rewriting interpretation of proof construction in a [non-modal] fragment of intuitionistic ordered logic~\autocite{Simmons:CMU12}.
String rewriting specifications in this fragment are equipped with a natural notion of concurrency based on treating  as equivalent the different interleavings of independent rewriting steps.
[equivalence classes of proofs.]

Despite being concurrent, these string rewriting specifications lack an immediate notion of \emph{process} or \emph{process identity}.
Toward this end, \cref{?} introduces \vocab{choreographies}, a further restriction of string rewriting specifications obtained when [in which] atomic propositions are assigned roles as either process-like atoms or message-like atoms.
(Message-like atoms, such as  in \cref{fig:outline}, are indicated with an arrow decoration.)
A specification may admit several choreographies, but, as described in \cref{?}, a well-formed choreography must be (lock-step) equivalent with the specification.

Even with process-like atoms, choreographies remain string rewriting specifications, not actual distributed implementations of processes.
Nevertheless, choreographies are a stepping-stone to process implementations. 
In \cref{?}, we develop a session-typed process calculus from a Curry--Howard interpretation of a fragment of linear logic; 
\Cref{?} shows how choreographies can be compiled to 

Choreographies serve as a stepping stone to full-fledged process definitions.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
