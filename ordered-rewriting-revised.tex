\chapter{Ordered rewriting}\label{ch:ordered-rewriting}

In this \lcnamecref{ch:ordered-rewriting}, we develop a rewriting interpretation of the ordered sequent calculus from the previous \lcnamecref{ch:ordered-logic}.

In \citeyear{Lambek:AMM58}, \citeauthor{Lambek:AMM58} developed a syntactic calculus, now known as the Lambek calculus, for formally describing the structure of sentences.\autocite{Lambek:AMM58}
Words are assigned syntactic types, which roughly correspond to grammatical parts of speech.
From a logical perspective, the Lambek calculus can [also] be viewed as a precursor to (and generalization of) \citeauthor{Girard:TCS87}'s linear logic\autocite{Girard:TCS87}\relax.\autocites{Polakow+Pfenning:MFPS99}{Polakow+Pfenning:TLCA99}
Implicit in \citeauthor{Lambek:AMM58}'s original article is a third perspective of the calculus: string rewriting.

In this \lcnamecref{ch:ordered-rewriting}, we review the Lambek calculus from a [string] rewriting perspective.

\newthought{The previous \lcnamecref{ch:string-rewriting}} showed how to use string rewriting to specify, on a global level, the [...] of concurrent systems that have a linear topology.
Although useful for [...], these string rewriting specifications lack a clear notion of local, decentralized execution -- for each step of rewriting, the entire string is rewritten as a monolithic whole by a central conductor.

Keeping in mind our ultimate goal of decentralized\fixnote{distributed?} implementations of concurrent systems, these string rewriting specifications are too abstract.
Instead, we need to expose local interactions that are left implicit in the string rewriting specifications.

As an example, recall from \cref{ch:string-rewriting} the string rewriting specification of a system that may transform strings that end with $b$ into the empty string:
\begin{equation}
  \infer{a \oc b \reduces b}{}
  \qquad
  \infer{b \reduces \octxe}{}
  \:.
\end{equation}
This specification is non-local in two ways:
the central conductor must identify those substrings that can be rewritten according to one of the axioms.
In the [...] axiom, for example, there is no description of how the symbols $a$ and $b$ would identify each other and coordinate to effect a rewriting to $b$.

To [...], we introduce \vocab{choreographies}, which refine string rewriting specifications by consistently assigning each symbol one of two roles: message or process.
\begin{equation*}
  \infer{\atmR{a} \oc \proc{b} \reduces \proc{b}}{}
  \qquad\text{and}\qquad
  \infer{\proc{b} \reduces \octxe}{}
\end{equation*}

a recursively defined ordered proposition, such as
\begin{equation*}
  \proc{b} \defd (\atmR{a} \limp \up \dn \proc{b}) \with \one
\end{equation*}
for the process $\proc{b}$.

The remainder of this \lcnamecref{ch:ordered-rewriting} presents a formulation of the Lambek calculus from the ordered sequent calculus of \cref{ch:ordered-logic}.

Then, in 


One valid choreography for this specification views each symbol $b$ as a process that nondeterministically receives some number of messages $a$ before terminating.

If we annotate messages with an underbar and processes with a circumflex, then $\atm{a} \oc \hat{b} \reduces \hat{b}$ and $\hat{b} \reduces \octxe$.


\section{Ordered resource decomposition as rewriting}

\subsection{Most left rules decompose ordered resources}

Recall two of the ordered sequent calculus's left rules:
\begin{inferences}
  \infer[\lrule{\fuse}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
    \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
  \and\text{and}\and
  \infer[\lrule{\with}_1]{\oseq{\octx'_L \oc (A \with B) \oc \octx'_R |- C}}{
    \oseq{\octx'_L \oc A \oc \octx'_R |- C}}
  \,.
\end{inferences}
Both rules decompose the principal resource: in the $\lrule{\fuse}$ rule, $A \fuse B$ into the separate resources $A \oc B$; and, in the $\lrule{\with}_1$ rule, $A \with B$ into $A$.
However, in both cases, the resource decomposition is somewhat obscured by boilerplate.
The framed contexts $\octx'_L$ and $\octx'_R$ and goal $C$ serve to enable the rules to be applied anywhere in the list of resources, without restriction;
these concerns are not specific to the $\lrule{\fuse}$ and $\lrule{\with}_1$ rules, but are general boilerplate that arguably should be factored out.

To decouple the resource decomposition from the surrounding boilerplate, we will introduce a new judgment, $\octx \reduces \octx'$, meaning \enquote{Resources $\octx$ may be decomposed into resources $\octx'$.}
The choice of notation for this judgment is not coincidental:
resource decomposition is a generalization of the string rewriting shown in \cref{ch:string-rewriting}.

% With this judgment in hand, the boilerplate can be factored into a uniform left rule, $\lrule{\star}$:
With this new decomposition judgment comes a cut principle, $\jrule{CUT}^{\reduces}$, into which all of the boilerplate is factored:
\begin{equation*}
  \infer[\jrule{CUT}\smash{^{\reduces}}]{\oseq{\octx'_L \oc \octx \oc \octx'_R |- C}}{
    \octx \reduces \octx' &
    \oseq{\octx'_L \oc \octx' \oc \octx'_R |- C}}
  .
\end{equation*}
The standard left rules can then be recovered from resource decomposition rules using this cut principle.
For example, the decomposition of $A \fuse B$ into $A \oc B$ is captured by
\begin{equation*}
  \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{}
  \,,
\end{equation*}
and the standard $\lrule{\fuse}$ rule can then be recovered as shown in the adjacent \lcnamecref{fig:ordered-rewriting:fuse-refactoring}.%
\begin{marginfigure}
  \begin{equation*}
    \begin{gathered}[t]
      \infer[\mathrlap{\lrule{\fuse}}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
        \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
      % 
      \\\leftrightsquigarrow\\
      % 
      \infer[\mathrlap{\jrule{CUT}\smash{^{\reduces}}}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
        \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{} &
        \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
    \end{gathered}
    \phantom{\jrule{CUT}\smash{^{\reduces}}}
  \end{equation*}
  \caption{Refactoring the $\lrule{\fuse}$ rule in terms of resource decomposition}\label{fig:ordered-rewriting:fuse-refactoring}
\end{marginfigure}
The left rules for $\one$ and $A \with B$ can be similarly refactored into the resource decomposition rules
\begin{inferences}
  \infer[\jrule{$\one$D}]{\one \reduces \octxe}{}
  \and
  \infer[\jrule{$\with$D}_1]{A \with B \reduces A}{}
  \and\text{and}\and
  \infer[\jrule{$\with$D}_2]{A \with B \reduces B}{}
  \,.
\end{inferences}

Even the left rules for left- and right-handed implications can be refactored in this way, despite the additional, minor premises that those rules carry.
To keep the correspondence between resource decomposition rules and left rules as close as possible, we could introduce the decomposition rules
\begin{equation}\label{eq:ordered-rewriting:limp-pmir-decomposition}
  \infer[\jrule{$\limp$D}']{\octx \oc (A \limp B) \reduces B}{
    \oseq{\octx |- A}}
  \qquad\text{and}\qquad
  \infer[\jrule{$\pmir$D}']{(B \pmir A) \oc \octx \reduces B}{
    \oseq{\octx |- A}}
  \,.
\end{equation}
Just as for ordered conjunction, the left rules for left- and right-handed implication would then be recoverable via the $\jrule{CUT}^{\reduces}$ rule~(see adjacent \lcnamecref{fig:ordered-rewriting:limp-refactoring-1}).%
\begin{marginfigure}
  \begin{equation*}
    \begin{gathered}
      \infer[\mathrlap{\lrule{\limp}}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
        \oseq{\octx |- A} &
        \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
      % 
      \\\leftrightsquigarrow\\
      % 
      \infer[\mathrlap{\jrule{CUT}\smash{^{\reduces}}}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
        \infer[\jrule{$\limp$D}']{\octx \oc (A \limp B) \reduces B}{
          \oseq{\octx |- A}} &
        \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
    \end{gathered}
    \phantom{\jrule{CUT}\smash{^{\reduces}}}
  \end{equation*}
  \caption{A possible refactoring of the $\lrule{\limp}$ rule in terms of resource decomposition}\label{fig:ordered-rewriting:limp-refactoring-1}
\end{marginfigure}

Although these
% $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$
rules keep the correspondence between resource decomposition rules and left rules close, they differ from the other decomposition rules in two significant ways.
First, the above $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules have premises, and those premises create a dependence of the decomposition judgment upon general provability.
Second, the above $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules do not decompose the principal proposition into \emph{immediate} subformulas since $\octx$ is involved.
This contrasts with, for example, the $\jrule{$\fuse$D}$ rule that decomposes $A \fuse B$ into the immediate subformulas $A \oc B$.

For these reasons, the above $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules are somewhat undesirable.
Fortunately, there is an alternative.
Filling in the $\oseq{\octx |- A}$ premises with the $\jrule{ID}^A$ rule, we arrive at the derivable rules
\begin{equation}\label{eq:ordered-rewriting:limp-pmir-decomposition-nullary}
  \infer[\jrule{$\limp$D}]{A \oc (A \limp B) \reduces B}{}
  \qquad\text{and}\qquad
  \infer[\jrule{$\pmir$D}]{(B \pmir A) \oc A \reduces B}{}
  \,,
\end{equation}
which we adopt as decomposition rules in place of those in \cref{eq:ordered-rewriting:limp-pmir-decomposition}.
The standard $\lrule{\limp}$ and $\lrule{\pmir}$ rules can still be recovered from these more specific decomposition rules, thanks to $\jrule{CUT}$ (see adjacent \lcnamecref{fig:ordered-rewriting:limp-refactoring-2}).%
\begin{marginfigure}[-10\baselineskip]
  \begin{gather*}
    \infer[\lrule{\limp}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
      \oseq{\octx |- A} &
      \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
    %
    \\\leftrightsquigarrow\\
    %
    \infer[\jrule{CUT}\smash{^A}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
      \oseq{\octx |- A} &
      \infer[\jrule{CUT}\smash{^{\reduces}}]{\oseq{\octx'_L \oc A \oc (A \limp B) \oc \octx'_R |- C}}{
        \infer[\jrule{$\limp$D}]{A \oc (A \limp B) \reduces B}{} &
        \oseq{\octx'_L \oc B \oc \octx'_R |- C}}}
  \end{gather*}
  \caption{Refactoring the $\lrule{\limp}$ rule in terms of resource decomposition, via $\jrule{$\limp$D}$ and $\jrule{CUT}\smash{^{\reduces}}$}\label{fig:ordered-rewriting:limp-refactoring-2}
\end{marginfigure}
These revised, nullary decomposition rules correct the earlier drawbacks: like the other decomposition rules, they now have no premises and only refer to immediate subformulas.
Moreover, these rules have the advantage of matching two of the axioms from \citeauthor{Lambek:AMM58}'s original article.\autocite{Lambek:AMM58}

\newthought{%
For most
ordered logical connectives}, this approach works perfectly.
Unfortunately, the left rules for additive disjunction, $A \plus B$, and its unit, $\zero$, are resistant to this kind of refactoring.
The difficulty with additive disjunction isn't that its left rule, $\lrule{\plus}$,%
\marginnote{%
  \begin{equation*}
    \infer[\lrule{\plus}]{\oseq{\octx'_L \oc (A \plus B) \oc \octx'_R |- C}}{
      \oseq{\octx'_L \oc A \oc \octx'_R |- C} &
      \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
  \end{equation*} 
}
doesn't decompose the resource $A \plus B$.
The $\lrule{\plus}$ rule certainly does decompose $A \plus B$, but it does so [...].\fixnote{fix}
$A \plus B \reduces A \mid B$
[...] retain the standard $\lrule{\plus}$ and $\lrule{\zero}$ rules.

\begin{figure}[tbp]
  \vspace*{\dimexpr-\abovedisplayskip-\abovecaptionskip\relax}
  \begin{inferences}
    \infer[\jrule{CUT}\smash{^A}]{\oseq{\octx'_L \oc \octx \oc \octx'_R |- C}}{
      \oseq{\octx |- A} & \oseq{\octx'_L \oc A \oc \octx'_R |- C}}
    \and 
    \infer[\jrule{ID}\smash{^A}]{\oseq{A |- A}}{}
    \\
    \infer[\jrule{CUT}\smash{^{\reduces}}]{\oseq{\octx'_L \oc \octx \oc \octx'_R |- C}}{
      \octx \reduces \octx' & \oseq{\octx'_L \oc \octx' \oc \octx'_R |- C}}
    \\
    \infer[\rrule{\fuse}]{\oseq{\octx_1 \oc \octx_2 |- A \fuse B}}{
      \oseq{\octx_1 |- A} & \oseq{\octx_2 |- B}}
    \and
    \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{}
    \\
    \infer[\rrule{\one}]{\oseq{\octxe |- \one}}{}
    \and
    \infer[\jrule{$\one$D}]{\one \reduces \octxe}{}
    \\
    \infer[\rrule{\with}]{\oseq{\octx |- A \with B}}{
      \oseq{\octx |- A} & \oseq{\octx |- B}}
    \and
    \infer[\jrule{$\with$D}_1]{A \with B \reduces A}{}
    \and
    \infer[\jrule{$\with$D}_2]{A \with B \reduces B}{}
    \\
    \infer[\rrule{\top}]{\oseq{\octx |- \top}}{}
    \and
    \text{(no $\jrule{$\top$D}$ rule)}
    \\
    \infer[\rrule{\limp}]{\oseq{\octx |- A \limp B}}{
      \oseq{A \oc \octx |- B}}
    \and
    \infer[\jrule{$\limp$D}]{A \oc (A \limp B) \reduces B}{}
    \\
    \infer[\rrule{\pmir}]{\oseq{\octx |- B \pmir A}}{
      \oseq{\octx \oc A |- B}}
    \and
    \infer[\jrule{$\pmir$D}]{(B \pmir A) \oc A \reduces B}{}
    \\
    \infer[\rrule{\plus}_1]{\oseq{\octx |- A \plus B}}{
      \oseq{\octx |- A}}
    \and
    \infer[\rrule{\plus}_2]{\oseq{\octx |- A \plus B}}{
      \oseq{\octx |- B}}
    \and
    \infer[\lrule{\plus}]{\oseq{\octx'_L \oc (A \plus B) \oc \octx'_R |- C}}{
      \oseq{\octx'_L \oc A \oc \octx'_R |- C} &
      \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
    \\
    \text{(no $\rrule{\zero}$ rule)}
    \and
    \infer[\lrule{\zero}]{\oseq{\octx'_L \oc \zero \oc \octx'_R |- C}}{}
  \end{inferences}
  \caption{A refactoring of the ordered sequent calculus to emphasize that most left rules amount to resource decomposition}\label{fig:ordered-rewriting:decompose-seq-calc}
\end{figure}

\newthought{\Cref{fig:ordered-rewriting:decompose-seq-calc} presents} the refactored sequent calculus for ordered logic in its entirety.
This calculus is sound and complete with respect to the ordered sequent calculus~\parencref{fig:ordered-logic:sequent-calculus}.
%
\begin{theorem}[Soundness and completeness]
  $\oseq{\octx |- A}$ is derivable in the refactored calculus of \cref{fig:ordered-rewriting:decompose-seq-calc} if, and only if $\oseq{\octx |- A}$ is derivable in the usual ordered sequent calculus~\parencref{fig:ordered-logic:sequent-calculus}.
\end{theorem}
%
\begin{proof}
  Soundness, the right-to-left direction, can be proved by structural induction on the given derivation.
  The key lemma is the admissibility of $\jrule{CUT}^{\reduces}$ in the usual ordered sequent calculus:
  \begin{quotation}
    \normalsize If $\octx \reduces \octx'$ and $\oseq{\octx'_L \oc \octx' \oc \octx'_R |- C}$, then $\oseq{\octx'_L \oc \octx \oc \octx'_R |- C}$.
  \end{quotation}
  This lemma can be proved by case analysis of the decomposition $\octx \reduces \octx'$, reconstituting the corresponding left rule along the lines of the sketches from \cref{fig:ordered-rewriting:fuse-refactoring,fig:ordered-rewriting:limp-refactoring-2}.

% \end{proof}
%
% \begin{theorem}[Completeness]
%   If\/ $\oseq{\octx |- A}$ is derivable in the usual ordered sequent calculus~\parencref{fig:ordered-logic:sequent-calculus}, then $\oseq{\octx |- A}$ is derivable in the refactored calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}.
% \end{theorem}
%
% \begin{proof}
  Completeness, the left-to-right direction, can be proved by structural induction on the given derivation.
  The critical cases are the left rules; they are resolved along the lines of the sketches shown in \cref{fig:ordered-rewriting:fuse-refactoring,fig:ordered-rewriting:limp-refactoring-2}.
\end{proof}

\subsection{Ordered resource decomposition as rewriting}

Thus far, we have used the decomposition judgment, $\octx \reduces \octx'$, and its rules as the basis for a reconfigured sequent-like calculus for ordered logic.
% But this refactoring also leads naturally to a rewriting system grounded in ordered logic.
% 
% Instead,
Additionally, 
% of taking the resource decomposition rules as a basis for a reconfigured sequent calculus,
we can instead view decomposition as the foundation of a rewriting system grounded in ordered logic.
For example, the decomposition of resource $A \fuse B$ into $A \oc B$ by the $\jrule{$\fuse$D}$ rule
% \marginnote{%
%   \begin{equation*}
%     \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{}
%   \end{equation*}
% }%
can also be seen as \emph{rewriting} $A \fuse B$ into $A \oc B$.
More generally, the decomposition judgment $\octx \reduces \octx'$ can be read as \enquote{$\octx$ rewrites to $\octx'$.}

\Cref{fig:ordered-rewriting:rewriting} summarizes the rewriting system that we obtain from the refactored sequent-like calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}%
%
\begin{figure}[tbp]
  \vspace{\dimexpr-\abovedisplayskip-\abovecaptionskip\relax}
  \begin{inferences}
    \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{}
    \and
    \infer[\jrule{$\one$D}]{\one \reduces \octxe}{}
    \\
    \infer[\jrule{$\with$D}_1]{A \with B \reduces A}{}
    \and
    \infer[\jrule{$\with$D}_2]{A \with B \reduces B}{}
    \and
    \text{(no $\jrule{$\top$D}$ rule)}
    \\
    \infer[\jrule{$\limp$D}]{A \oc (A \limp B) \reduces B}{}
    \and
    \infer[\jrule{$\pmir$D}]{(B \pmir A) \oc A \reduces B}{}
    \and
    \text{(no $\jrule{$\plus$D}$ and $\jrule{$\zero$D}$ rules)}
    \\
    \infer[\jrule{$\reduces$C}]{\octx_L \oc \octx \oc \octx_R \reduces \octx_L \oc \octx' \oc \octx_R}{
      \octx \reduces \octx'}
  \end{inferences}
  \begin{inferences}
    \infer[\jrule{$\Reduces$R}]{\octx \Reduces \octx}{}
    \and
    \infer[\jrule{$\Reduces$T}]{\octx \Reduces \octx''}{
      \octx \reduces \octx' & \octx' \Reduces \octx''}
  \end{inferences}
  \caption{The \acs*{OR} rewriting fragment of ordered logic, based on resource decomposition}\label{fig:ordered-rewriting:rewriting}
\end{figure}%
%
; we dub this ordered rewriting system \acs{OR}.
Essentially, \ac{OR} is obtained by discarding all rules except for the decomposition rules.
However, if only the decomposition rules are used, rewritings cannot occur within a larger context.
For example, the $\jrule{$\limp$D}$ rule derives $A \oc (A \limp B) \reduces B$, but $\octx'_L \oc A \oc (A \limp B) \oc \octx'_R \reduces \octx'_L \oc B \oc \octx'_R$ would not be derivable in general.
In the refactored calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}, this kind of framing is taken care of by the cut principle for decomposition, $\jrule{CUT}^{\reduces}$.
To express framing at the level of the $\octx \reduces \octx'$ judgment itself, we ensure that rewriting is compatible with concatenation of ordered contexts:
\begin{equation*}
  \infer[\jrule{$\reduces$C}]{\octx_L \oc \octx \oc \octx_R \reduces \octx_L \oc \octx' \oc \octx_R}{
    \octx \reduces \octx'}
  \,.
\end{equation*}

By forming the reflexive, transitive closure of $\reduces$, we may construct a multi-step rewriting relation, which we choose to write as $\Reduces$.%
\footnote{% [][0.5\baselineskip]{%
  Usually written as $\reduces^*$, we instead chose $\Reduces$ for the reflexive, transitive closure because of its similarity with process calculus notation for weak transitions, $\Reduces[\smash{\alpha}]$.
  Our reasons will become clearer in subsequent \lcnamecrefs{ch:ordered-bisimilarity}.%
}
Consistent with its monoidal structure, there are two equivalent formulations of this reflexive, transitive closure: each rewriting sequence $\octx \Reduces \octx'$ can be viewed as either a list or tree of individual rewriting steps.\fixnote{rewrite with reference to string rewriting}
We prefer the list-based formulation shown in \cref{fig:ordered-rewriting:rewriting} because it tends to streamline proofs by structural induction, but, on the basis of the following \lcnamecref{fact:ordered-rewriting:transitivity}, we allow ourselves to freely switch between the two formulations as needed.
%
\begin{fact}[Transitivity of $\Reduces$]\label{fact:ordered-rewriting:transitivity}
  If \kern0.15em$\octx \Reduces \octx'$ and\/ $\octx' \Reduces \octx''$, then\/ $\octx \Reduces \octx''$.
\end{fact}
%
\begin{proof}
  By induction on the structure of the first trace, $\octx \Reduces \octx'$.
\end{proof}

\newthought{A few remarks} about these rewriting relations are in order.
%
First, interpreting the resource decomposition rules as rewriting only confirms our preference for the nullary $\jrule{$\limp$D}$ and $\jrule{$\pmir$D}$ rules~(eq.~\ref{eq:ordered-rewriting:limp-pmir-decomposition-nullary}).
% [over the $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules.]
The $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules~(eq.~\ref{eq:ordered-rewriting:limp-pmir-decomposition}), with their $\oseq{\octx |- A}$ premises, would be problematic as rewriting rules because they would introduce a dependence of rewriting upon general provability
% By instead using the $\jrule{$\limp$D}$ and $\jrule{$\pmir$D}$ rules, we ensures that ordered rewriting is a syntactic procedure that
% Instead, we want ordered rewriting to be a syntactic procedure, withou 
 and the accompanying proof search would take \ac{OR} too far afield from traditional, syntactic notions of string and multiset rewriting.

Second, multi-step rewriting, $\Reduces$, is incomplete with respect to the usual ordered sequent calculus~\parencref{fig:ordered-logic:sequent-calculus} because all right rules have been discarded.%
%
 \begin{falseclaim}[Completeness]
  If \kern0.15em$\oseq{\octx |- A}$, then\/ $\octx \Reduces A$.
\end{falseclaim}
%
\begin{proof}[Counterexample]
  The sequent $\oseq{A \limp (C \pmir B) |- (A \limp C) \pmir B}$ is provable, and yet $A \limp (C \pmir B) \Longarrownot\Reduces (A \limp C) \pmir B$ (even though $A \oc (A \limp (C \pmir B)) \oc B \Reduces C$ does hold).
\end{proof}
\noindent
As expected from the way in which it was developed, ordered rewriting in \acs{OR} is, however, sound.
To state and prove soundness, we must first define an operation $\bigfuse \octx$ that reifies an ordered context as a single proposition (see adjacent \lcnamecref{fig:ordered-rewriting:bigfuse}).\fixnote{fix}%
%
\begin{marginfigure}
  \begin{align*}
    (\octx_1 \oc \octx_2) &= (\octx_1) \fuse (\octx_2) \\
    \mathord{\text{$\fuse$}} (\octxe) &= \one \\
    A &= A
  \end{align*}
  \begin{align*}
    \bigfuse (\octx_1 \oc \octx_2) &= (\bigfuse \octx_1) \fuse (\bigfuse \octx_2) \\
    \bigfuse (\octxe) &= \one \\
    \bigfuse A &= A
  \end{align*}
  \caption{From ordered contexts to propositions}\label{fig:ordered-rewriting:bigfuse}
\end{marginfigure}%
%
\begin{lemma}
  For all $\octx$ and $C$, we have $\oseq{\octx |- C}$ implies $\oseq{\bigfuse \octx |- C}$, as well as $\oseq{\octx |- \bigfuse \octx}$.
\end{lemma}
\begin{proof}
  By induction on the structure of the given context, $\octx$.
\end{proof}
%
\begin{theorem}[Soundness]
  If \kern0.15em$\octx \reduces \octx'$, then\/ $\oseq{\octx |- \bigfuse \octx'}$.
  Also, if \kern0.15em$\octx \Reduces \octx'$, then\/ $\oseq{\octx |- \bigfuse \octx'}$.
\end{theorem}
%
\begin{proof}
  By induction on the structure of the given step or trace.
\end{proof}

Last, notice that every rewriting step, $\octx \reduces \octx'$, strictly decreases the number of logical connectives that occur in the ordered context.
More formally, let $\card{\octx}_{\star}$ be a measure of the number of logical connectives that occur in $\octx$, as defined in the adjacent \lcnamecref{fig:ordered-rewriting:measure}.
%
\begin{marginfigure}
  \begin{align*}
    \card{\octx_1 \oc \octx_2}_{\star} &= \card{\octx_1}_{\star} + \card{\octx_2}_{\star} \\
    \card{\octxe}_{\star} &= 0 \\
    \card{A \star B}_{\star} &= \begin{tabular}[t]{@{}l@{}}
                          $1 + \card{A}_{\star} + \card{B}_{\star}$ \\
                          \quad if $\mathord{\star} = \mathord{\fuse}$, $\mathord{\with}$, $\mathord{\limp}$, $\mathord{\pmir}$, or $\mathord{\plus}$
                         \end{tabular} \\
    \card{A}_{\star} &= \mathrlap{1}
                    \quad \text{if $A = a$, $\one$, $\top$, or $\zero$}
  \end{align*}
  \caption{A measure of the number of logical connectives within an ordered context}\label{fig:ordered-rewriting:measure}
\end{marginfigure}%
%
We may then prove the following \lcnamecref{lem:ordered-rewriting:reduction}.%
%
\begin{lemma}\label{lem:ordered-rewriting:reduction}
  If \kern0.15em$\octx \reduces \octx'$, then $\card{\octx}_{\star} > \card{\octx'}_{\star}$.
  If \kern0.15em$\octx \Reduces \octx'$, then $\card{\octx}_{\star} \geq \card{\octx'}_{\star}$.
\end{lemma}
%
\begin{proof}
  By induction on the structure of the rewriting step.
\end{proof}
%
\noindent
On the basis of this \lcnamecref{lem:ordered-rewriting:reduction}, we will frequently refer to the rewriting relation, $\reduces$, as the \vocab{reduction relation}.
We may use this \lcnamecref{lem:ordered-rewriting:reduction} to prove that ordered rewriting is terminating.
% 
% Because each rewriting step reduces the number of logical connectives present in the state~\parencref{lem:ordered-rewriting:reduction}, ordered rewriting is terminating.
%
\begin{theorem}[Termination]\label{thm:ordered-rewriting:termination}
  For all ordered contexts $\octx$, every rewriting sequence from $\octx$ is finite.
  % $\octx_0 \reduces \octx_1 \reduces \octx_2 \reduces \dotsb$ exists.
\end{theorem}
%
\begin{proof}
  Let $\octx$ be an arbitrary ordered context.
  Beginning from state $\octx_0 = \octx$, some state $\octx_i$ will eventually be reached such that either: $\octx_i \nreduces$; or $\card{\octx_i}_{\star} = 0$ and $\octx_i \reduces \octx_{i+1}$.
  In the latter case, \cref{lem:ordered-rewriting:reduction} establishes $\card{\octx_{i+1}}_{\star} < 0$, which is impossible because $\card{}_{\star}$ is a measure.
\end{proof}


\subsection{Recursively defined propositions and unbounded ordered rewriting}

Although a seemingly pleasant property, termination~\parencref{thm:ordered-rewriting:termination} significantly limits the expressiveness of ordered rewriting.
For example, without unbounded rewriting, we cannot even use ordered rewriting to describe producer-consumer systems or finite automata.

As the proof of termination shows, rewriting is bounded
% $\card{\octx_0}$ is an upper bound on the length of any trace from state $\octx_0$,
precisely because
% $\octx_0$
states
consist of finitely many finite propositions.
One way to admit unbounded rewriting is therefore to permit circular propositions in the form of mutually recursive definitions, $\defp{p} \defd A$, where the grammar of ordered propositions now includes these recursively defined propositions $\defp{p}$:
\begin{equation*}
  A,B \Coloneqq a \mid A \fuse B \mid \one \mid A \limp B \mid B \pmir A \mid A \with B \mid \top \mid \defp{p}
  \,.
\end{equation*}
Sequent calculi with definitions of this kind have previously been studied by \textcites{Hallnas:??}{Erikkson:??}{Schroeder-Heister:??}{McDowell+Miller:??}{Tiu+Momigliano:??}, among others.

To rule out definitions like $\defp{p} \defd \defp{p}$ that do not correspond to sensible infinite propositions, we require that definitions be \vocab{contractive}\autocite{Gay+Hole:AI05} -- \ie, that the body of each recursive definition begin with a logical connective (or constant or atom) at the top level.

% could either permit states consisting of infinitely many finite propositions or states consisting of finitely many infinite propositions.
% We choose the latter route [...].
%%
%%
% Infinite propositions are described by mutually recursive definitions $\alpha \defd A$.
The recursive definitions are collected into a signature, $\orsig$, which indexes the rewriting relations: $\reduces_{\orsig}$ and $\Reduces_{\orsig}$.%
\footnote{We nearly always elide the index, as it is usually clear from context.} 
Syntactically, these signatures are given by
\begin{equation*}
  \orsig \Coloneqq \orsige \mid \orsig , (\defp{p} \defd A)
  \,.
\end{equation*}


\newthought{By analogy with} recursive types from functional programming\autocite{??}, we must now decide whether to treat definitions \emph{iso}\-re\-cur\-sively or \emph{equi}\-re\-cur\-sively.
Under an equirecursive interpretation, definitions $\defp{p} \defd A$ may be silently unrolled or rolled at will;
in other words, $\defp{p}$ is literally \emph{equal} to its unrolling -- $\defp{p} = A$.
In contrast, under an isorecursive interpretation, unrolling a recursively defined proposition would count as an explicit step of rewriting -- $\defp{p} \neq A$ but $\defp{p} \reduces A$, for example.

% Under the isorecursive interpretation, unrolling a recursively defined prop\-o\-sition counts as an explicit step of rewriting.
% We introduce the $\jrule{$\defd$D}$ rule to account for this unrolling:
% \begin{equation*}
%   \infer[\jrule{$\defd$D}]{\alpha \reduces_{\sig} A}{
%     \text{$(\alpha \defd A) \in \sig$}}
% \end{equation*}
% Because $A$ is seen as a proper subformula of [the recursively defined] $\alpha$, this unrolling rule aligns well with the rewriting-as-decomposition philosophy.%
% \footnote{In fact, we could have chosen to include recursive definitions in the sequent calculus, following \textcites{SchroederHeister:LICS93}{Tiu+Momigliano:JAL12} and others.
%   Had we done so, the $\jrule{$\defd$D}$ rule would be seen as the decomposition counterpart to the left rule
%   \begin{equation*}
%     \infer[\lrule{\defd}]{\oseq{\octx'_L \oc \alpha \oc \octx'_R |-_{\sig} C}}{
%       \bigl((\alpha \defd A) \in \sig\bigr) &
%       \oseq{\octx'_L \oc A \oc \octx'_R |-_{\sig} C}}
%   \end{equation*}
% }
% Conversely, there is no rule that permits the rolling of $A$ into $\alpha$, because such a rule would not be a decomposition.

We choose to interpret definitions equirecursively
because the equirecursive treatment, with its generous notion of equality, helps to minimize the overhead of recursively defined propositions.
As a simple example, under the equirecursive definition $\defp{p} \defd a \limp \defp{p}$, we have the trace
\begin{equation*}
  a \oc a \oc \defp{p} = a \oc a \oc (a \limp \defp{p}) \reduces a \oc \defp{p} = a \oc (a \limp \defp{p}) \reduces \defp{p}
\end{equation*}
or, more concisely, $a \oc a \oc \defp{p} \reduces a \oc \defp{p} \reduces \defp{p}$.
Had we chosen
% With
 an isorecursive treatment of the same definition, we would have only the more laborious
\begin{equation*}
  a \oc a \oc \defp{p} \reduces a \oc a \oc (a \limp \defp{p}) \reduces a \oc \defp{p} \reduces a \oc (a \limp \defp{p}) \reduces \defp{p}
  \,.
\end{equation*}
This choice differs from the aforementioned works on definitions, which use an isorecursive treatment with explicit right and left rules for recursively defined propositions.


\paragraph*{Replication}

In Milner's development of the $\pi$-calculus, there are two avenues to unbounded process behavior: recursive process definitions and replication.

\autocite{Aranda+:FMCO06}


\subsection{Properties of the \acs*{OR} \acl*{OR} framework}

\paragraph*{Concurency}

As an example of multi-step rewriting, observe that
\begin{equation*}
  % \octx = 
  a \oc (a \limp b) \oc (c \pmir a) \oc a \Reduces b \oc c
  % = \octx''
  .
\end{equation*}
In fact, as shown in the adjacent \lcnamecref{fig:ordered-rewriting:concurrent-example},%
%
\begin{marginfigure}
  \begin{equation*}
  \begin{tikzcd}[row sep=large, column sep=tiny]
    &
    \makebox[1em][c]{$a \oc (a \limp b) \oc (c \pmir a) \oc a$}
      \dlar \drar \arrow[Reduces]{dd}
    &
    \\
    b \oc (c \pmir a) \oc a
      \drar
    &&
    a \oc (a \limp b) \oc c
      \dlar
    \\
    &
    b \oc c
    &
  \end{tikzcd}
\end{equation*}
  \caption{An example of concurrency in ordered rewriting}\label{fig:ordered-rewriting:concurrent-example}
\end{marginfigure}
%
two sequences witness this rewriting: either
\begin{itemize*}[
  mode=unboxed,
  label=, afterlabel=
]
\item the initial state's left half, $a \oc (a \limp b)$, is first rewritten to $b$ and then its right half, $(c \pmir a) \oc a$, is rewritten to $c$; or
\item \textit{vice versa}, the right half is first rewritten to $c$ and then the left half is rewritten to $b$
\end{itemize*}.

Notice that these two sequences differ only in how non-overlapping, and therefore independent, rewritings of the initial state's two halves are interleaved.
Consequently, the two sequences can be -- and indeed should be -- considered essentially equivalent.
% In differing only by the order in which the non-overlapping left and right halves are rewritten, these two rewriting sequences are essentially equivalent.
The details of how the small-step rewrites are interleaved are irrelevant, so that
conceptually, at least, only the big-step trace from $a \oc (a \limp b) \oc (c \pmir a) \oc a$ to $b \oc c$ remains.
% The details of how the small-step rewrites are interleaved are -- and indeed should be -- swept away, so that conceptually only the big-step trace from $\alpha_1 \oc (\alpha_1 \limp \alpha_2) \oc (\beta_2 \pmir \beta_1) \oc \beta_1$ to $\alpha_2 \oc \beta_2$ remains.

More generally, this idea that the interleaving of independent actions is irrelevant is known as \vocab{concurrent equality}\autocite{Watkins+:CMU02}, and it forms the basis of concurrency.\autocite{??}
Concurrent equality also endows traces $\octx \Reduces \octx'$ with a free partially commutative monoid structure, \ie, traces form a trace monoid.


% Because the two indivisual rewriting steps are independent, 
% Nothing about the final result, $\alpha_2 \oc \beta_2$, suggests which rewriting sequence 


% The rewritings of the left and right halves are not overlapping and therefore independent.
% Their independence means that we may view the two rewriting sequences as equivalent -- the two rewriting steps

% More generally, any non-overlapping rewritings are independent and may occur in any order.
% Rewriting sequences that differ only by the order in which independent rewritings occur may be seen as equivalent sequences.
% This equivalence relation, \vocab{concurrent equality}\autocite{Watkins+:CMU02}

% because the left half of $\octx$ may be rewritten by the $\jrule{$\limp$D}$ rule to $\alpha_2$, and then the right half may be rewritten to $\beta_2$:


\clearpage

\paragraph*{Non-confluence}

As the relation $\Reduces$ forms a rewriting system, we may evaluate it along several standard dimensions: termination, confluence.


Although terminating, ordered rewriting is not confluent.
Confluence requires that all states with a common ancestor, \ie, states $\octx'_1$ and $\octx'_2$ such that $\octx'_1 \secudeR\Reduces \octx'_2$, be joinable, \ie, $\octx'_1 \Reduces\secudeR \octx'_2$.
Because ordered rewriting is directional\fixnote{Is this phrasing correct?} and the relation $\Reduces$ is not symmetric, some nondeterministic choices are irreversible.%
%
\begin{falseclaim}[Confluence]
  If\/ $\octx'_1 \secudeR\Reduces \octx'_2$, then $\octx'_1 \Reduces\secudeR \octx'_2$.
\end{falseclaim}
%
\begin{proof}[Counterexamples]
  Consider the state $a \with b$.
  By the rewriting rules for additive conjunction, $a \secuder a \with b \reduces b$, and hence $a \secudeR a \with b \Reduces b$.
  However, being atoms, neither $a$ nor $b$ reduces.
  And $a \neq b$, so $a \Reduces\secudeR b$ does \emph{not} hold.

  Even in the $\with$-free fragment, ordered rewriting is not confluent:
  for example,
  % consider the state $(\beta_1 \pmir \alpha) \oc \alpha \oc (\alpha \limp \beta_2)$.
  % By the rewriting rules for right- and left-handed implications,
  \begin{equation*}
    \nsecuder c \oc (a \limp b) \secudeR (c \pmir a) \oc a \oc (a \limp b) \Reduces (c \pmir a) \oc b \nreduces
    .
    \qedhere
  \end{equation*}
\end{proof}


% Viewing the resource decomposition rules for left- and right-handed implications as rewriting rules is slightly problematic, however.%
% Notice that the premises of these rules both require proofs of $\oseq{\octx |-  A}$.
% In the refactored sequent calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}, that dependence of judgments is fine.
% But for a rewriting system, including arbitrary[/general] proofs would be odd -- rewriting should be a syntax-directed process and should not depend on provability.



% We write the reflexive, transitive closure of $\reduces$ as $\Reduces$.%
% \footnote{This notation is adopted for its similarity with the standard $\pi$-calculus notation for weak transitions, $\cramped{\Reduces[\alpha]}$.}

% This rewriting system is a proper fragment of ordered logic.
% \begin{equation*}
%   \oseq{A \limp (C \pmir B) \dashv|- (A \limp C) \pmir B}
%   \enspace\text{but}\enspace
%   A \limp (C \pmir B) \Longarrownot\Reduces (A \limp C) \pmir B
% \end{equation*}




\section{The \acs*{FOR} focused ordered rewriting framework}

The above ordered rewriting framework is based upon decomposition rules that are very fine-grained.
Each step of rewriting decomposes a proposition into only its immediate subformulas, and no further, such as in the very fine-grained step $a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr) \reduces a \oc (a \limp c \fuse a)$.
% \begin{marginfigure}
%   \begin{equation*}
%     \begin{tikzcd}[sep=small]
%       & a \mathrlap{\oc (a \limp b) \reduces b}
%       \\
%       \mathllap{a \oc \bigl((a \limp b) \with (c \pmir a)\bigr)}
%         \urar[reduces] \drar[reduces]
%       \\
%       & a \mathrlap{\oc (c \pmir a) \nreduces}
%     \end{tikzcd}
%     \hphantom{\oc (a \limp b) \reduces b}
%   \end{equation*}
%   \caption{}
% \end{marginfigure}%
It is not possible to rewrite the context $a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr)$ into $c \oc a$ (or even $c \fuse a$) in a single step, although it is possible in several steps: $a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr) \Reduces c \oc a$, because
\begin{equation*}
  a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr) \reduces a \oc (a \limp c \fuse a) \reduces c \fuse a \reduces c \oc a
  \,.
\end{equation*}

The decomposition rules are so fine-grained that rewriting may even get stuck in undesirable and unintended ways.
For instance, in the previous example, we might have instead nondeterministically committed to rewriting $a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr)$ into $a \oc (b \limp \one)$ as the first step, and then $a \oc (b \limp \one)$ is stuck, with no further rewritings possible:
\begin{equation*}
  a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr)
    \reduces a \oc (b \limp \one)
    \nreduces
    \!\,.
\end{equation*}
Instead, we would rather have a coarser notion of decomposition so that $a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr) \reduces c \oc a$ is a single step%
\footnote{Or at least so that $a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr) \reduces c \fuse a$ is a single step.}
and, conversely, so that $a \oc \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr) \reduces \octx'$ only if $\octx' = c \oc a$.

\newthought{Focusing, as developed by} \textcite{Andreoli:??}, provides just the right coarse-grained decomposition through its complementary inversion and chaining strategies for proof search.
An inversion phase groups together successive invertible rules, and a chaining phase groups together successive noninvertible rules that are applied to a single \emph{in-focus} proposition;
together, a chaining phase followed by an inversion phase constitutes a \emph{bipole}.
Rather than having each of these rules give rise to a separate step, we can treat the entire bipole as an atomic step of rewriting.

This idea of using focusing to increase the granularity of rewriting steps dates back to, at least, the \acf{CLF}\autocites{??}{??} and was later streamlined by \textcite{Cervesato+Scedrov:IC09}.
\Textcite{Simmons:CMU12} has studied a focused ordered rewriting framework, though in a somewhat different formulation than the one we present here.

\newthought{The ordered propositions are polarized} into positive and negative classes, or \vocab{polarities}\autocite{??}, according to the invertibility of their sequent calculus rules; two \enquote*{shift} connectives, $\dn$ and $\up$, mediate between the two classes.
\begin{align*}
  % Positive props. &
    \p{A} &\Coloneqq \p{a} \mid \p{A} \fuse \p{B} \mid \one \mid \dn \n{A}
  \\
  % Negative props. &
    \n{A} &\Coloneqq \p{A} \limp \n{B} \mid \n{B} \pmir \p{A} \mid \n{A} \with \n{B} \mid \top \mid \up \p{A}
\end{align*}
The positive propositions, $\p{A}$, are those propositions that have invertible left rules, such as ordered conjunction; the negative propositions, $\n{A}$, are those that have invertible right rules, such as the left- and right-handed implications.
For reasons that will become clear in \cref{ch:formula-as-process}, we choose to assign a positive polarity to all atomic propositions, $\p{a}$.

Ordered contexts are then formed as the free monoid over negative propositions and positive atoms:
\begin{equation*}
  \np{\octx} \Coloneqq \np{\octx}_1 \oc \np{\octx}_2 \mid \octxe \mid \n{A} \mid \p{a}
  \,.
\end{equation*}
As usual, we do not distinguish those ordered contexts that are equivalent up to the monoid laws.
We may also reify an ordered context $\np{\octx}$ as a positive proposition, $\bigfuse \np{\octx}$, using the operation defined in the neighboring \lcnamecref{fig:ordered-rewriting:bigfuse}%
%
\begin{marginfigure}
  \begin{align*}
    \bigfuse (\np{\octx}_1 \oc \np{\octx}_2) &= (\bigfuse \np{\octx}_1) \fuse (\bigfuse \np{\octx}_2) \\
    \bigfuse (\octxe) &= \one \\
    \bigfuse \n{A} &= \dn \n{A} \\
    \bigfuse \p{a} &= \p{a}
  \end{align*}
  \caption{Reifying an ordered context as a positive proposition}
\end{marginfigure}%
%
.

\newthought{Each class of propositions} is then equipped with its own focusing judgment: a \vocab{left-focus judgment}, $\lfocus{\np{\octx}_L}{\n{A}}{\np{\octx}_R}{\p{C}}$, that focuses on a negative proposition, $\n{A}$, that occurs to the left of the turnstile; and a \vocab{right-focus judgment}, $\rfocus{\np{\octx}}{\p{A}}$, that focuses on a positive proposition, $\p{A}$, that occurs to the right of the turnstile.%
\footnote{We choose a left-facing turnstile for the right-focus judgment to emphasize its input/output mode; see the next paragraph.}

Following \textcite{Zeilberger:??}, each of these judgments can be read as a function that provides a form of extended decomposition -- the in-focus proposition is decomposed beyond its immediate subformulas, until subformulas of the opposite polarity are reached.
% The judgment $\rfocus{\octx}{\p{A}}$ decomposes the in-focus proposition $\p{A}$ into the ordered context $\octx$ of negative subformulas,
% and $\lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}}$ decomposes the in-focus proposition $\n{A}$ into the ordered contexts $\octx_L$ and $\octx_R$ and the positive subformula $\p{C}$.
% 
The two focusing judgments are defined inductively on the structure of the in-focus proposition, with the left-focus judgment depending on the right-focus judgment (though not vice versa).

The right-focus judgment, $\rfocus{\np{\octx}}{\p{A}}$, decomposes $\p{A}$ into the ordered context $\np{\octx}$ of its nearest negative subformulas, treating $\p{A}$ as input and $\np{\octx}$ as output.%
% \footnote{This input/output behavior explains why we choose to write the \emph{right}-focus judgment as $\rfocus{\np{\octx}}{\p{A}}$ with a \emph{left}-facing turnstile:
  % when written this way, the judgment's input is followed by its output.}
% The right-focus judgment, $\rfocus{\np{\octx}}{\p{A}}$, decomposes $\p{A}$ into the ordered context $\np{\octx}$ of its nearest negative subformulas;
% this judgment therefore takes an in-focus proposition, $\p{A}$, as an input and produces an ordered context, $\np{\octx}$, as output.
The judgment is given by the following rules.
\begin{inferences}
  \infer[\rrule{\fuse}]{\rfocus{\np{\octx}_1 \oc \np{\octx}_2}{\p{A} \fuse \p{B}}}{
    \rfocus{\np{\octx}_1}{\p{A}} & \rfocus{\np{\octx}_2}{\p{B}}}
  \and
  \infer[\rrule{\one}]{\rfocus{\octxe}{\one}}{}
  \\
  \infer[\jrule{ID}\smash{^{\p{a}}}]{\rfocus{\p{a}}{\p{a}}}{}
  \and
  \infer[\rrule{\dn}]{\rfocus{\n{A}}{\dn \n{A}}}{}
\end{inferences}
% This right-focus judgment decomposes a positive proposition until its [largest] negative subformulas are reached.
Ordered conjunctions $\p{A} \fuse \p{B}$ are decomposed into $\np{\octx}_1 \oc \np{\octx}_2$ by inductively decomposing $\p{A}$ and $\p{B}$ into $\np{\octx}_1$ and $\np{\octx}_2$, respectively, and $\one$ is decomposed into the empty context.
Atoms $\p{a}$ are not decomposed further%
\footnote{Alternatively, following \textcite{Simmons:CMU12}, atoms $\p{a}$ could be decomposed to suspensions $\langle\p{a}\rangle$, but we choose not to do that here.}%
, and $\dn \n{A}$ is decomposed into its immediate subformula of negative polarity, $\n{A}$.

This right-focus judgment is a left inverse of the $\bigfuse (-)$ operation:
\begin{lemma}
  $\rfocus{\np{\octx'{}}}{\bigfuse \np{\octx}}$ if, and only if, $\np{\octx} = \np{\octx'{}}$.
\end{lemma}
\begin{proof}
  Each direction is separately proved by structural induction on the context $\np{\octx}_2$.
\end{proof}

The left-focus judgment, $\lfocus{\np{\octx}_L}{\n{A}}{\np{\octx}_R}{\p{C}}$, decomposes $\n{A}$ into the ordered contexts $\np{\octx}_L$ and $\np{\octx}_R$ and positive subformula $\p{C}$, treating $\n{A}$ as input and $\np{\octx}_L$, $\np{\octx}_R$, and $\p{C}$ as outputs.
The judgment is given by the following rules.
\begin{inferences}
  \infer[\lrule{\limp}]{\lfocus{\np{\octx}_L \oc \np{\octx}_A}{\p{A} \limp \n{B}}{\np{\octx}_R}{\p{C}}}{
    \rfocus{\np{\octx}_A}{\p{A}} &
    \lfocus{\np{\octx}_L}{\n{B}}{\np{\octx}_R}{\p{C}}}
  \and
  \infer[\lrule{\pmir}]{\lfocus{\np{\octx}_L}{\n{B} \pmir \p{A}}{\np{\octx}_A \oc \np{\octx}_R}{\p{C}}}{
    \rfocus{\np{\octx}_A}{\p{A}} &
    \lfocus{\np{\octx}_L}{\n{B}}{\np{\octx}_R}{\p{C}}}
  \\
  \infer[\lrule{\with}_1]{\lfocus{\np{\octx}_L}{\n{A} \with \n{B}}{\np{\octx}_R}{\p{C}}}{
    \lfocus{\np{\octx}_L}{\n{A}}{\np{\octx}_R}{\p{C}}}
  \quad\enspace%\and\!
  \infer[\lrule{\with}_2]{\lfocus{\np{\octx}_L}{\n{A} \with \n{B}}{\np{\octx}_R}{\p{C}}}{
    \lfocus{\np{\octx}_L}{\n{B}}{\np{\octx}_R}{\p{C}}}
  \quad\enspace%\and\!
  \text{(no $\lrule{\top}$ rule)}
  \\
  \infer[\lrule{\up}]{\lfocus{}{\up \p{A}}{}{\p{A}}}{}
\end{inferences}
The left-focus judgment's rules parallel the usual sequent calculus rules, but maintaining focus on the immediate subformulas -- left focus for subformulas of negative polarity and right focus for subformulas of positive polarity.
The $\lrule{\up}$ rule ends left focus by decomposing an $\up \p{A}$ antecedent into an $\p{A}$ consequent.

Unlike the right-focus judgment, the left-focus judgment describes a relation (or nondeterministic function), owing to the two rules, $\lrule{\with}_1$ and $\lrule{\with}_2$, that may apply to alternative conjunctions.
For example, both 
\begin{gather*}
  \lfocus{\p{a}}{(\p{a} \limp \up (\p{c} \fuse \p{a})) \with (\p{b} \limp \up \one)}{}{\p{c} \fuse \p{a}}
\shortintertext{and}
  \lfocus{\p{b}}{(\p{a} \limp \up (\p{c} \fuse \p{a})) \with (\p{b} \limp \up \one)}{}{\one}
\end{gather*}
are both derivable when the negative proposition $(\p{a} \limp \up (\p{c} \fuse \p{a})) \with (\p{a} \limp \up \one)$ is in focus.

\newthought{A focused rewriting step arises} when a negative proposition, $\n{A}$, is put into focus and the resulting consequent, $\p{C}$, is subsequently decomposed into the ordered context.\fixnote{name for this rule?}%
\footnote{Writing the right-focus judgment as $\rfocus{\np{\octx'{}}}{\p{B}}$ gives this rule the flavor of a cut principle.}
In addition, the compatibility rule $\jrule{$\reduces$C}$ is retained.
\begin{inferences}
  \infer[\jrule{$\reduces$I}]{\np{\octx}_L \oc \n{A} \oc \np{\octx}_R \reduces \np{\octx'{}}}{
    \lfocus{\np{\octx}_L}{\n{A}}{\np{\octx}_R}{\p{C}} &
    \rfocus{\np{\octx'{}}}{\p{C}}}
  \and
  \infer[\jrule{$\reduces$C}]{\np{\octx}_L \oc \np{\octx} \oc \np{\octx}_R \reduces \np{\octx}_L \oc \np{\octx'{}} \oc \np{\octx}_R}{
    \np{\octx} \reduces \np{\octx'{}}}
\end{inferences}

With this $\jrule{$\reduces$I}$ rule, it is indeed possible to rewrite\fixnote{fix}
\begin{equation*}
  \p{a} \oc \bigl((\p{a} \limp \up (\p{c} \fuse \p{a})) \with (\p{b} \limp \up \one)\bigr)
    \reduces \p{c} \oc \p{a}
\end{equation*}
in a single, atomic step because $\lfocus{\p{a}}{(\p{a} \limp \up (\p{c} \fuse \p{a})) \with (\p{b} \limp \up \one)}{}{\p{c} \fuse \p{a}}$ and $\rfocus{\p{c} \oc \p{a}}{\p{c} \fuse \p{a}}$ hold.
Moreover, the larger granularity afforded by the left- and right-focus judgments precludes the small steps that led to unintended stuck states.
For example:
\begin{equation*}
  \p{a} \oc \bigl((\p{a} \limp \up (\p{c} \fuse \p{a})) \with (\p{b} \limp \up \one)\bigr)
    \reduces \np{\octx'{}}
  \enspace\text{only if}\enspace
  \np{\octx'{}} = \p{c} \oc \p{a}
  \,.
\end{equation*}

\subsection{Recursively defined propositions and focused ordered rewriting}\label{sec:ordered-rewriting:focused:recursive}

With the revisions to the granularity of rewriting steps that the focused rewriting framework brings, we should pause to consider how recursively defined propositions interact with focused rewriting.

Previously, in the unfocused rewriting framework, recursively defined propostions such as $\defp{p} \defd (a \limp \defp{p} \fuse a) \with (b \limp \one)$ were permitted.
With the fine granularity of rewriting imposed in that framework, it took three steps to rewrite $a \oc \defp{p}$ into $\defp{p} \oc a$:
\begin{equation*}
  a \oc \defp{p} = a \oc \bigl((a \limp \defp{p} \fuse a) \with (b \limp \one)\bigr) \reduces a \oc (a \limp \defp{p} \fuse a) \reduces \defp{p} \fuse a \reduces \defp{p} \oc a
  \,.
\end{equation*}
% Consider the recursively defined proposition $p \defd (a \limp p \fuse a) \with (b \limp \one)$.
% Previously, in the unfocused rewriting framework, it took three steps to rewrite $a \oc p$ into $p \oc a$:
% \begin{equation*}
%   a \oc p = a \oc \bigl((a \limp p \fuse a) \with (b \limp \one)\bigr) \reduces a \oc (a \limp p \fuse a) \reduces p \fuse a \reduces p \oc a
%   \,.
% \end{equation*}

In the polarized, focused rewriting framework, the analogous definition with only the minimally necessary shifts is $\n{\defp{p}} \defd (\p{a} \limp \up (\dn \n{\defp{p}} \fuse \p{a})) \with (\p{b} \limp \up \one)$.
With the coarser granularity of rewriting now afforded by focusing, it takes only one focused step to rewrite $\p{a} \oc \n{\defp{p}}$ into $\n{\defp{p}} \oc \p{a}$:
\begin{gather*}
  \p{a} \oc \n{\defp{p}} = \p{a} \oc \bigl((\p{a} \limp \up (\dn \n{\defp{p}} \fuse \p{a})) \with (\p{b} \limp \up \one)\bigr) \reduces \n{\defp{p}} \oc \p{a}
\shortintertext{because}
  \lfocus{\p{a}}{\n{\defp{p}}}{}{\dn \n{\defp{p}} \fuse \p{a}}
  \qquad\text{and}\qquad
  \rfocus{\n{\defp{p}} \oc \p{a}}{\dn \n{\defp{p}} \fuse \p{a}}
  \,.
\end{gather*}

\newthought{Because the left-focus judgment} is defined inductively, not coinductively, there are some recursively defined negative propositions that cannot successfully be put into focus.
Under the definition $\n{\defp{p}} \defd \p{a} \limp \n{\defp{p}}$, for example, there are no contexts $\np{\octx}_L$ and $\np{\octx}_R$ and positive consequent $\p{C}$ for which $\lfocus{\np{\octx}_L}{\n{\defp{p}}}{\np{\octx}_R}{\p{C}}$ is derivable.
To derive a left-focus judgment on $\n{\defp{p}}$, the finite context $\octx_L$ would need to hold an infinite stream of $\p{a}$ atoms, which is impossible in an inductively defined context.

However, by inserting a double shift, $\up \dn$, which allows focus to be blurred at the $\up$, the definition can be revised to one that admits left-focusing: when $\n{\defp{p}}$ is defined by $\n{\defp{p}} \defd \p{a} \limp \up \dn \n{\defp{p}}$, the judgment $\lfocus{\p{a}}{\n{\defp{p}}}{}{\dn \n{\defp{p}}}$ is derivable.
It follows that $\p{a} \oc \n{\defp{p}} \reduces \n{\defp{p}}$.

More generally, any recursively defined proposition that does not pass through an $\up$ shift along a main branch cannot be successfully put into focus.




\begin{figure}
  \vspace*{\dimexpr-\abovedisplayskip-\abovecaptionskip\relax}
  \begin{syntax*}
    Positive props. &
      \p{A} & \p{A} \fuse \p{B} \mid \one \mid \p{a} \mid \dn \n{A}
    \\
    Negative props. &
      \n{A} & \p{A} \limp \n{B} \mid \n{B} \pmir \p{A} \mid \n{A} \with \n{B} \mid \top \mid \n{\defp{p}} \mid \up \p{A}
    \\
    Contexts &
      \np{\octx} & \np{\octx}_1 \oc \np{\octx}_2 \mid \octxe \mid \n{A} \mid \p{a}
    \\
    Signatures &
      \orsig & \orsige \mid \orsig, \n{\defp{p}} \defd \n{A}
  \end{syntax*}
  \begin{inferences}
    \infer[\rrule{\fuse}]{\rfocus{\np{\octx}_1 \oc \np{\octx}_2}{\p{A} \fuse \p{B}}}{
      \rfocus{\np{\octx}_1}{\p{A}} & \rfocus{\np{\octx}_2}{\p{B}}}
    \and
    \infer[\rrule{\one}]{\rfocus{\octxe}{\one}}{}
    \\
    \infer[\jrule{ID}\smash{^{\p{a}}}]{\rfocus{\p{a}}{\p{a}}}{}
    \and
    \infer[\rrule{\dn}]{\rfocus{\n{A}}{\dn \n{A}}}{}
  \end{inferences}
  \begin{inferences}
    \infer[\lrule{\limp}]{\lfocus{\np{\octx}_L \oc \np{\octx}_A}{\p{A} \limp \n{B}}{\np{\octx}_R}{\p{C}}}{
      \rfocus{\np{\octx}_A}{\p{A}} &
      \lfocus{\np{\octx}_L}{\n{B}}{\np{\octx}_R}{\p{C}}}
    \and
    \infer[\lrule{\pmir}]{\lfocus{\np{\octx}_L}{\n{B} \pmir \p{A}}{\np{\octx}_A \oc \np{\octx}_R}{\p{C}}}{
      \rfocus{\np{\octx}_A}{\p{A}} &
      \lfocus{\np{\octx}_L}{\n{B}}{\np{\octx}_R}{\p{C}}}
    \\
    \infer[\lrule{\with}_1]{\lfocus{\np{\octx}_L}{\n{A} \with \n{B}}{\np{\octx}_R}{\p{C}}}{
      \lfocus{\np{\octx}_L}{\n{A}}{\np{\octx}_R}{\p{C}}}
    \and
    \infer[\lrule{\with}_2]{\lfocus{\np{\octx}_L}{\n{A} \with \n{B}}{\np{\octx}_R}{\p{C}}}{
      \lfocus{\np{\octx}_L}{\n{B}}{\np{\octx}_R}{\p{C}}}
    \and
    \text{(no $\lrule{\top}$ rule)}
    \\
    \infer[\lrule{\up}]{\lfocus{}{\up \p{A}}{}{\p{A}}}{}
  \end{inferences}
  \begin{inferences}
    \infer[\jrule{$\reduces$I}]{\octx_L \oc \n{A} \oc \octx_R \reduces \octx'}{
      \lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}} &
      \rfocus{\octx'}{\p{C}}}
    \and
    \infer[\jrule{$\reduces$C}]{\octx_L \oc \octx \oc \octx_R \reduces \octx_L \oc \octx' \oc \octx_R}{
      \octx \reduces \octx'}
  \end{inferences}
  \begin{inferences}
    \infer[\jrule{$\Reduces$R}]{\octx \Reduces \octx}{}
    \and
    \infer[\jrule{$\Reduces$T}]{\octx \Reduces \octx''}{
      \octx \reduces \octx' & \octx' \Reduces \octx''}
  \end{inferences}
  \caption{The \acs*{FOR} framework for focused ordered rewriting}
\end{figure}

\clearpage

\section{Using shifts to control focusing}

With careful placement of shifts, it is possible to control the behavior of \acl{FOR} in \acs{FOR}.
It is even possible to embed unfocused ordered rewriting and weakly focused ordered rewriting within \ac{FOR} in an operationally faithful way, as we show in \cref{sec:ordered-rewriting:embed-unfocused,sec:ordered-rewriting:embed-weakly-focused}.
But first, we discuss a minimal polarization strategy for propositions.

\subsection{A minimal polarization strategy}

Because the unpolarized and polarized propositions share the same logical connectives and constants, there is an obvious polarization strategy:
Given an unpolarized proposition, insert an $\up$ in front of each positive proposition that occurs where a negative subformula is required; symmetrically, insert a $\dn$ in front of each negative proposition that occurs where a positive subformula is required.
%
For example, the unpolarized proposition $a \fuse \bigl((a \limp c \fuse a) \with (b \limp \one)\bigr)$ becomes $\p{a} \fuse \dn \bigl((\p{a} \limp \up (\p{c} \fuse \p{a})) \with (\p{b} \limp \up \one)\bigr)$ under the minimal polarization strategy.

In other words, the minimal polarization is one that adds $\up$ and $\dn$ shifts only as required.
We will frequently elide these shifts because they can be easily inferred.

% Focused ordered rewriting is sound with respect to the unfocused rewriting framework of \cref{??}, in the sense that every focused rewriting step possible
% The neighboring \lcnamecref{fig:ordered-rewriting:minimal-polarization}%
% %
% \begin{marginfigure}
%   \begin{equation*}
%     \begin{aligned}
%       \embedp{a} &= \p{a} \\
%       \embedp*{A \fuse B}
%         &= \embedp{A} \fuse \embedp{B} \\
%       \embedp{\one} &= \one \\
%       \embedp{A} &= \dn \embedn{A} \quad\text{otherwise}
%     \\[2\jot]
%       \embedn*{A \limp B}
%         &= \embedp{A} \limp \embedn{B} \\
%       \embedn*{B \pmir A}
%         &= \embedn{B} \pmir \embedp{A} \\
%       \embedn*{A \with B}
%         &= \embedn{A} \with \embedn{B} \\
%       \embedn{\top} &= \top \\
%       \embedn{A} &= \up \embedp{A} \quad\text{otherwise}
%     \\[2\jot]
%       \embed*{\octx_1 \oc \octx_2}
%         &= \embed{\octx_1} \oc \embed{\octx_2} \\
%       \embed*{\octxe} &= \octxe \\
%       \embed{A} &=
%         \begin{cases*}
%           \p{a} & if $A = a$ \\
%           \embedn{A} & otherwise
%         \end{cases*}
%     \end{aligned}
%   \end{equation*}
%   \caption{A minimal polarization strategy}\label{fig:ordered-rewriting:minimal-polarization}
% \end{marginfigure}%
% %



% \begin{equation*}
%   \begin{aligned}
%     \embedp*{A} &=
%       \begin{cases*}
%         \p{a} & if $A = a$ \\
%         \embedp{A_1} \fuse \embedp{A_2} & if $A = A_1 \fuse A_2$ \\
%         \one & if $A = \one$ \\
%         \dn \embedn{A} & otherwise
%       \end{cases*}
%     \\
%     \embedn*{A} &=
%       \begin{cases*}
%         \embedp{A_1} \limp \embedn{A_2} & if $A = A_1 \limp A_2$ \\
%         \embedn{A_2} \pmir \embedp{A_1} & if $A = A_2 \pmir A_1$ \\
%         \embedn{A_1} \with \embedn{A_2} & if $A = A_1 \with A_2$ \\
%         \top & if $A = \top$ \\
%         \up \embedp{A} & otherwise
%       \end{cases*}
%     \\
%     \embed{\octx} &=
%       \begin{cases*}
%         \embed{\octx_1} \oc \embed{\octx_2} & if $\octx = \octx_1 \oc \octx_2$ \\
%         \octxe & if $\octx = \octxe$ \\
%         \embedn{A} & if $\octx = A \neq a$ \\
%         \p{a} & if $\octx = a$
%       \end{cases*}
%   \end{aligned}
% \end{equation*}

% \begin{theorem}
%   If $\embed{\octx_1} \reduces \np{\octx}_2$, then $\octx_1 \Reduces \octx_2$ for some $\octx_2$ such that $\embed{\octx_2} = \np{\octx}_2$.
% \end{theorem}

\subsection{Embedding unfocused ordered rewriting}

With careful placement of additional, non-minimal shifts, it is possible to embed unfocused ordered rewriting within the focused ordered rewriting framework in a operationally faithful way.
Specifically, we can define a mapping, $\embed*{}$, from contexts of unpolarized propositions to contexts of negative propositions and positive atoms in a way that strongly respects the operational behavior of unfocused ordered rewriting:
\begin{itemize}[noitemsep]
\item $\octx \reduces \octx'$ implies $\embed{\octx} \reduces \embed{\octx'{}}$; and
\item $\embed{\octx} \reduces \np{\lctx'{}}$ implies $\octx \reduces \octx'$, for some $\octx'$ such that $\np{\lctx'{}} = \embed{\octx'{}}$.
\end{itemize}
That is, $\embed*{}$ will be a \emph{strong reduction bisimulation}\autocite{Sangiorgi+Walker:CUP03}.
% By appropriately placing double shifts, $\dn \up$ or $\up \dn$, between each pair of 

Essentially, this embedding inserts a double shift, $\dn \up$, in front of each proper, nonatomic subformula.
These double shifts cause chaining and inversion to be interrupted after each step, forcing the focused rewriting to mimic the small-step behavior of unfocused rewriting.

The mapping $\embed*{}$ relies on two auxiliary mappings:
% $\embed*{}$, from unpolarized propositions to negative propositions and positive atoms;
$\embedn*{}$ and $\embedp*{}$, from unpolarized propositions to negative and positive propositions, respectively.
$\embedn{A}$ and $\embedp{A}$ produce negative and positive polarizations of $A$ that insert a $\dn \up$ shift in front of every proper, nonatomic subformula of $A$.
In addition, $\embedn{A}$ prepends an $\up$ shift whenever the top-level connective of $A$ has positive polarity, whereas $\embedn{A}$ prepends a $\dn$ shift whenever $A$ is not atomic.
% $\embed{A}$ produces either a positive atom or a negative polarization of $A$, according to wheter $A$ is atomic.
%
% \begin{marginfigure}
% \begin{equation*}
%   \begin{aligned}
%     \embedp{A} &= \begin{cases*}
%                     \p{a} & if $A = a$ \\
%                     \dn \embedn{A} & otherwise
%                \end{cases*}
%     \\
%     \embedn{A} &= \begin{cases*}
%                     \up (\embedp{A_1} \fuse \embedp{A_2}) & if $A = A_1 \fuse A_2$ \\
%                     \up \one & if $A = \one$ \\
%                     \embedp{A_1} \limp \up \embedp{A_2} & if $A = A_1 \limp A_2$ \\
%                     \up \embedp{A_2} \pmir \embedp{A_1} & if $A = A_2 \pmir A_1$ \\
%                     \up \embedp{A_1} \with \up \embedp{A_2} & if $A = A_1 \with A_2$ \\
%                     \top & if $A = \top$
%                   \end{cases*}
%     \\
%     \embed{A} &= \begin{cases*}
%                    \p{a} & if $A = a$ \\
%                    \embedn{A} & otherwise
%                  \end{cases*}
%     \\
%     \embed{\octx} &= \begin{cases*}
%                        \embed{\octx_1} \oc \embed{\octx_2} & if $\octx = \octx_1 \oc \octx_2$ \\
%                        (\octxe) & if $\octx = \octxe$ \\
%                        \embed{A} & if $\octx = A$
%                      \end{cases*}
%   \end{aligned}
% \end{equation*}
% % \caption{An embedding of unfocused ordered rewriting within the focused ordered rewriting framework}
% \end{marginfigure}
\begin{marginfigure}
  \begin{equation*}
    \begin{aligned}
      \embedn*{A \fuse B} &= \up (\embedp{A} \fuse \embedp{B}) \\
      \embedn{\one} &= \up \one \\
      \embedn*{A \limp B} &= \embedp{A} \limp \up \embedp{B} \\
      \embedn*{B \pmir A} &= \up \embedp{B} \pmir \embedp{A} \\
      \embedn*{A \with B} &= \up \embedp{A} \with \up \embedp{B} \\
      \embedn{\top} &= \top
      \\
      \embedp{A} &=
        \begin{cases*}
          \p{a} & if $A = a$ \\
          \dn \embedn{A} & otherwise
        \end{cases*}
      \\
      \embed*{\octx_1 \oc \octx_2} &= \embed{\octx_1} \oc \embed{\octx_2} \\
      \embed*{\octxe} &= \octxe \\
      \embed{A} &=
        \begin{cases*}
          \p{a} & if $A = a$ \\
          \embedn{A} & otherwise
        \end{cases*}
    \end{aligned}
  \end{equation*}
  \caption{An embedding of unfocused ordered rewriting (\ie, \acs*{OR}) within \acs*{FOR}}
\end{marginfigure}

\begin{theorem}
  The embedding $\embed{(-)}$ satisfies the following properties.
  \begin{itemize}[nosep]
  \item If $\octx \reduces \octx'$, then $\embed{\octx} \reduces \embed{\octx'{}}$.
  \item If $\embed{\octx} = \np{\lctx} \reduces \np{\lctx'{}}$, then $\octx \reduces \octx'$ for some $\octx'$ such that $\np{\lctx'{}} = \embed{\octx'{}}$.
  \end{itemize}
\end{theorem}
\begin{proof}
  The proofs of these properties require a straightforward lemma:
  for all unpolarized propositions $A$, 
  \begin{equation*}
    \rfocus{\np{\lctx}}{\embedp{A}} \text{\ if, and only if, } \np{\lctx} = \embed{A}
    \,.
  \end{equation*}

  The first property is then proved by induction over the structure of the given rewriting step, $\octx \reduces \octx'$.
  As an example, consider the case in which $\octx = A \oc (A \limp B) \reduces B = \octx'$.
  By definition, $\embed{\octx} = \embed{A} \oc (\embedp{A} \limp \up \embedp{B})$ and $\embed{\octx'{}} = \embed{B}$, and we can indeed derive $\lfocus{\embed{A}}{\embedp{A} \limp \up \embedp{B}}{}{\embedp{B}}$ and $\rfocus{\embed{B}}{\embedp{B}}$.
  So, as required, $\embed{\octx} = \embed{A} \oc (\embedp{A} \limp \up \embedp{B}) \reduces \embed{B} = \embed{\octx'{}}$.

  The second property is also proved by induction over the structure of the given rewriting step, this time $\embed{\octx} = \np{\lctx} \reduces \np{\lctx'{}}$.
  As an example, consider the case in which $\lfocus{\embed{\octx_L}}{\embedp{A} \limp \up \embedp{B}}{\embed{\octx_R}}{\p{C}}$ and $\rfocus{\np{\lctx'{}}}{\p{C}}$, for some $\octx_L$, $A$, $B$, $\octx_R$, and $\p{C}$ such that $\octx = \octx_L \oc (A \limp B) \oc \octx_R$.
  By inversion and the aforementioned lemma, we have $\octx_L = A$, $\octx_R = \octxe$, $\p{C} = \embedp{B}$, and $\np{\lctx'{}} = \embed{B}$.
  Indeed, as required, $\octx = A \oc (A \limp B) \reduces B = \octx'$ and $\np{\lctx'{}} = \embed{\octx'{}}$.
\end{proof}

\subsection{Embedding weakly focused ordered rewriting}

It is similarly possible to embed weakly focused ordered rewriting, a rewriting discipline based on weak focusing\autocite{??} in which the granularity of steps lies between that of the unfocused and fully focused ordered rewriting frameworks.
More specifically, weak focusing differs from full focusing in that it retains chaining but abandons eager inversion.
For example, with weakly focused rewriting,
\begin{equation*}
  \p{a} \oc \dn \bigl((\p{a} \limp \up (\p{c} \fuse \p{a})) \with (\p{b} \limp \up \one)\bigr)
    \reduces \p{c} \fuse \p{a}
    \reduces \p{c} \oc \p{a}
  \,,
\end{equation*}
where the inversion of $\p{c} \fuse \p{a}$ is now an atomic step of its own.

This weakly focused rewriting discipline could be achieved as an independent system with the rules shown in \cref{??}.
Notice that weakly focused rewriting restricts the left- and right-handed implications to have only atomic premises.
Although weak focusing is well-defined for arbitrary implications\autocite{??}, it is not clear how to give a rewriting interpretation of weak focusing unless this restriction is made.

\begin{figure}
  \vspace*{\dimexpr-\abovedisplayskip-\abovecaptionskip\relax}
\begin{inferences}
  \infer[\jrule{$\dn$D}]{\p{\octx}_L \oc \dn \n{A} \oc \p{\octx}_R \reduces \p{C}}{
    \lfocus{\p{\octx}_L}{\n{A}}{\p{\octx}_R}{\p{C}}}
  \and
  \infer[\jrule{$\fuse$D}]{\p{A} \fuse \p{B} \reduces \p{A} \oc \p{B}}{}
  \and
  \infer[\jrule{$\one$D}]{\one \reduces \octxe}{}
  \\
  \infer[\jrule{$\reduces$C}]{\p{\octx}_L \oc \p{\octx} \oc \p{\octx}_R \reduces \p{\octx}_L \oc \p{\octx'{}} \oc \p{\octx}_R}{
    \p{\octx} \reduces \p{\octx'{}}}
\end{inferences}
\begin{inferences}
  \infer[\lrule{\limp}]{\lfocus{\p{\octx}_L \oc \p{a}}{\p{a} \limp \n{B}}{\p{\octx}_R}{\p{C}}}{
    \lfocus{\p{\octx}_L}{\n{B}}{\p{\octx}_R}{\p{C}}}
  \and
  \infer[\lrule{\pmir}]{\lfocus{\p{\octx}_L}{\n{B} \pmir \p{a}}{\p{a} \oc \p{\octx}_R}{\p{C}}}{
    \lfocus{\p{\octx}_L}{\n{B}}{\p{\octx}_R}{\p{C}}} 
  \\
  \infer[\lrule{\with}_1]{\lfocus{\p{\octx}_L}{\n{A} \with \n{B}}{\p{\octx}_R}{\p{C}}}{
    \lfocus{\p{\octx}_L}{\n{A}}{\p{\octx}_R}{\p{C}}}
  \and
  \infer[\lrule{\with}_2]{\lfocus{\p{\octx}_L}{\n{A} \with \n{B}}{\p{\octx}_R}{\p{C}}}{
    \lfocus{\p{\octx}_L}{\n{B}}{\p{\octx}_R}{\p{C}}}
  \and
  \text{(no $\lrule{\top}$ rule)}
  \\
  \infer[\lrule{\up}]{\lfocus{}{\up \p{A}}{}{\p{A}}}{}
\end{inferences}
\caption{A framework for \emph{weakly} focused ordered rewriting}
\end{figure}

In fact, there is a better approach than using weakly focused ordered rewriting as yet another independent rewriting system.
Instead of using weakly focused rewriting directly, we can embed it within \ac{FOR} by inserting shifts at specific locations and then use the embedding.
From here on, we will exclusively use this embedding when weakly focused ordered rewriting is needed.%
\begin{marginfigure}
\begin{equation*}
  \begin{aligned}
    \embedp*{\p{A}} &=
      \begin{cases*}
        \p{a} & if $\p{A} = \p{a}$ \\
        \dn \embed*{\p{A}} & otherwise
      \end{cases*}
  \\
    \embedn*{\p{a} \limp \n{B}}
      &= \p{a} \limp \embedn*{\n{B}} \\
    \embedn*{\n{B} \pmir \p{a}}
      &= \embedn*{\n{B}} \pmir \p{a} \\
    \embedn*{\n{A} \with \n{B}}
      &= \embedn*{\n{A}} \with \embedn*{\n{B}} \\
    \embedn{\top} &= \top \\
    \embedn*{\up \p{A}} &= \up \embedp*{\p{A}}
  \\
    \embed*{\p{\octx}_1 \oc \p{\octx}_2}
      &= \embed*{\p{\octx}_1} \oc \embed*{\p{\octx}_2} \\
    \embed*{\octxe} &= \octxe \\
    \embed*{\p{a}} &= \p{a} \\
    \embed*{\p{A} \fuse \p{B}} &= \up (\embedp*{\p{A}} \fuse \embedp*{\p{B}}) \\
    \embed{\one} &= \up \one \\
    \embed*{\dn \n{A}} &= \embedn*{\n{A}}
  \end{aligned}
\end{equation*}
  \caption{An embedding of weakly focused ordered rewriting (\ie, \acs*{OR}) within \acs*{FOR}}
\end{marginfigure}

% \begin{equation*}
%   \begin{aligned}
%     \embedp*{\p{A}} &= \begin{cases*}
%                     \p{a} & if $\p{A} = \p{a}$ \\
%                     \dn \up (\embedp*{\p{A}_1} \fuse \embedp*{\p{A}_2}) & if $\p{A} = \p{A}_1 \fuse \p{A}_2$ \\
%                     \dn \up \one & if $\p{A} = \one$ \\
%                     \dn \embedn*{\n{A}_0} & if $\p{A} = \dn \n{A}_0$
%                \end{cases*}
%     \\
%     \embedn*{\n{A}} &= \begin{cases*}
%                          \embedp*{\p{A}_1} \limp \embedn*{\n{A}_2} & if $\n{A} = \p{A}_1 \limp \n{A}_2$ \\
%                     \embedn*{\n{A}_2} \pmir \embedp*{\p{A}_1} & if $\n{A} = \n{A}_2 \pmir \p{A}_1$ \\
%                     \embedn*{\n{A}_1} \with \embedn*{\n{A}_2} & if $\n{A} = \n{A}_1 \with \n{A}_2$ \\
%                     \top & if $\n{A} = \top$ \\
%                     \up \embedp*{\p{A}_0} & if $\n{A} = \up \p{A}_0$
%                   \end{cases*}
%     \\
%     \embed*{\p{A}} &=
%       \begin{cases*}
%         \p{a} & if $\p{A} = \p{a}$ \\
%         \up (\embedp*{\p{A}_1} \fuse \embedp*{\p{A}_2}) & if $\p{A} = \p{A}_1 \fuse \p{A}_2$ \\
%         \up \one & if $\p{A} = \one$ \\
%         \embedn*{\n{A}_0} & if $\p{A} = \dn \n{A}_0$
%       \end{cases*}
%     \\
%     \embed*{\p{\octx}} &=
%       \begin{cases*}
%         \embed*{\p{\octx}_1} \oc \embed*{\p{\octx}_2} & if $\p{\octx} = \p{\octx}_1 \oc \p{\octx}_2$ \\
%         (\octxe) & if $\octx = \octxe$ \\
%         \embed*{\p{A}} & if $\octx = \p{A}$
%       \end{cases*}
%   \end{aligned}
% \end{equation*}

\begin{theorem}
  The embedding $\embed{(-)}$ satisfies the following properties.
  \begin{itemize}[nosep]
  \item If $\p{\octx} \reduces \p{\octx'{}}$, then $\embed*{\p{\octx}} \reduces \embed*{\p{\octx'{}}}$.
  \item If $\embed*{\p{\octx}} \reduces \np{\lctx'{}}$, then $\p{\octx} \reduces \p{\octx'{}}$ for some $\p{\octx'{}}$ such that $\np{\lctx'{}} = \embed*{\p{\octx'{}}}$.
  \end{itemize}
\end{theorem}
\begin{proof}
  The proofs of these properties require two relatively straightforward lemmas:
  for all polarized propositions $\p{A}$ and $\n{A}$,
  \begin{itemize}
  \item $\rfocus{\np{\lctx}}{\embedp*{\p{A}}}$ if, and only if, $\np{\lctx} = \embed*{\p{A}}$; and
  \item $\lfocus{\np{\lctx}_L}{\embedn*{\n{A}}}{\np{\lctx}_R}{\p{B}}$ if, and only if,
    $\lfocus{\p{\octx}_L}{\n{A}}{\p{\octx}_R}{\p{C}}$ and
    $\np{\lctx}_L = \embed*{\p{\octx}_L}$,
    $\np{\lctx}_R = \embed*{\p{\octx}_R}$, and
    $\p{B} = \embedp*{\p{C}}$.
  \end{itemize}
  Both lemmas are proved by structural induction on the polarized proposition, $\p{A}$ and $\n{A}$, respectively.

  The first of the above properties is then proved by induction over the structure of the given weakly focused rewriting step, $\p{\octx} \reduces \p{\octx'}$.
  As an example, consider the case in which $\p{\octx}_L \oc \dn \n{A} \oc \p{\octx}_R \reduces \p{C}$ because $\lfocus{\p{\octx}_L}{\n{A}}{\p{\octx}_R}{\p{C}}$.
  By the above lemma, $\lfocus{\embed*{\p{\octx}_L}}{\embedn*{\n{A}}}{\embed*{\p{\octx}_R}}{\embedp*{\p{C}}}$ holds in the fully focused calculus.
  And so, as required, $\embed*{\p{\octx}_L} \oc \embed*{\dn \n{A}} \oc \embed*{\p{\octx}_R} \reduces \embed*{\p{C}}$.

  The second property is also proved by induction over the structure of the given rewriting step, this time the fully focused $\embed*{\p{\octx}} \reduces \np{\lctx'{}}$.
  As an example, consider the case in which $\lfocus{\np{\lctx}_L}{\p{a}_1 \limp \embedn*{\n{A}_2}}{\np{\lctx}_R}{\p{B}}$ and $\rfocus{\np{\lctx'{}}}{\p{B}}$.
  Inversion yields $\lfocus{\np{\lctx'_L{}}}{\embedn*{\n{A}_2}}{\np{\lctx}_R}{\p{B}}$ for some $\np{\lctx'_L{}}$ such that $\np{\lctx}_L = \np{\lctx'_L{}} \oc \p{a}_1$.
  Then, by the above lemma, $\lfocus{\p{\octx}_L}{\n{A}_2}{\p{\octx}_R}{\p{C}}$ holds in the weakly focused calculus, with $\np{\lctx'_L{}} = \embed*{\p{\octx}_L}$, $\np{\lctx}_R = \embed*{\p{\octx}_R}$, and $\p{B} = \embedp*{\p{C}}$.
  It follows that $\lfocus{\p{\octx}_L \oc \p{a}_1}{\p{a}_1 \limp \n{A}_2}{\p{\octx}_R}{\p{C}}$, and so $\p{\octx}_L \oc \p{a}_1 \oc \dn (\p{a}_1 \limp \n{A}_2) \oc \p{\octx}_R \reduces \p{C}$.
  Also notice that $\np{\lctx}_L = \embed*{\p{\octx}_L \oc \p{a}_1}$ and $\np{\lctx'{}} = \embed*{\p{C}}$, as required.
\end{proof}


\clearpage
\clearpage

\chapter{MOVE THESE}

\section{Choreographies}

Recall the string rewriting specification
\begin{equation*}
  \infer{a \oc b \reduces b}{}
  \qquad\text{and}\qquad
  \infer{b \reduces \emp}{}
  \:.
\end{equation*}

A choreography is a refinement of this specification in which each symbol $a$ of the rewriting alphabet is mapped to an ordered proposition: either an atomic proposition, $\atmL{a}$ or $\atmR{a}$, or a recursively defined proposition, $\proc{a}$.
In other words, a choreography is an injection from symbols to propositions.
\begin{equation*}
  \begin{tikzcd}
    w \rar[reduces] \dar[dash] & w' \dar[dash, exists]
    \\
    \mathllap{\theta}(w) \rar[Reduces, exists] & \theta(w')
  \end{tikzcd}
  \begin{tikzcd}
    \mathllap{\theta}(w) \rar[reduces] \dar[dash] & \octx' \rar[Reduces, exists] & \theta(w') \dar[dash, exists]
    \\
    w \arrow[reduces, exists]{rr} && w'
  \end{tikzcd}
\end{equation*}

$\atmR{a} \oc \proc{b}$

Suppose that $\theta$ is the mapping $a \mapsto \atmR{a}$ and $b \mapsto \proc{b}$.
and the choreography
\begin{equation*}
  \proc{b} \defd (\atmR{a} \limp \proc{b}) \with \one
  \,.
\end{equation*}
Notice that 
\begin{alignat*}{2}
  &a \oc b \reduces b
  &&\quad\text{and}\quad
  b \reduces \emp
\shortintertext{as well as}
  &\atmR{a} \oc \proc{b} \reduces \atmR{a} \oc (\atmR{a} \limp \proc{b}) \reduces \proc{b}
  &&\quad\text{and}\quad
  \proc{b} \reduces \one \reduces \octxe
  \:.
\end{alignat*}


\begin{equation*}
  \infer{a \oc b \reduces b}{}
  \qquad\text{and}\qquad
  \infer{c \oc b \reduces b}{}
\end{equation*}

\begin{equation*}
  \proc{b} \defd (\atmR{a} \limp \proc{b}) \with (\atmR{c} \limp \proc{b})
\end{equation*}

\begin{equation*}
  a \oc b \reduces w' \text{ implies $w' = b$}
  \quad\text{but}\quad
  \atmR{a} \oc \proc{b} \reduces \atmR{a} \oc (\atmR{c} \limp \proc{b}) \nreduces
\end{equation*}

\autocite{McDowell+:TCS03}


Judgments $\chorsig{\theta}{\sig}{\sig'}$ and $\chorax{\theta}{w \reduces w'}{\proc{a}}{A}$.
In both judgments, all terms before the $\chorarrow$ are inputs; all terms after the $\chorarrow$ are outputs.


\begin{inferences}
  \infer{\chorsig{\theta}{\sige}{\sige}}{}
  \and
  \infer{\chorsig{\theta}{\sig, w \reduces w'}{\sig', \proc{a} \defd A_1 \with A_2}}{
    \chorsig{\theta}{\sig}{\sig'} &
    \chorax{\theta}{w \reduces w'}{\proc{a}}{A_2} &
    \text{($\sig'(\proc{a}) = A_1$)}}
  \\
  \infer{\chorsig{\theta}{\sig, w \reduces w'}{\sig', \proc{a} \defd A}}{
    \chorsig{\theta}{\sig}{\sig'} &
    \chorax{\theta}{w \reduces w'}{\proc{a}}{A} &
    \text{($\proc{a} \notin \dom{\sig'}$)}}
  \\
  \infer{\chorax{\theta}{a \reduces w'}{\proc{a}}{\up (\bigfuse \octx')}}{
    \text{($\theta(a) = \proc{a}$)} &
    \text{($\theta(w') = \octx'$)}}
  \\
  \infer{\chorax{\theta}{b \oc w \reduces w'}{\proc{a}}{\atmR{b} \limp A}}{
    \chorax{\theta}{w \reduces w'}{\proc{a}}{A} &
    \text{($\theta(b) = \atmR{b}$)}}
  \and
  \infer{\chorax{\theta}{w \oc b \reduces w'}{\proc{a}}{A \pmir \atmL{b}}}{
    \chorax{\theta}{w \reduces w'}{\proc{a}}{A} &
    \text{($\theta(b) = \atmL{b}$)}}
\end{inferences}

\begin{theorem}
  \begin{itemize}
  \item If $\chorsig{\theta}{\sig}{\sig'}$ and $w \reduces_{\sig} w'$, then $\theta(w) \reduces_{\sig'} \theta(w')$.
    If $\chorsig{\theta}{\sig}{\sig'}$ and $\octx \reduces_{\sig'} \octx'$, then $\theta^{-1}(\octx) \reduces_{\sig} \theta^{-1}(\octx')$.
  \item If $\chorax{\theta}{w \reduces w'}{\proc{a}}{A}$, then $\theta(w) \reduces_{\proc{a} \defd A} \theta(w')$.
    If $\chorax{\theta}{w \reduces w'}{\proc{a}}{A}$ and $\octx \reduces_{\proc{a} \defd A} \octx'$, then $\theta^{-1}(\octx) \reduces \theta^{-1}(\octx')$.
  \end{itemize}
\end{theorem}
\begin{proof}
  $\proc{a} \reduces \bigfuse \theta(w')$

  $\atmR{b} \oc \theta(w) \reduces_{\proc{a} \defd \atmR{b} \limp A} \theta(w')$ if $\theta(w) \reduces_{\proc{a} \defd A} \theta(w')$

  $\theta(w) \oc \atmL{b} \reduces_{\proc{a} \defd A \pmir \atmL{b}} \theta(w')$ if $\theta(w) \reduces_{\proc{a} \defd A} \theta(w')$


  
\end{proof}

When $\theta = \Set{(a, \atmR{a}), (b, \proc{b})}$, the judgment $\chorsig{\theta}{\sig}{\proc{b} \defd (\atmR{a} \limp \proc{b}) \with \one}$ holds.
However, $b \reduces \emp$ but $\proc{b} \nreduces \octxe$.



\begin{equation*}
  \begin{lgathered}
    \proc{e} \defd \up (\dn \proc{e} \fuse \dn \proc{b}_1) \pmir \atmL{i} \\
    \proc{b}_0 \defd \up \dn \proc{b}_1 \pmir \atmL{i} \\
    \proc{b}_1 \defd \up (\atmL{i} \fuse \dn \proc{b}_0) \pmir \atmL{i}
  \end{lgathered}
\end{equation*}

\begin{equation*}
  \begin{lgathered}
    \proc{e} \defd \bigl(\up (\dn \proc{e} \fuse \dn \proc{b}_1) \pmir \atmL{i}\bigr) \with (\up \atmR{z} \pmir \atmL{d})
  \end{lgathered}
\end{equation*}

\begin{equation*}
  \begin{lgathered}
    \proc{\imath} \defd (\atmR{e} \limp \up (\atmR{e} \fuse \atmR{b}_1)) \with (\atmR{b}_0 \limp \up \atmR{b}_1) \with (\atmR{b}_1 \limp \up (\dn \proc{\imath} \fuse \atmR{b}_0))
  \end{lgathered}
\end{equation*}



\subsection{}



\section{}

Atomic ordered propositions are viewed as messages; compound ordered propositions, as processes; and ordered contexts, as configurations of processes.

The ordered contexts form a monoid over the positive propositions and are given by
\begin{equation*}
  \octx \Coloneqq \octx_1 \oc \octx_2 \mid \octxe \mid \p{A}
  \,.
\end{equation*}
In keeping with the monoid laws, we treat $(\octx_1 \oc \octx_2) \oc \octx_3$ and $\octx_1 \oc (\octx_2 \oc \octx_3)$ as syntactically indistinguishable, as we also do for $\octx \oc (\octxe)$ and $\octx$ and $(\octxe) \oc \octx$.

Each atom is consistently assigned a direction, either left-directed, $\atmL{a}$, or right-directed, $\atmR{a}$.

An atom's direction and position within the larger context together indicate whether, when viewed as a message, it is being sent or received.
In the context $\octx_1 \oc \atmR{a} \oc \octx_2$, the atom $\atmR{a}$ is a message being sent from $\octx_1$ to $\octx_2$.
Symmetrically, in the context $\octx_1 \oc \atmL{a} \oc \octx_2$, the atom $\atmL{a}$ is a message being sent from $\octx_1$ to $\octx_2$.

The context $\octx = \octx' \oc \atmR{a}$ is a process configuration that sends $\atmR{a}$ to its right and continues as $\octx'$.
Conversely, $\atmR{a} \oc \octx$ is a process configuration in which $\octx$ is the intended recipient of the message $\atmR{a}$.


\begin{align*}
  \p{A} &\Coloneqq \atmL{a} \mid \atmR{a} \mid \p{\hat{p}} \mid \p{A} \fuse \p{B} \mid \one \mid \dn \n{A} \\
  \n{A} &\Coloneqq \n{\hat{p}} \mid \atmR{a} \limp \n{B} \mid \n{B} \pmir \atmL{a} \mid \n{A} \with \n{B} \mid \top \mid \up \p{A}
\end{align*}

\section{Choreographing specifications}

\begin{equation*}
  \infer{a \oc b \reduces b}{}
  \qquad\text{and}\qquad
  \infer{b \reduces \octxe}{}
\end{equation*}

As a specification, these string rewriting axioms are quite reasonable.
However, as a [...], [...].

Toward our ultimate goal of relating the proof-construction and proof-reduction appraches to concurrency, we would like a description of this concurrent system that is slightly more concrete.

\begin{align*}
  \atmR{a} \oc \hat{b} &\reduces \hat{b} \\
  \hat{b} &\reduces \octxe
\end{align*}

\begin{equation*}
  \hat{b} \defd (\atmR{a} \limp \up \dn \hat{b}) \with \one
\end{equation*}


\begin{inferences}
  \infer{e \oc i \reduces e \oc b_1}{}
  \and
  \infer{b_0 \oc i \reduces b_1}{}
  \and\text{and}\and
  \infer{b_1 \oc i \reduces i \oc b_0}{}
\end{inferences}

\begin{equation*}
  \begin{lgathered}
    \bin{e} \defd \bin{e} \fuse \bin{b}_1 \pmir \atmL{i} \\
    \bin{b}_0 \defd \bin{b}_1 \pmir \atmL{i} \\
    \bin{b}_1 \defd \atmL{i} \fuse \bin{b}_0 \pmir \atmL{i}
  \end{lgathered}
\end{equation*}

\begin{equation*}
  \begin{lgathered}
    e \simu{R} \bin{e} \\
    b_0 \simu{R} \bin{b}_0 \\
    b_1 \simu{R} \bin{b}_1 \\
    i \simu{R} \atmL{i} \\
    e \oc b_1 \simu{R} \bin{e} \fuse \bin{b}_1 \\
    i \oc b_0 \simu{R} \atmL{i} \fuse \bin{b}_0
  \end{lgathered}
\end{equation*}
$\simu{R}$ is a reduction bisimulation.

$\bin{e} \oc \atmL{i} \Reduces \bin{e} \oc \bin{b}_1$
and $e \oc i \Reduces e \oc b_1$
and $e \oc b_1 \Reduces e \oc b_1$

\begin{equation*}
  \begin{lgathered}
    \bin{\imath} \defd (\atmR{e} \limp \atmR{e} \fuse \atmR{b}_1)
               \with (\atmR{b}_0 \limp \atmR{b}_1)
               \with (\atmR{b}_1 \limp \bin{\imath} \fuse \atmR{b}_0)
  \end{lgathered}
\end{equation*}

$\atmR{e} \oc \bin{\imath} \Reduces \atmR{e} \oc \atmR{b}_1$
and $e \oc i \Reduces e \oc b_1$
and $e \oc b_1 \Reduces e \oc b_1$


\begin{equation*}
  \dfa{q} \defd \bigwith_{a \in \ialph}(\atmR{a} \limp \dfa{q}'_a)
\end{equation*}

Compare:
\begin{itemize}
\item $q \dfareduces[a] q'_a$ if, and only if, $\atmR{a} \oc \dfa{q} \reduces \dfa{q}'_a$.
\item $q \dfareduces[a] q'_a$ if, and only if, $\atmR{a} \oc \dfa{q} \reduces \octx'$ for some $\octx' = \dfa{q}'_a$.
\item $q \dfareduces[a] q'_a$ and $\dfa{q}'_a = \octx'$ for some $q'_a$ if, and only if, $\atmR{a} \oc \dfa{q} \reduces \octx'$.
\end{itemize}
These differ in the placement of the existential quantifier.
The first pair are, in fact, false.

\emph{For the former:}
Assume that $q \dfareduces[a] q''_a$ and $\dfa{q}''_a = \octx' = \dfa{q}'_a$.
It might be that the states $q''_a$ and $q'_a$ are only bisimilar, not equal.
In that case, $q \dfareduces[a]\asim q'_a$ but, in general, not $q \dfareduces[a] q'_a$ directly.

\emph{For the latter:}
Assume that $q \dfareduces[a] q''_a$ and $\dfa{q}''_a = \octx'$.
Choosing $q'_a \coloneqq q''_a$, we indeed have $q \dfareduces[a] q'_a$ and $\dfa{q}'_a = \octx'$. 

\begin{equation*}
\begin{tikzcd}
  q \rar[reduces, "a", exists] \dar[dash, "\simu{R}"'] & q'_a \dar[dash, "\simu{R}"]
  \\
  \atmR{a} \oc \dfa{q} \rar[reduces] & \octx' \mathrlap{{} = \dfa{q}'_a}
\end{tikzcd}
\qquad\qquad
\begin{tikzcd}
  q \rar[reduces, "a", exists] \dar[dash, "\simu{R}"'] & q'_a \dar[dash, "\simu{R}", exists]
  \\
  \atmR{a} \oc \dfa{q} \rar[reduces] & \octx' \mathrlap{{} = \dfa{q}'_a}
\end{tikzcd}
\end{equation*}



\section{Encoding \aclp*{DFA}}

Recall from \cref{??} our string rewriting specification of how \iac{NFA} processes its input.
Given \iac{DFA} $\aut{A} = (Q, ?, F)$ over an input alphabet $\ialph$, the \ac{NFA}'s operational semantics are adequately captured by the folllwing string rewriting axioms:
\begin{equation*}
  \infer{a \oc q \reduces q'_a}{}
  \enspace\text{for each transition $q \nfareduces[a] q'_a$.}
\end{equation*}
\begin{equation*}
  \infer{\emp \oc q \reduces F(q)}{}
  \enspace\text{for each state $q$, where}\enspace
  F(q) = \begin{cases*}
           (\octxe) & if $q \in F$ \\
           \symrej & if $q \notin F$\,.
         \end{cases*}
\end{equation*}

\subsection{A functional choreography}

One possible choreography for this specification treats the input symbols $a \in \ialph$ as atomic propositions $\atmR{a}$; states $q \in Q$ as recursively defined propostions $\proc{q}$;and the end-of-word marker $\emp$ as an atomic proposition $\atmR{\emp}$.
In other words, the \ac{NFA}'s input is treated as a sequence of messages, $\atmR{\emp} \oc \atmR{a}_n \dotsm \atmR{a}_2 \oc \atmR{a}_1$, and the \ac{NFA}'s states are treated as [recursive] processes.

$a \mapsto \atmR{a}$ for all $a \in \ialph$; $q \mapsto \proc{q}$ for all $q \in Q$; and $\emp \mapsto \atmR{\emp}$.

Using this assignment, the choreography constructed from the specification consists of the following definition, one for each \ac{NFA} state $q \in Q$:
\begin{equation*}
  \proc{q} \defd \bigwith_{a \in \ialph} \bigwith_{q\smash{'_a}} (\atmR{a} \limp \proc{q}'_a) \with (\atmR{\emp} \limp \nfa{F}(q))
  \,.
\end{equation*}

\begin{corollary}
  If $a \oc q \reduces q'_a$, then $\atmR{a} \oc \proc{q} \Reduces \proc{q}'_a$.
  If $\atmR{a} \oc \proc{q} \reduces \octx'$, then $a \oc q \reduces w'$ and $\octx' \Reduces \theta(w')$.
\end{corollary}

\begin{corollary}
  If $q \nfareduces[a] q'_a$, then $\atmR{a} \oc \proc{q} \Reduces \proc{q}'_a$.
  If $\atmR{a} \oc \proc{q} \reduces \proc{q}'_a$, then $q \nfareduces[a] q''_a$ for some $q''_a$ such that $\proc{q}'_a = \proc{q}''_a$.
\end{corollary}

As an extended example, we will use ordered rewriting to specify how \iac{DFA} processes its input.
%
% \Acp{DFA} serve as an example of ordered rewriting,  can be used to specify how \iac{DFA} processes its input.
%
Given \iac{DFA} $\aut{A} = (Q, ?, F)$ over an input alphabet $\ialph$, the idea is to encode each state, $q \in Q$, as an ordered proposition, $\dfa{q}$, in such a way that the \ac{DFA}'s operational semantics are adequately captured by [ordered] rewriting.
%
% The basic idea is to define an encoding, $\dfa{q}$, of \ac{DFA} states as ordered propositions;
% this encoding should adequately reflect the \ac{DFA}'s operational semantics with ordered rewriting traces.
\fixnote{[In general, the behavior of \iac{DFA} state is recursive, so the proposition $\dfa{q}$ will be recursively defined.]}
%
% finite input words, $w \in \finwds{\ialph}$, are encoded as ordered contexts by $\emp \oc \rev{w}$

% \NewDocumentCommand \rev { s m } {
%   \IfBooleanTF {#1}
%     { (#2)^{\mathsf{R}} }
%     { #2^{\mathsf{R}} }
% }

% \begin{align*}
%   \rev{a} &= a \\
%   \rev*{w_1 \wc w_2} &= \rev{w_2} \oc \rev{w_1} \\
%   \rev{\emp} &= \octxe
% \end{align*}

Ideally, \ac{DFA} transitions $q \dfareduces[a] q'_a$ would be in bijective correspondence with rewriting steps $a \oc \dfa{q} \reduces \dfa{q}'_a$, where each input symbol $a$ is encoded by a matching [propositional] atom.
%
We will return to the possibility of this kind of tight correspondence in \cref{??}, but,
%
for now, we will content ourselves with a correspondence with traces rather than individual steps, adopting the following desiderata:
% Unfortunately, ordered rewriting's small step size turns out to be a poor match for [...], so in both cases we will instead content ourselves with corrspondances with \emph{traces}:
% a bijection between transitions $q \dfareduces[a] q'_a$ and \emph{traces} $a \oc \dfa{q} \Reduces \dfa{q}'_a$.
% Similarly, [...] a bijection between accepting states $q \in F$ and traces $\emp \oc \dfa{q} \Reduces \octxe$.
%
% This leads us to adopt the following as desiderata:
\begin{itemize}
\item
  $q \dfareduces[a] q'_a$ if, and only if, $a \oc \dfa{q} \Reduces \dfa{q}'_a$, for all input symbols $a \in \ialph$.
\item
  $q \in F$ if, and only if, $\emp \oc \dfa{q} \Reduces \one$, where the atom $\emp$ functions as an end-of-word marker.
% \item
%   $q \dfareduces[w] q'_w \in F$ if, and only if, $\emp \oc \rev{w} \oc \dfa{q} \Reduces \octxe$.
%   Also, $q \dfareduces[w] q'_w \notin F$ if, and only if, $\emp \oc \rev{w} \oc \dfa{q} \Reduces \top$.
\end{itemize}
Given the reversal (anti-)\-homo\-morph\-ism from finite words to ordered contexts defined in the adjacent \lcnamecref{fig:ordered-rewriting:reversal}%
\begin{marginfigure}
  \begin{align*}
    \rev*{w_1 \wc w_2} &= \rev{w_2} \oc \rev{w_1} \\
    \rev{\emp} &= \octxe \\
    \rev{a} &= a
  \end{align*}
  \caption{An (anti-)\-homo\-morph\-ism for reversal of finite words to ordered contexts}\label{fig:ordered-rewriting:reversal}
\end{marginfigure}%
, the first desideratum is subsumed by a third:
% property that covers finite words:
\begin{itemize}[resume*]
\item $q \dfareduces[w] q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$, for all finite words $w \in \finwds{\ialph}$.
\end{itemize}

From these desiderata [and the observation that \acp{DFA}' graphs frequently%
\fixnote{Actually, there is always at least one cycle in a well-formed \ac{DFA}.}
contain cycles], we arrive at the following encoding, in which each state is encoded by one of a collection of mutually recursive definitions:%
\fixnote{$q'_a$, using function or relation?}
\begin{gather*}
  \dfa{q} \defd
    \parens[size=big]{
      \bigwith_{a \in \ialph}(a \limp \dfa{q}'_a)}
    \with
    \parens[size=big]{\emp \limp \dfa{F}(q)}
  % \text{where
  %   $q \dfareduces[a] q'_a$ for all $a \in \ialph$
  %   and
  %   $\dfa{F}(q) = 
  %     \begin{cases*}
  %       \one & if $q \in F$ \\
  %       \top & if $q \notin F$
  %     \end{cases*}$%
  % }
  %
\shortintertext{where}
  %
  q \dfareduces[a] q'_a
  \text{, for all input symbols $a \in \ialph$,\quad and\quad}
  \dfa{F}(q) = 
    \begin{cases*}
      \one & if $q \in F$ \\
      \top & if $q \notin F$%
    \,.
    \end{cases*}
\end{gather*}
Just as each state $q$ has exactly one successor for each input symbol $a$, its encoding, $\dfa{q}$, has exactly one input clause, $(a \limp \dotsb)$, for each symbol $a$.



% The traces $a \oc \dfa{q} \Reduces \dfa{q}'_a$
% % for input symbols $a \in \ialph$
% suggest that $\dfa{q}$ should be a collection of clauses that input atoms $a$ from the left.
% And the traces $\emp \oc \dfa{q} \Reduces \octxe$ or $\emp \oc \dfa{q} \Reduces \top$ suggest that $\dfa{q}$ also contain a clause that inputs atom $\emp$ from the left.
% Thus, we arrive at the encoding


\newthought{For a concrete instance} of this encoding, recall from \cref{ch:automata} the \ac{DFA} (repeated in the adjacent \lcnamecref{fig:ordered-rewriting:dfa-example-ends-b})%
%
\begin{marginfigure}
  \begin{equation*}
    \mathllap{\aut{A}_2 = {}}
    \begin{tikzpicture}[baseline=(q_0.base)]
      \graph [automaton] {
        q_0
         -> [loop above, "a"]
        q_0
         -> ["b", bend left]
        q_1 [accepting]
         -> [loop above, "b"]
        q_1
         -> ["a", bend left]
        q_0;
      };
    \end{tikzpicture}
  \end{equation*}
  \caption{\Iac*{DFA} that accepts, from state $q_0$, exactly those words that end with $b$. (Repeated from \cref{fig:dfa-example-ends-b}.)}\label{fig:ordered-rewriting:dfa-example-ends-b}
\end{marginfigure}
%
that accepts exactly those words, over the alphabet $\ialph = \set{a,b}$, that end with $b$; that \ac{DFA} is encoded by the following definitions:
\begin{equation*}
  \begin{lgathered}
    \dfa{q}_0 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top) \\
    \dfa{q}_1 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one)
  \end{lgathered}
\end{equation*}
Indeed, just as the \ac{DFA} has a transition $q_0 \dfareduces[b] q_1$, its encoding admits a trace
\begin{align*}
  &b \oc \dfa{q}_0
     = b \oc \bigl((a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top)\bigr)
     \Reduces b \oc (b \limp \dfa{q}_1)
     \reduces \dfa{q}_1
  \,.
\intertext{And, just as $q_1$ is an accepting state, its encoding also admits a trace}
  &\emp \oc \dfa{q}_1 = \emp \oc \bigl((a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one)\bigr) \Reduces \emp \oc (\emp \limp \one) \reduces \one
  \,.
\end{align*}

\newthought{More generally}, this encoding is complete, in the sense that it simulates all \ac{DFA} transitions: $q \dfareduces[a] q'$ implies $a \oc \dfa{q} \Reduces \dfa{q}'$, for all states $q$ and $q'$ and input symbols $a$.

However, the converse does not hold -- the encoding is unsound because there are rewritings that cannot be simulated by \iac{DFA} transition.
% That is, $a \oc \dfa{q} \Reduces \dfa{q}'$ does \emph{not} imply $q \dfareduces[a] q'$.
% 
\begin{falseclaim}
  Let $\aut{A} = (Q, \mathord{\dfareduces}, F)$ be \iac{DFA} over the input alphabet $\ialph$.
  Then $a \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[a] q'$, for all input symbols $a \in \ialph$.
\end{falseclaim}
%
\begin{marginfigure}
    \centering
    % \subfloat[][]{\label{fig:ordered-rewriting:dfa-counterexample:dfa}%
      \begin{equation*}
        \aut{A}'_2 = 
      \begin{tikzpicture}[baseline=(q_0.base)]
        \graph [automaton] {
          q_0
           -> [loop above, "a"]
          q_0
           -> ["b", bend left]
          q_1 [accepting]
           -> [loop above, "b"]
          q_1
           -> ["a", bend left]
          q_0;
          %
%          { [chain shift={(2,0)}]
            s_1 [accepting, below=1.5em of q_1.south]
             -> [loop right, "b"]
            s_1
             -> ["a", bend left]
            q_0;
%          };
        };
      \end{tikzpicture}
    \end{equation*}
    % }
    % \subfloat[][]{\label{fig:ordered-rewriting:dfa-counterexample:encoding}%
      $\!\begin{aligned}
        \dfa{q}_0 &\defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top) \\
        \dfa{q}_1 &\defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one) \\
        \dfa{s}_1 &\defd (a \limp \dfa{q}_0) \with (b \limp \dfa{s}_1) \with (\emp \limp \one)
      \end{aligned}$%
    % }
    \caption{{fig:ordered-rewriting:dfa-counterexample:dfa}~A slightly modified version of the \ac*{DFA} from \cref{fig:ordered-rewriting:dfa-example-ends-b}; and {fig:ordered-rewriting:dfa-counterexample:encoding}~its encoding}\label{fig:ordered-rewriting:dfa-counterexample}
  \end{marginfigure}%
\begin{proof}[Counterexample]
  Consider the \ac{DFA} and encoding shown in the adjacent \lcnamecref{fig:ordered-rewriting:dfa-counterexample}; it is the same \ac{DFA} as shown in \cref{fig:ordered-rewriting:dfa-example-ends-b}, but with one added state, $s_1$, that is unreachable from $q_0$ and $q_1$.
    %
  % When encoded as an ordered rewriting specification, it corresponds to the following definitions:
  % \begin{equation*}
  %   \begin{lgathered}
  %     \dfa{q}_0 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top) \\
  %     \dfa{q}_1 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one) \\
  %     \dfa{s}_1 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{s}_1) \with (\emp \limp \one)
  %   \end{lgathered}
  % \end{equation*}
  Notice that, as a coinductive consequence of the equirecursive treatment of definitions, $\dfa{q}_1 = \dfa{s}_1$.
  Previously, we saw that $b \oc \dfa{q}_0 \Reduces \dfa{q}_1$; hence $b \oc \dfa{q}_0 \Reduces \dfa{s}_1$.
  However, the \ac{DFA} has no $q_0 \dfareduces[b] s_1$ transition (because $q_1 \neq s_1$), and so this encoding is unsound with respect to the operational semantics of \acp{DFA}.
\end{proof}

As this counterexample shows, the lack of adequacy stems from attempting to use an encoding that is not injective -- here, $q_1 \neq s_1$ even though $\dfa{q}_1 = \dfa{s}_1$.
In other words, eqality of state encodings is a coarser eqvivalence than equality of the states themselves.

One possible remedy for this lack of adequacy might be to revise the encoding to have a stronger nominal character.
By tagging each state's encoding with an atom that is unique to that state, we can make the encoding manifestly injective.
For instance, given the pairwise distinct atoms $\Set{q \given q \in F}$ and $\Set{\bar{q} \given q \in Q - F}$ to tag final and non-final states, respectively, we could define an alternative encoding, $\check{q}$:
%
\begin{gather*}
  \check{q} \defd
    \parens[size=big]{
      \bigwith_{a \in \ialph}(a \limp \check{q}'_a)}
    \with
    \parens[size=big]{\emp \limp \check{F}(q)}
  %
  \shortintertext{where}
  %
  q \dfareduces[a] q'_a
  \text{, for all input symbols $a \in \ialph$,\quad and\quad}
  \check{F}(q) =
    \begin{cases*}
      q & if $q \in F$ \\
      \bar{q} & if $q \notin F$%
    \,.
    \end{cases*}
\end{gather*}
%
Under this alternative encoding, the states $q_1$ and $s_1$ of \cref{fig:ordered-rewriting:dfa-counterexample} are no longer a counterexample to injectivity:
Because $q_1$ and $s_1$ are distinct states, they correspond to distinct tags, and so $\check{q}_1 \neq \check{s}_1$.

% One possible remedy
% % for this apparent lack of adequacy
% might be to revise the encoding to have a stronger nominal character % .
% by tagging each state's encoding with an atom that is unique to that state.
% For instance, given the pairwise distinct atoms $\set{q \given q \in F}$ and $\set{\bar{q} \given q \in Q - F}$ to tag final and non-final states, respectively, we could define an alternative encoding, $\check{q}$, that is manifestly injective:
% %
% % \begin{marginfigure}
% \begin{gather*}
%   \check{q} \defd
%     \parens[size=big]{
%       \bigwith_{a \in \ialph}(a \limp \check{q}'_a)}
%     \with
%     \parens[size=big]{\emp \limp \check{F}(q)}
%   %
%   \shortintertext{where}
%   %
%   q \dfareduces[a] q'_a
%   \text{, for all input symbols $a \in \ialph$,\quad and\quad}
%   \check{F}(q) =
%     \begin{cases*}
%       q & if $q \in F$ \\
%       \bar{q} & if $q \notin F$%
%     \,.
%     \end{cases*}
% \end{gather*}
% % \end{marginfigure}%
% % , the encoding can be made to be injective.
% % With this change, the alternative encoding is now injective: $\check{q} = \check{s}$ implies $q = s$.

Although such a solution is certainly possible, it seems unsatisfyingly ad~hoc.
A closer examination of the preceding counterexample reveals that the states $q_1$ and $s_1$, while not equal, are in fact bisimilar~\parencref{??}.
In other words, although the encoding is not, strictly speaking, injective, it is injective \emph{up to bisimilarity}: $\dfa{q} = \dfa{s}$ implies $q \asim s$.
This suggests a more elegant solution to the apparent lack of adequacy: the encoding's adequacy should be judged up to \ac{DFA} bisimilarity.
%
\newcommand{\dfaadequacybisimbody}{%
  Let $\aut{A} = (Q, ?, F)$ be \iac{DFA} over the input alphabet $\ialph$.
  Then, for all states $q$, $q'$, and $s$:
  \begin{enumerate}
  \item\label{enum:ordered-rewriting:dfa-adequacy:1}
    $q \asim s$ if, and only if, $\dfa{q} = \dfa{s}$.
  \item\label{enum:ordered-rewriting:dfa-adequacy:2}
    $q \asim\dfareduces[a]\asim q'$ if, and only if, $a \oc \dfa{q} \Reduces \dfa{q}'$, for all input symbols $a \in \ialph$.    
    More generally, $q \asim\dfareduces[w]\asim q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$, for all finite words $w \in \finwds{\ialph}$.
  \item\label{enum:ordered-rewriting:dfa-adequacy:3}
    $q \in F$ if, and only if, $\emp \oc \dfa{q} \Reduces \one$.
  \end{enumerate}%
}%
%  
\begin{restatable*}[
  name=\ac*{DFA} adequacy up to bisimilarity,
  label=thm:ordered-rewriting:dfa-adequacy-bisim
]{theorem}{dfaadequacybisim}
  \dfaadequacybisimbody
% Let $\aut{A} = (Q, \mathord{\dfareduces}, F)$ be \iac{DFA} over the input alphabet $\ialph$.
%   Then, for all states $q$, $q'$, and $s$:
%   \begin{enumerate}
%   \item\label{enum:ordered-rewriting:dfa-adequacy:1}
%     $q \asim s$ if, and only if, $\dfa{q} = \dfa{s}$.
%   \item\label{enum:ordered-rewriting:dfa-adequacy:2}
%     $q \asim\dfareduces[a]\asim q'$ if, and only if, $a \oc \dfa{q} \Reduces \dfa{q}'$, for all input symbols $a \in \ialph$.    
%     More generally, $q \asim\dfareduces[w]\asim q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$, for all finite words $w \in \finwds{\ialph}$.
%   \item\label{enum:ordered-rewriting:dfa-adequacy:3}
%     $q \in F$ if, and only if, $\emp \oc \dfa{q} \Reduces \one$.
%   \end{enumerate}
\end{restatable*}

Before proving this \lcnamecref{thm:ordered-rewriting:dfa-adequacy-bisim}, we must first prove a \lcnamecref{lem:ordered-rewriting:dfa-traces}: the only traces from one state's encoding to another's are the trivial traces.
%
\begin{lemma}\label{lem:ordered-rewriting:dfa-traces}
  Let $\aut{A} = (Q, ?, F)$ be \iac{DFA} over the input alphabet $\ialph$.
  For all states $q$ and $s$, if $\dfa{q} \Reduces \dfa{s}$, then $\dfa{q} = \dfa{s}$.
\end{lemma}
%
\begin{proof}
  Assume that a trace $\dfa{q} \Reduces \dfa{s}$ exists.
  If the trace is trivial, then $\dfa{q} = \dfa{s}$ is immediate.
  Otherwise, the trace is nontrivial and consists of a strictly positive number of rewriting steps.
  By inversion, those rewriting steps drop one or more conjuncts from $\dfa{q}$ to form $\dfa{s}$.
  Every \ac{DFA} state's encoding contains exactly $\card{\ialph} + 1$ conjuncts -- one for each input symbol $a$ and one for the end-of-word marker, $\emp$.
  % Being the encoding of \iac{DFA} state, $\dfa{q}$ contains one $(\emp \limp \dotsb)$ conjunct and exactly one $(a \limp \dotsb)$ conjunct for each input symbol $a$.
  % Similarly, $\dfa{s}$ must contain the same.
  If even one conjunct is dropped from $\dfa{q}$, not enough conjuncts will remain to form $\dfa{s}$.
  Thus, a nontrivial trace $\dfa{q} \Reduces \dfa{s}$ cannot exist.
\end{proof}
%
\noindent
It is important to differentiate this \lcnamecref{lem:ordered-rewriting:dfa-traces} from the false claim that a state's encoding can take no rewriting steps.
There certainly exist nontrivial traces from $\dfa{q}$, but they do not arrive at the encoding of any state.

With this \lcnamecref{lem:ordered-rewriting:dfa-traces} now in hand, we can proceed to proving adequacy up to bisimilarity.
%
\dfaadequacybisim
%
\begin{proof}
  Each part is proved in turn.
  The proof of part~\ref{enum:ordered-rewriting:dfa-adequacy:2} % and~\ref{enum:ordered-rewriting:dfa-adequacy:4}
  depends on the proof of part~\ref{enum:ordered-rewriting:dfa-adequacy:1}.
  \begin{enumerate}[parsep=0em, listparindent=\parindent]
  %% Part one
  \item
    We shall show that bisimilarity coincides with equality of encodings, proving each direction separately.
    \begin{itemize}[parsep=0em, listparindent=\parindent]
    \item
      To prove that bisimilar \ac{DFA} states have equal encodings -- \ie, that $q \asim s$ implies $\dfa{q} = \dfa{s}$ -- a fairly straightforward proof by coinduction suffices.

      Let $q$ and $s$ be bisimilar states.
      By the definition of bisimilarity~\parencref{??}, two properties hold:
      \begin{itemize}
      \item For all input symbols $a$, the unique $a$-successors of $q$ and $s$ are also bisimilar.
      \item States $q$ and $s$ have matching finalities -- \ie, $q \in F$ if and only if $s \in F$.
      \end{itemize}
      Applying the coinductive hypothesis to the former property, we may deduce that, for all symbols $a$, the $a$-successors of $q$ and $s$ also have equal encodings.
      From the latter property, it follows that $\dfa{F}(q) = \dfa{F}(s)$.
      Because definitions are interpreted equirecursively, these equalities together imply that $q$ and $s$ themselves have equal encodings.

    \item
      To prove the converse -- that states with equal encodings are bisimilar -- we will show that the relation $\mathord{\simu{R}} = \Set{(q, s) \given \dfa{q} = \dfa{s}}$, which relates states if they have equal encodings, is a bisimulation and is therefore included in bisimilarity.
      \begin{itemize}
      \item
        The relation $\simu{R}$ is symmetric.
      \item
        We must show that $\simu{R}$-related states have $\simu{R}$-related $a$-successors, for all input symbols $a$.

        Let $q$ and $s$ be $\simu{R}$-related states.
        Being $\simu{R}$-related, $q$ and $s$ have equal encodings;
        because definitions are interpreted equirecursively, the unrollings of those encodings are also equal.
        By definition of the encoding, it follows that, for each input symbol $a$, the unique $a$-successors of $q$ and $s$ have equal encodings.
        Therefore, for each $a$, the $a$-successors of $q$ and $s$ are themselves $\simu{R}$-related.

      \item
        We must show that $\simu{R}$-related states have matching finalities.

        Let $q$ and $s$ be $\simu{R}$-related states, with $q$ a final state.
        Being $\simu{R}$-related, $q$ and $s$ have equal encodings;
        because definitions are interpreted equirecursively, the unrollings of those encodings are also equal.
        It follows that $\dfa{F}(q) = \dfa{F}(s)$, and so $s$ is also a final state.
      \end{itemize}
    \end{itemize}

  %% Part two
  \item
    We would like to prove that $q \asim\dfareduces[a]\asim q'$ if, and only if, $a \oc \dfa{q} \Reduces \dfa{q}'$, or, more generally, that $q \asim\dfareduces[w]\asim q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$.
    Because bisimilar states have equal encodings (part~\ref{enum:ordered-rewriting:dfa-adequacy:1}) and bisimilarity is reflexive (\cref{??}), it suffices to show two stronger statements:
    \begin{enumerate*}
    \item that $q \dfareduces[w] q'$ implies $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$; and
    \item that $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[w]\asim q'$.
    \end{enumerate*}
    %
    We prove these in turn.
    %
    \begin{enumerate}
    %% Subpart (a)
    \item
      We shall prove that $q \dfareduces[w] q'$ implies $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$ by induction over the structure of word $w$.
      \begin{itemize}
      \item
        Consider the case of the empty word, $\emp$; we must show that $q = q'$ implies $\dfa{q} \Reduces \dfa{q}'$.
        Because the encoding is a function, this is immediate.
      \item
        Consider the case of a nonempty word, $a \wc w$; we must show that $q \dfareduces[a]\dfareduces[w] q'$ implies $\rev{w} \oc a \oc \dfa{q} \Reduces \dfa{q}'$.
        Let $q'_a$ be an $a$-successor of state $q$ that is itself $w$-succeeded by state $q'$.
        There exists, by definition of the encoding, a trace
        \begin{equation*}
          \rev{w} \oc a \oc \dfa{q}
            \Reduces \rev{w} \oc a \oc (a \limp \dfa{q}'_a)
            \reduces \rev{w} \oc \dfa{q}'_a
            \Reduces \dfa{q}'
          \,,
        \end{equation*}
        with the trace's tail justified by an appeal to the inductive hypothesis.
        % Because $q'$ is a $w$-successor of $q'_a$, an appeal to the inductive hypothesis yields a trace $\rev{w} \oc \dfa{q}'_a \Reduces \dfa{q}'$.
      \end{itemize}

      % Let $q'$ be an $a$-successor of state $q$.
      % There exists, by definition of the encoding, a trace
      % \begin{equation*}
      %   a \oc \dfa{q} \Reduces a \oc (a \limp \dfa{q}') \reduces \dfa{q}'
      % \,.
      % \end{equation*}

    %% Subpart (b)
    \item
      We shall prove that $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[w]\asim q'$ by induction over the structure of word $w$.
      \begin{itemize}
      \item
        Consider the case of the empty word, $\emp$;
        we must show that $\dfa{q} \Reduces \dfa{q}'$ implies $q \asim q'$.
        By \cref{lem:ordered-rewriting:dfa-traces}, $\dfa{q} \Reduces \dfa{q}'$ implies that $q$ and $q'$ have equal encodings.
        Part~\ref{enum:ordered-rewriting:dfa-adequacy:1} can then be used to establish that $q$ and $q'$ are bisimilar.
      \item
        Consider the case of a nonempty word, $a \wc w$;
        we must show that $\rev{w} \oc a \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[a]\dfareduces[w]\asim q'$.
        By inversion\fixnote{Is this enough justification?}, the given trace can only begin by inputting $a$:
        \begin{equation*}
          \rev{w} \oc a \oc \dfa{q}
            \Reduces \rev{w} \oc a \oc (a \limp \dfa{q}'_a)
            \reduces \rev{w} \oc \dfa{q}'_a
            \Reduces \dfa{q}'
          \,,
        \end{equation*}
        where $q'_a$ is an $a$-successor of state $q$.
        An appeal to the inductive hypothesis on the trace's tail yields $q'_a \dfareduces[w]\asim q'$, and so the \ac{DFA} admits $q \dfareduces[a]\dfareduces[w]\asim q'$, as required.
      \end{itemize}
      % Assume that a trace $a \oc \dfa{q} \Reduces \dfa{q}'$ exists.
      % By the input lemma, $\dfa{q} \Reduces (a \limp A) \oc \octx'$ for some proposition $A$ and context $\octx'$ such that $A \oc \octx' \Reduces \dfa{q}'$.
      % Upon inversion of the trace from $\dfa{q}$, we conclude that $A = \dfa{q}'_a$, where $q'_a$ is an $a$-successor of $q$, and that $\octx'$ is empty -- in other words, we have a trace $\dfa{q}'_a \Reduces \dfa{q}'$.
      % Such a trace exists only if $\dfa{q}'_a = \dfa{q}'$.
      % By part~\ref{enum:ordered-rewriting:dfa-adequacy:1} of this \lcnamecref{thm:ordered-rewriting:dfa-adequacy-bisim}, it follows that $q'_a$ and $q'$ are bisimilar.
    \end{enumerate}

  %% Part three
  \item
    We shall prove that the final states are exactly those states $q$ such that $\emp \oc \dfa{q} \Reduces \one$.
    \begin{itemize}
    \item
      Let $q$ be a final state; accordingly, $\dfa{F}(q) = \one$.
      There exists, by definition of the encoding, a trace
      \begin{equation*}
        \emp \oc \dfa{q} \Reduces \emp \oc (\emp \limp \dfa{F}(q)) \reduces \dfa{F}(q) = \one
      \,.
      \end{equation*}

    \item
      Assume that a trace $\emp \oc \dfa{q} \Reduces \one$ exists.
      By inversion\fixnote{Is this enough justification?}, this trace can only begin by inputting $\emp$:
      \begin{equation*}
        \emp \oc \dfa{q} \Reduces \emp \oc (\emp \limp \dfa{F}(q)) \reduces \dfa{F}(q) \Reduces \one
      \,.
      \end{equation*}
      The tail of this trace, $\dfa{F}(q) \Reduces \one$, can exist only if $q$ is a final state.
    %
    \qedhere
    \end{itemize}

  % %% Part four
  % \item 
  %   We would like to prove that $q \asim\dfareduces[w]\asim q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$.
  %   Because bisimilar states have equal encodings (part~\ref{enum:ordered-rewriting:dfa-adequacy:1}) and bisimilarity is reflexive (\cref{??}), it suffices to show:
  %   \begin{enumerate*}
  %   \item that $q \dfareduces[w] q'$ implies $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$; and
  %   \item that $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[w]\asim q'$.
  %   \end{enumerate*}

  %   Both statements can be established by induction over the structure of word $w$.
  %   The latter proof is slightly more involved and deserves a bit of explanation.
  %   \begin{itemize}
  %   \item Consider the case in which $w$ is the empty word; we must show that $\dfa{q} \Reduces \dfa{q}'$ implies $q \asim q'$.
  %     By \cref{lem:ordered-rewriting:dfa-traces}, $\dfa{q} \Reduces \dfa{q}'$ implies that $\dfa{q} = \dfa{q}'$.
  %     Part~\ref{enum:ordered-rewriting:dfa-adequacy:1} can then be used to establish $q$ and $q'$ as bisimilar.

  %   \item Consider the case of a nonempty word, $a \wc w$.
  %     We must show that $\rev{w} \oc a \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[a]\dfareduces[w]\asim q'$.
  %     By inversion, the given trace must begin by inputting $a$:
  %     \begin{equation*}
  %       \rev{w} \oc a \oc \dfa{q} \Reduces \rev{w} \oc a \oc (a \limp \dfa{q}'_a) \reduces \rev{w} \oc \dfa{q}'_a \Reduces \dfa{q}'
  %       \,,
  %     \end{equation*}
  %     where $q'_a$ is an $a$-successor of state $q$.
  %     Appealing to the inductive hypothesis on the trace's tail yields $q'_a \dfareduces[w]\asim q'$, and so $q \dfareduces[a]\dfareduces[w]\asim q'$, as required.
  %   %
  %   \qedhere
  %   \end{itemize}
  \end{enumerate}
\end{proof}


\subsection{Encoding \aclp*{NFA}?}

We would certainly be remiss if we did not attempt to generalize the rewriting specification of \acp{DFA} to one for their nondeterministic cousins.

Differently from \ac{DFA} states, \iac{NFA} state $q$ may have several nondeterministic successors for each input symbol $a$.
To encode the \ac{NFA} state $q$, all of its $a$-successors are collected in an alternative conjunction underneath the left-handed input of $a$.
Thus, the encoding of \iac{NFA} state $q$ becomes
\begin{equation*}
  \nfa{q} \defd
    \parens[size=auto]{\displaystyle
      \bigwith_{a \in \ialph}
        \parens[size=big]{a \limp \parens{\bigwith_{q'_a} \nfa{q}'_a}}
    }
    \with
    \parens[size=big]{\emp \limp \nfa{F}(q)}
  \,,
\end{equation*}
where $\nfa{F}(q)$ is defined as for \acp{DFA}.

The adjacent \lcnamecref{fig:ordered-rewriting:nfa-example}
\begin{marginfigure}
  \centering
  % \subfloat[][]{\label{fig:ordered-rewriting:nfa-example:nfa}%
    \begin{tikzpicture}
      \graph [automaton] {
        q_0
         -> ["a,b", loop above]
        q_0
         -> ["b"]
        q_1 [accepting]
         -> ["a,b"]
        q_2
         -> ["a,b", loop above]
        q_2;
      };
    \end{tikzpicture}
  % }

%   \subfloat[][]{\label{fig:ordered-rewriting:nfa-example:encoding}%
      $\!\begin{aligned}
        \nfa{q}_0 &\defd (a \limp \nfa{q}_0) \with \bigl(b \limp (\nfa{q}_0 \with \nfa{q}_1)\bigr) \with (\emp \limp \top) \\
        \nfa{q}_1 &\defd (a \limp \nfa{q}_2) \with (b \limp \nfa{q}_2) \with (\emp \limp \one) \\
        \nfa{q}_2 &\defd (a \limp \nfa{q}_2) \with (b \limp \nfa{q}_2) \with (\emp \limp \top)
      \end{aligned}$
%     }

  \caption{{fig:ordered-rewriting:nfa-example:nfa}~\Iac*{NFA} that accepts exactly those words, over the alphabet $\ialph = \set{a,b}$, that end with $b$; and {fig:ordered-rewriting:nfa-example:encoding}~its encoding}\label{fig:ordered-rewriting:nfa-example}
\end{marginfigure}%
recalls from \cref{ch:automata} \iac{NFA} that accepts exactly those words, over the alphabet $\ialph = \set{a,b}$, that end with $b$.
Using the above encoding of \acp{NFA}, ordered rewriting does indeed simulate this \ac{NFA}.
For example, just as there are transitions $q_0 \nfareduces[b] q_0$ and $q_0 \nfareduces[b] q_1$, there are traces
\begin{equation*}
  \begin{tikzcd}[
    cells={inner xsep=0.65ex,
           inner ysep=0.4ex},
         % nodes={draw},
    row sep=0em,
    column sep=scriptsize
  ]
    &[-0.2em] \nfa{q}_0
    \\
    b \oc \nfa{q}_0 \Reduces b \oc \bigl(b \limp (\nfa{q}_0 \with \nfa{q}_1)\bigr) \reduces \nfa{q}_0 \with \nfa{q}_1
      \urar[reduces, start anchor=east]
      \drar[reduces, start anchor=base east]
    \\
    & \nfa{q}_1
  \end{tikzcd}
\end{equation*}

Unfortunately, while it does simulate \ac{NFA} behavior, this encoding is not adequate.
Like \ac{DFA} states, \ac{NFA} states that have equal encodings are bisimilar.
% \begin{proof}
%   Define a relation $\mathord{\simu{R}} = \set{(q, s) \given \nfa{q} = \nfa{s}}$; we will show that $\simu{R}$ is a bisimulation.
%   \begin{itemize}
%   \item Assume that $s \simu{R}^{-1} q \nfareduces[a] q'_a$.
%     By definition, $a \oc \nfa{q} \Reduces \nfa{q}'_a$.
%     Because $\nfa{q} = \nfa{s}$, it follows that $s \nfareduces[a] s'_a$ for some state $s'_a$ such that $\nfa{q}'_a = \nfa{s}'_a$ -- that is, $q'_a \simu{R} s'_a$.
%     Thus, $s \nfareduces[a]\simu{R}^{-1} q'_a$.
%   \item Assume that $q \simu{R} s$.
%     It follows that $\nfa{F}(q) = \nfa{F}(s)$.
%     Thus, $q$ is an accepting state if and only if $s$ is.
%   \end{itemize}
% \end{proof}
However, for \acp{NFA}, the converse does not hold: bisimilar states do not necessarily have equal encodings.
%
\begin{falseclaim}
  Let $\aut{A} = (Q, ?, F)$ be \iac{NFA} over input alphabet $\ialph$.
  Then $q \asim s$ implies $\nfa{q} = \nfa{s}$, for all states $q$ and $s$.
\end{falseclaim}
%
\begin{proof}[Counterexample]
  Consider the \ac{NFA} and encoding depicted in the adjacent \lcnamecref{fig:ordered-rewriting:nfa-counterexample}.
  \begin{marginfigure}
    \begin{alignat*}{2}
      \begin{tikzpicture}
        \graph [automaton] {
          q_0 [accepting]
           -> ["a", loop above]
          q_0
           -> ["a", overlay]
          q_1 [accepting, overlay]
           -> ["a", loop above, overlay]
          q_1;
        };
      \end{tikzpicture}
      &\quad&&
      \\
      &\quad& \nfa{q}_0 &\defd \bigl(a \limp (\nfa{q}_0 \with \nfa{q}_1)\bigr) \with (\emp \limp \one) \\
      &\quad& \nfa{q}_1 &\defd (a \limp \nfa{q}_1) \with (\emp \limp \one)
    \end{alignat*}
    \caption{\Iac*{NFA} that accepts all finite words over the alphabet $\ialph = \set{a}$}\label{fig:ordered-rewriting:nfa-counterexample}
  \end{marginfigure}
  It is easy to verify that the relation $\set{q_1} \times \set{q_0,q_1}$ is a bisimulation; in particular, $q_1$ simulates the $q_0 \nfareduces[a] q_1$ transition by its self-loop, $q_1 \nfareduces[a] q_1$.
  Hence, $q_0$ and $s_0$ are bisimilar.
  %
  % These same \acp{NFA} are encoded by the following definitions.
  % \begin{align*}
  %   \nfa{q}_0 &\defd (a \limp \nfa{q}_0) \with (\emp \limp \one)
  % \shortintertext{and}
  %   \nfa{s}_0 &\defd \bigl(a \limp (\nfa{s}_0 \with \nfa{s}_1)\bigr) \with (\emp \limp \one) \\
  %   \nfa{s}_1 &\defd (a \limp \nfa{s}_1) \with (\emp \limp \one)
  % \end{align*}
  It is equally easy to verify, by unrolling the definitions used in the encoding, that $\nfa{q}_0 \neq \nfa{s}_0$.
\end{proof}

For \acp{DFA}, bisimilar states do have equal encodings because the inherent determinism \ac{DFA} bisimilarity is a rather fine-grained equivalence.
Because each \ac{DFA} state has exactly one successor for each input symbol
The additional flexibility entailed by nondeterminism

Once again, it would be possible to construct an adequate encoding, by tagging each state with a unique atom.
% with a stronger nominal character

For the moment, we will put aside the question of an adequate encoding of \acp{NFA}.



\section{Introduction}

In the previous \lcnamecref{ch:ordered-logic}, we saw that the ordered sequent calculus can be given a resource interpretation in which sequents $\oseq{\octx |- A}$ may be read as \enquote{From resources $\octx$, resource goal $A$ is achievable.}
For instance, the left rule for ordered conjunction ($\lrule{\fuse}$, see adjacent display)%
\marginnote{%
  $\infer[\lrule{\fuse}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
     \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}$%
}
was read \enquote{Goal $C$ is achievable from resource $A \fuse B$ if it is achievable from the separate resources $A \oc B$.}

As alluded in the previous \lcnamecref{ch:ordered-logic}'s discussion of ordered conjunction\footnote{See \cpageref{p:ordered-logic:ordered-conjunction}.}, this $\lrule{\fuse}$ rule is essentially a rule of resource decomposition: it decomposes [the resource] $A \fuse B$ into the separate resources $A \oc B$ and relegates the unchanged goal $C$ to a secondary role.

\newthought{%
This \lcnamecref{ch:ordered-rewriting}%
}
begins by exploring a refactoring of the ordered sequent calculus's left rules around this idea of resource decomposition~\parencref{sec:ordered-rewriting:??}.
Most of the left rules can be easily refactored in this way, although a few will prove resistant to the change.

Emphasizing resource decomposition naturally leads us to a rewriting interpretation of (a fragment of) ordered logic~\parencref{sec:ordered-rewriting:??}.
This rewriting system is closely related to traditional notions of string rewriting\autocite{??}, but simultaneously restricts and generalizes [...] along distinct axes.

The connection of ordered logic and the Lambek calculus to rewriting is certainly not new.
\Citeauthor{Lambek:AMM58}'s original article\autocite{Lambek:AMM58}

This development borrows from \citeauthor{Cervesato+Scedrov:IC09}'s work on intuitionistic linear logic as an expressive rewriting framework that generalizes traditional notions of multiset rewriting.\autocite{Cervesato+Scedrov:IC09}



\newthought{Most} of the left rules could be seen as decomposing resources.
The left rules were seen as decomposing resources, such as the $\lrule{\fuse}$~rule%
\marginnote{%
  $\infer[\lrule{\fuse}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
     \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}$%
}
decomposing $A \fuse B$ into the resources $A \oc B$.
The right rules, on the other hand, were seen as ...

Replacing the left rules with a single, common rule ... and a new judgment, $\octx \reduces \octx'$, that exposes [makes [more] explicit] the decomposition of resources/state transformation aspect.


\section{Most left rules decompose ordered resources}

Recall two of the ordered sequent calculus's left rules: $\lrule{\fuse}$ and $\lrule{\with}_1$.
\begin{inferences}
  \infer[\lrule{\fuse}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
    \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
  \and
  \infer[\lrule{\with}_1]{\oseq{\octx'_L \oc (A \with B) \oc \octx'_R |- C}}{
    \oseq{\octx'_L \oc A \oc \octx'_R |- C}}
\end{inferences}
Both rules decompose the principal resource: in the $\lrule{\fuse}$ rule, $A \fuse B$ into the separate resources $A \oc B$; and, in the $\lrule{\with}_1$ rule, $A \with B$ into $A$.
However, in both cases, the resource decomposition is somewhat obscured by boilerplate.
The framed contexts $\octx'_L$ and $\octx'_R$ and goal $C$ serve to enable the rules to be applied anywhere [in the string of resources], without restriction;
these concerns are not specific to the $\lrule{\fuse}$ and $\lrule{\with}_1$ rules, but are general boilerplate that arguably should be factored out.

To decouple the resource decomposition from the surrounding boilerplate, we will introduce a new judgment, $\octx \reduces \octx'$, meaning \enquote{Resources $\octx$ may be decomposed into [resources] $\octx'$.}
% With this judgment in hand, the boilerplate can be factored into a uniform left rule, $\lrule{\star}$:
With this new judgment comes a cut principle, $\jrule{CUT}^{\reduces}$, into which all of the boilerplate is factored:
\begin{equation*}
  \infer[\jrule{CUT}\smash{^{\reduces}}]{\oseq{\octx'_L \oc \octx \oc \octx'_R |- C}}{
    \octx \reduces \octx' &
    \oseq{\octx'_L \oc \octx' \oc \octx'_R |- C}}
  .
\end{equation*}

The standard left rules can be recovered from resource decomposition rules using this cut principle.
For example, the decomposition of $A \fuse B$ into $A \oc B$ is captured by
\begin{equation*}
  \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{}
  ,
\end{equation*}
and the standard $\lrule{\fuse}$ rule can then be recovered as shown in the neighboring \lcnamecref{fig:ordered-rewriting:fuse-refactoring}.%
\begin{marginfigure}[-8\baselineskip]
  \begin{gather*}
    \infer[\lrule{\fuse}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
      \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
    %
    \\\leftrightsquigarrow\\
    %
    \infer[\jrule{CUT}\smash{^{\reduces}}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
      \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{} &
      \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
    .
  \end{gather*}
  \caption{A refactoring of the $\lrule{\fuse}$ rule as resource decomposition}\label{fig:ordered-rewriting:fuse-refactoring}
\end{marginfigure}
The left rules for $\one$ and $A \with B$ can be similarly refactored into resource decomposition rules.

Even the left rules for left- and right-handed implications can be refactored in this way, despite the additional, minor premises that those rules carry.
To keep the correspondence between resource decomposition rules and left rules close, we could introduce the decomposition rules
\begin{inferences}
  \infer[\jrule{$\limp$D}']{\octx \oc (A \limp B) \reduces B}{
    \oseq{\octx |- A}}
  \and\text{and}\and
  \infer[\jrule{$\pmir$D}']{(B \pmir A) \oc \octx \reduces B}{
    \oseq{\octx |- A}}
  .
\end{inferences}
Just as for ordered conjunction, the left rules for left- and right-handed implication are then recovered by combining a decomposition rule with the $\jrule{CUT}^{\reduces}$ rule~(see adjacent \lcnamecref{fig:ordered-rewriting:limp-refactoring-1}).%
\begin{marginfigure}[-8\baselineskip]
  \begin{gather*}
    \infer[\lrule{\limp}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
      \oseq{\octx |- A} &
      \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
    %
    \\\leftrightsquigarrow\\
    %
    \infer[\jrule{CUT}\smash{^{\reduces}}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
      \infer[\jrule{$\limp$D}']{\octx \oc (A \limp B) \reduces B}{
        \oseq{\octx |- A}} &
      \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
  \end{gather*}
  \caption{A refactoring of the $\lrule{\limp}$ rule using a resource decomposition rule}\label{fig:ordered-rewriting:limp-refactoring-1}
\end{marginfigure}

Although these $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules keep the correspondence between resource decomposition rules and left rules close, they differ from the other decomposition rules in two significant ways.
First, the above $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules have premises, and those premises create a dependence of the decomposition judgment upon general provability.
Second, the above $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules do not decompose the principal proposition into immediate subformulas.
This contrasts with, for example, the $\jrule{$\fuse$D}$ rule that decomposes $A \fuse B$ into the immediate subformulas $A \oc B$.

For these reasons, the above $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules are somewhat undesirable.
Fortunately, there is an alternative.
Filling in the $\oseq{\octx |- A}$ premises with the $\jrule{ID}^A$ rule, we arrive at the derivable rules
\begin{inferences}
  \infer[\jrule{$\limp$D}]{A \oc (A \limp B) \reduces B}{}
  \and\text{and}\and
  \infer[\jrule{$\pmir$D}]{(B \pmir A) \oc A \reduces B}{}
  .
\end{inferences}
The standard $\lrule{\limp}$ and $\lrule{\pmir}$ rules can still be recovered from these more specific decomposition rules, thanks to $\jrule{CUT}$ (see adjacent \lcnamecref{fig:ordered-rewriting:limp-refactoring-2}).%
\begin{marginfigure}[-10\baselineskip]
  \begin{gather*}
    \infer[\lrule{\limp}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
      \oseq{\octx |- A} &
      \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
    %
    \\\leftrightsquigarrow\\
    %
    \infer[\jrule{CUT}\smash{^A}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
      \oseq{\octx |- A} &
      \infer[\jrule{CUT}\smash{^{\reduces}}]{\oseq{\octx'_L \oc A \oc (A \limp B) \oc \octx'_R |- C}}{
        \infer[\jrule{$\limp$D}]{A \oc (A \limp B) \reduces B}{} &
        \oseq{\octx'_L \oc B \oc \octx'_R |- C}}}
  \end{gather*}
  \caption{A refactoring of the $\lrule{\limp}$ rule using an alternative resource decomposition rule}\label{fig:ordered-rewriting:limp-refactoring-2}
\end{marginfigure}
These revised, nullary decomposition rules correct the earlier drawbacks: like the other decomposition rules, they now have no premises and only refer to immediate subformulas.
Moreover, these rules have the advantage of matching two of the axioms from \citeauthor{Lambek:AMM58}'s original article.\autocite{Lambek:AMM58}


% For many of the ordered logical connectives, this approach  works perfectly.
% The decomposition of $A \fuse B$ into $A \oc B$ is, for example, captured by
% \begin{equation*}
%   \infer[\lrule{\fuse}']{A \fuse B \reduces A \oc B}{}
%   ,
% \end{equation*}
% so that the ordered sequent calculus's standard $\lrule{\fuse}$ rule
% % left rule for multiplicative conjunction
% is then derivable from the uniform left rule:
% \begin{equation*}
%   \infer[\lrule{\fuse}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
%     \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
%   %
%   \enspace\leftrightsquigarrow\enspace
%   %
%   \infer[\lrule{\star}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
%     \infer[\lrule{\fuse}']{A \fuse B \reduces A \oc B}{} &
%     \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
%   .
% \end{equation*}
% The left rules for $\one$ and $A \with B$ can be refactored in a similar way.
% Despite their additional, minor premises, even the left rules for left- and right-handed implications can be refactored in this way.
% \begin{inferences}
%   \infer[\lrule{\limp}']{\octx \oc (A \limp B) \reduces B}{
%     \oseq{\octx |- A}}
%   \and
%   \infer[\lrule{\pmir}']{(B \pmir A) \oc \octx \reduces B}{
%     \oseq{\octx |- A}}
% \end{inferences}

% \begin{equation*}
%   \infer[\lrule{\limp}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
%     \oseq{\octx |- A} &
%     \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
%   %
%   \enspace\leftrightsquigarrow\enspace
%   %
%   \infer[\lrule{\star}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- C}}{
%     \infer[\lrule{\limp}']{\octx \oc (A \limp B) \reduces B}{
%       \oseq{\octx |- A}} &
%     \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
% \end{equation*}


\newthought{%
So, for most%
}
ordered logical connectives, this approach works perfectly.
Unfortunately, the left rules for additive disjunction, $A \plus B$, and its unit, $\zero$, are resistant to this kind of refactoring.
The difficulty with additive disjunction isn't that its left rule, $\lrule{\plus}$,%
\marginnote{%
  \begin{equation*}
    \infer[\lrule{\plus}]{\oseq{\octx'_L \oc (A \plus B) \oc \octx'_R |-  C}}{
      \oseq{\octx'_L \oc A \oc \octx'_R |-  C} &
      \oseq{\octx'_L \oc B \oc \octx'_R |-  C}}
  \end{equation*} 
}
doesn't decompose the resource $A \plus B$.
The $\lrule{\plus}$ rule certainly does decompose $A \plus B$, but it does so [...].
$A \plus B \reduces A \mid B$
[...] retain the standard $\lrule{\plus}$ and $\lrule{\zero}$ rules.

\begin{figure}[tbp]
  \begin{inferences}
    \infer[\jrule{CUT}\smash{^A}]{\oseq{\octx'_L \oc \octx \oc \octx'_R |- C}}{
      \oseq{\octx |- A} & \oseq{\octx'_L \oc A \oc \octx'_R |- C}}
    \and 
    \infer[\jrule{ID}\smash{^A}]{\oseq{A |- A}}{}
    \\
    \infer[\jrule{CUT}\smash{^{\reduces}}]{\oseq{\octx'_L \oc \octx \oc \octx'_R |- C}}{
      \octx \reduces \octx' & \oseq{\octx'_L \oc \octx' \oc \octx'_R |- C}}
    \\
    \infer[\rrule{\fuse}]{\oseq{\octx_1 \oc \octx_2 |- A \fuse B}}{
      \oseq{\octx_1 |- A} & \oseq{\octx_2 |- B}}
    \and
    \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{}
    \\
    \infer[\rrule{\one}]{\oseq{\octxe |- \one}}{}
    \and
    \infer[\jrule{$\one$D}]{\one \reduces \octxe}{}
    \\
    \infer[\rrule{\with}]{\oseq{\octx |- A \with B}}{
      \oseq{\octx |- A} & \oseq{\octx |- B}}
    \and
    \infer[\jrule{$\with$D}_1]{A \with B \reduces A}{}
    \and
    \infer[\jrule{$\with$D}_2]{A \with B \reduces B}{}
    \\
    \infer[\rrule{\top}]{\oseq{\octx |- \top}}{}
    \and
    \text{(no $\jrule{$\top$D}$ rule)}
    \\
    \infer[\rrule{\limp}]{\oseq{\octx |- A \limp B}}{
      \oseq{A \oc \octx |- B}}
    \and
    \infer[\jrule{$\limp$D}]{A \oc (A \limp B) \reduces B}{}
    \\
    \infer[\rrule{\pmir}]{\oseq{\octx |- B \pmir A}}{
      \oseq{\octx \oc A |- B}}
    \and
    \infer[\jrule{$\pmir$D}]{(B \pmir A) \oc A \reduces B}{}
    \\
    \infer[\rrule{\plus}_1]{\oseq{\octx |- A \plus B}}{
      \oseq{\octx |- A}}
    \and
    \infer[\rrule{\plus}_2]{\oseq{\octx |- A \plus B}}{
      \oseq{\octx |- B}}
    \and
    \infer[\lrule{\plus}]{\oseq{\octx'_L \oc (A \plus B) \oc \octx'_R |- C}}{
      \oseq{\octx'_L \oc A \oc \octx'_R |- C} &
      \oseq{\octx'_L \oc B \oc \octx'_R |- C}}
    \\
    \text{(no $\rrule{\zero}$ rule)}
    \and
    \infer[\lrule{\zero}]{\oseq{\octx'_L \oc \zero \oc \octx'_R |- C}}{}
  \end{inferences}
  \caption{A refactoring of the ordered sequent calculus to emphasize that most left rules amount to resource decomposition}\label{fig:ordered-rewriting:decompose-seq-calc}
\end{figure}

\newthought{%
\Cref{fig:ordered-rewriting:decompose-seq-calc} presents%
}
the fully refactored sequent calculus for ordered logic.
This refactored calculus is sound and complete with respect to the ordered sequent calculus~\parencref{fig:ordered-logic:sequent-calculus}.
%
\begin{theorem}[Soundness]
  If\/ $\oseq{\octx |- A}$ is derivable in the refactored calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}, then $\oseq{\octx |- A}$ is derivable in the ordered sequent calculus~\parencref{fig:ordered-logic:sequent-calculus}.
\end{theorem}
%
\begin{proof}
  By structural induction on the given derivation.
  The key lemma is the admissibility of $\jrule{CUT}^{\reduces}$ in the ordered sequent calculus:
  \begin{quotation}
    \normalsize If $\octx \reduces \octx'$ and $\oseq{\octx'_L \oc \octx' \oc \octx'_R |- C}$, then $\oseq{\octx'_L \oc \octx \oc \octx'_R |- C}$.
  \end{quotation}
  This lemma can be proved by case analysis of the decomposition $\octx \reduces \octx'$, reconstituting the corresponding left rule along the lines of the sketches from \cref{fig:ordered-rewriting:fuse-refactoring,fig:ordered-rewriting:limp-refactoring-2}.
\end{proof}
%
\begin{theorem}[Completeness]
  If\/ $\oseq{\octx |- A}$ is derivable in the ordered sequent calculus~\parencref{fig:ordered-logic:sequent-calculus}, then $\oseq{\octx |- A}$ is derivable in the refactored calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}.
\end{theorem}
%
\begin{proof}
  By structural induction on the given derivation.
  The critical cases are the left rules; they are resolved along the lines of the sketches shown in \cref{fig:ordered-rewriting:fuse-refactoring,fig:ordered-rewriting:limp-refactoring-2}.
\end{proof}




\section{Decomposition as rewriting}

Thus far, we have used the decomposition judgment, $\octx \reduces \octx'$, and its rules as the basis for a reconfigured sequent-like calculus for ordered logic.
% But this refactoring also leads naturally to a rewriting system grounded in ordered logic.
% 
Instead,
% of taking the resource decomposition rules as a basis for a reconfigured sequent calculus,
we can also view decomposition as the foundation of a rewriting system grounded in ordered logic.
For example, the decomposition of resource $A \fuse B$ into $A \oc B$ by the $\jrule{$\fuse$D}$ rule
% \marginnote{%
%   \begin{equation*}
%     \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{}
%   \end{equation*}
% }%
can also be seen as \emph{rewriting} $A \fuse B$ into $A \oc B$.
More generally, the decomposition judgment $\octx \reduces \octx'$ can be read as \enquote{$\octx$ rewrites to $\octx'$.}

\Cref{fig:ordered-rewriting:rewriting} summarizes the rewriting system that we obtain from the refactored sequent-like calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}.
%
\begin{figure}[tbp]
  \vspace{\dimexpr-\abovedisplayskip-\abovecaptionskip\relax}
  \begin{inferences}
    \infer[\jrule{$\fuse$D}]{A \fuse B \reduces A \oc B}{}
    \and
    \infer[\jrule{$\one$D}]{\one \reduces \octxe}{}
    \\
    \infer[\jrule{$\with$D}_1]{A \with B \reduces A}{}
    \and
    \infer[\jrule{$\with$D}_2]{A \with B \reduces B}{}
    \and
    \text{(no $\jrule{$\top$D}$ rule)}
    \\
    \infer[\jrule{$\limp$D}]{A \oc (A \limp B) \reduces B}{}
    \and
    \infer[\jrule{$\pmir$D}]{(B \pmir A) \oc A \reduces B}{}
    \\
    \text{(no $\jrule{$\plus$D}$ and $\jrule{$\zero$D}$ rules)}
    \\
    \infer[\jrule{$\reduces$C}\smash{_{\jrule{L}}}]{\octx_1 \oc \octx_2 \reduces \octx'_1 \oc \octx_2}{
      \octx_1 \reduces \octx'_1}
    \and
    \infer[\jrule{$\reduces$C}\smash{_{\jrule{R}}}]{\octx_1 \oc \octx_2 \reduces \octx_1 \oc \octx'_2}{
      \octx_2 \reduces \octx'_2}
  \end{inferences}
  \begin{inferences}
    \infer[\jrule{$\Reduces$R}]{\octx \Reduces \octx}{}
    \and
    \infer[\jrule{$\Reduces$T}]{\octx \Reduces \octx''}{
      \octx \reduces \octx' & \octx' \Reduces \octx''}
  \end{inferences}
  \caption{A rewriting fragment of ordered logic, based on resource decomposition}\label{fig:ordered-rewriting:rewriting}
\end{figure}
%
Essentially, the ordered rewriting system is obtained by discarding all rules except for the decomposition rules.
However, if only the decomposition rules are used, rewritings cannot occur within a larger context.
For example, the $\jrule{$\limp$D}$ rule derives $A \oc (A \limp B) \reduces B$, but $\octx'_L \oc A \oc (A \limp B) \oc \octx'_R \reduces \octx'_L \oc B \oc \octx'_R$ would not be derivable in general.
In the refactored calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}, this kind of framing is taken care of by the cut principle for decomposition, $\jrule{CUT}^{\reduces}$.
To express framing at the level of the $\octx \reduces \octx'$ judgment, we introduce two compatibility rules: together,
\begin{inferences}
  \infer[\jrule{$\reduces$C}\smash{_{\jrule{L}}}]{\octx_1 \oc \octx_2 \reduces \octx'_1 \oc \octx_2}{
    \octx_1 \reduces \octx'_1}
  \and\text{and}\and
  \infer[\jrule{$\reduces$C}\smash{_{\jrule{R}}}]{\octx_1 \oc \octx_2 \reduces \octx_1 \oc \octx'_2}{
    \octx_2 \reduces \octx'_2}
\end{inferences}
ensure that rewriting is compatible with concatenation of ordered contexts.%
\footnote[][-4\baselineskip]{%
  Because ordered contexts form a monoid, these compatibility rules are equivalent to the unified rule
  \begin{equation*}
    \infer[\jrule{$\reduces$C}]{\octx_L \oc \octx \oc \octx_R \reduces \octx_L \oc \octx' \oc \octx_R}{
      \octx \reduces \octx'}
    .
  \end{equation*}
  However, we prefer the two-rule formulation of compatibility because it better aligns with the syntactic structure of contexts.%
}

By forming the reflexive, transitive closure of $\reduces$, we may construct a multi-step rewriting relation, which we choose to write as $\Reduces$.%
\footnote[][0.5\baselineskip]{%
  Usually written as $\reduces^*$, we instead chose $\Reduces$ for the reflexive, transitive closure because of its similarity with process calculus notation for weak transitions, $\Reduces[\smash{\alpha}]$.
  Our reasons will become clearer in subsequent \lcnamecrefs{ch:ordered-bisimilarity}.%
}

Consistent with its [free] monoidal structure, there are two equivalent formulations of this reflexive, transitive closure: each rewriting sequence $\octx \Reduces \octx'$ can be viewed as either a list or tree of individual rewriting steps.
We prefer the list-based formulation shown in \cref{fig:ordered-rewriting:rewriting} because it tends to [...] proofs by structural induction, but, on the basis of the following \lcnamecref{fact:ordered-rewriting:transitivity}, we allow ourselves to freely switch between the two formulations as needed.
%
\begin{fact}[Transitivity of $\Reduces$]
  If \kern0.15em$\octx \Reduces \octx'$ and\/ $\octx' \Reduces \octx''$, then\/ $\octx \Reduces \octx''$.
\end{fact}
%
\begin{proof}
  By induction on the structure of the first trace, $\octx \Reduces \octx'$.
\end{proof}

\newthought{A few remarks} about these rewriting relations are in order.
%
First, interpreting the resource decomposition rules as rewriting only confirms our preference for the nullary $\jrule{$\limp$D}$ and $\jrule{$\pmir$D}$ rules.
% [over the $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules.]
The $\jrule{$\limp$D}'$ and $\jrule{$\pmir$D}'$ rules, with their $\oseq{\octx |- A}$ premises, would be problematic as rewriting rules because they would introduce a dependence of ordered rewriting upon general provability%
% By instead using the $\jrule{$\limp$D}$ and $\jrule{$\pmir$D}$ rules, we ensures that ordered rewriting is a syntactic procedure that
% Instead, we want ordered rewriting to be a syntactic procedure, withou 
, and the concomitant[/attendant] proof search would take ordered rewriting too far afield from traditional, syntactic\fixnote{Is this the right word?} notions of string and multiset rewriting.
[mechanical, computational]

Second, multi-step rewriting is incomplete with respect to the ordered sequent calculus~\parencref{fig:ordered-logic:sequent-calculus} because all right rules have been discarded.
%
 \begin{falseclaim}[Completeness]
  If \kern0.15em$\oseq{\octx |- A}$, then\/ $\octx \Reduces A$.
\end{falseclaim}
%
\begin{proof}[Counterexample]
  The sequent $\oseq{A \limp (C \pmir B) |- (A \limp C) \pmir B}$ is provable, but $A \limp (C \pmir B) \Longarrownot\Reduces (A \limp C) \pmir B$ even though $A \oc (A \limp (C \pmir B)) \oc B \Reduces C$ does hold.
\end{proof}


As expected from the way in which it was developed, ordered rewriting is, however, sound.
Before stating and proving soundness, we must define an operation $\bigfuse \octx$ that reifies an ordered context as a single proposition (see adjacent \lcnamecref{fig:ordered-rewriting:bigfuse}).
%
\begin{marginfigure}
  \begin{align*}
    (\octx_1 \oc \octx_2) &= (\octx_1) \fuse (\octx_2) \\
    \mathord{\text{$\fuse$}} (\octxe) &= \one \\
    A &= A
  \end{align*}
  \begin{align*}
    \bigfuse (\octx_1 \oc \octx_2) &= (\bigfuse \octx_1) \fuse (\bigfuse \octx_2) \\
    \bigfuse (\octxe) &= \one \\
    \bigfuse A &= A
  \end{align*}
\begin{theorem}
  If \kern0.15em$\octx \reduces \octx'$, then\/ $\oseq{\octx |- \bigfuse \octx'}$.
  Also, if \kern0.15em$\octx \Reduces \octx'$, then\/ $\oseq{\octx |- \bigfuse \octx'}$.
\end{theorem}
  \caption{From ordered contexts to propositions}\label{fig:ordered-rewriting:bigfuse}
\end{marginfigure}
%
\begin{theorem}[Soundness]
  If \kern0.15em$\octx \reduces \octx'$, then\/ $\oseq{\octx |- \bigfuse \octx'}$.
  Also, if \kern0.15em$\octx \Reduces \octx'$, then\/ $\oseq{\octx |- \bigfuse \octx'}$.
\end{theorem}
%
\begin{proof}
  By induction on the structure of the given step or trace.
\end{proof}

Last, notice that every rewriting step, $\octx \reduces \octx'$, strictly decreases the number of logical connectives that occur in the ordered context.
More formally, let $\card{\octx}$ be a measure of the number of logical connectives that occur in $\octx$, as defined in the adjacent \lcnamecref{fig:ordered-rewriting:measure}.
%
\begin{marginfigure}
  \begin{align*}
    \card{\octx_1 \oc \octx_2} &= \card{\octx_1} + \card{\octx_2} \\
    \card{\octxe} &= 0 \\
    \card{A \star B} &= \begin{tabular}[t]{@{}l@{}}
                          $1 + \card{A} + \card{B}$ \\
                          \quad if $\mathord{\star} = \mathord{\fuse}$, $\mathord{\with}$, $\mathord{\limp}$, $\mathord{\pmir}$, or $\mathord{\plus}$
                         \end{tabular} \\
    \card{A} &= \mathrlap{1}
                    \quad \text{if $A = \alpha$, $\one$, $\top$, or $\zero$}
  \end{align*}
  \caption{A measure of the number of logical connectives within an ordered context}\label{fig:ordered-rewriting:measure}
\end{marginfigure}%
%
We may then prove the following \lcnamecref{fact:ordered-rewriting:reduction}.
%
\begin{fact}\label{fact:ordered-rewriting:reduction}
  If \kern0.15em$\octx \reduces \octx'$, then $\card{\octx} > \card{\octx'}$.
  Also, if \kern0.15em$\octx \Reduces \octx'$, then $\card{\octx} \geq \card{\octx'}$.
\end{fact}
%
\begin{proof}
  By induction on the structure of the rewriting step.
\end{proof}
%
\noindent
On the basis of this \lcnamecref{fact:ordered-rewriting:reduction}, we will frequently refer to the rewriting relation, $\reduces$, as reduction.


\section{}

\subsection{Binary counters}

\begin{equation*}
  \begin{lgathered}
    \bin{e} \oc \atmL{i} \Reduces \bin{e} \oc \bin{b}_1 \\
    \bin{b}_0 \oc \atmL{i} \Reduces \bin{b}_1 \\
    \bin{b}_1 \oc \atmL{i} \Reduces \atmL{i} \oc \bin{b}_0
  \end{lgathered}
\end{equation*}

\begin{equation*}
  \begin{lgathered}
    \bin{e} \oc \atmL{d} \Reduces \atmR{z} \\
    \bin{b}_0 \oc \atmL{d} \Reduces \atmL{d} \oc \bin{b}'_0 \\
    \bin{b}_1 \oc \atmL{d} \Reduces \bin{b}_0 \oc \atmR{s} \\
    \atmR{z} \oc \bin{b}'_0 \Reduces \atmR{z} \\
    \atmR{s} \oc \bin{b}'_0 \Reduces \bin{b}_1 \oc \atmR{s}
  \end{lgathered}
\end{equation*}

\begin{inferences}
  \infer{e \simu{R} \bin{e}}{}
  \and
  \infer{\octx \oc b_0 \simu{R} \octx' \oc \bin{b}_0}{
    \octx \simu{R} \octx'}
  \and
  \infer{\octx \oc b_1 \simu{R} \octx' \oc \bin{b}_1}{
    \octx \simu{R} \octx'}
  \and
  \infer{\octx \oc i \simu{R} \octx' \oc \atmL{i}}{
    \octx \simu{R} \octx'}
  \\
  \infer{\octx \oc i \oc b_0 \simu{R} \octx' \oc (\atmL{i} \fuse b_0)}{
    \octx \simu{R} \octx'}
\end{inferences}

\subsection{Automata}

\begin{inferences}
  \infer{a \oc \octx \simu{R} \atmR{a} \oc \octx'}{
    \octx \simu{R} \octx'}
  \and
  \infer{q \simu{R} \dfa{q}}{}
\end{inferences}

\begin{equation*}
  \infer{q \simu{R} \dfa{q}'}{
    q \asim q'}
\end{equation*}


\section{Ordered rewriting for specifications}

\subsection{\Aclp*{DFA}}

\begin{equation*}
  \infer[]{a \oc q \reduces q'_a}{}
\end{equation*}
for each \ac{DFA} transition $q \dfareduces[a] q'_a$, and 
\begin{equation*}
  \infer[]{\emp \oc q \reduces F(q)}{}
\end{equation*}
for each state $q$, where $F(q) = \one$ if $q$ is a final state and $F(q) = \top$ otherwise.

\begin{itemize}
\item $q \dfareduces[a] q'_a$ if, and only if, $a \oc q \reduces q'_a$; and 
\item $q \in F$ if, and only if, $\emp \oc q \reduces \one$.
\end{itemize}

\subsection{\Aclp*{NFA}}

Equally straightforward

\subsection{Binary counters}

Values

\paragraph*{An increment operation}
To use ordered rewriting to specify [...]
\begin{equation*}
  \infer[]{e \oc i \reduces e \oc b_1}{}
  \qquad
  \infer[]{b_0 \oc i \reduces b_1}{}
  \qquad
  \infer[]{b_1 \oc i \reduces i \oc b_0}{}
\end{equation*}

Small- and big-step adequacy theorems for increments
\begin{itemize}
\item Slightly simplified because there is no $\fuse$
\end{itemize}


\paragraph*{A decrement operation}
\begin{equation*}
  \infer[]{e \oc d \reduces z}{}
  \qquad
  \infer[]{b_0 \oc d \reduces d \oc b'_0}{}
  \qquad
  \infer[]{b_1 \oc d \reduces b_0 \oc s}{}
  \qquad
  \infer[]{z \oc b'_0 \reduces z}{}
  \qquad
  \infer[]{s \oc b'_0 \reduces b_1 \oc s}{}
\end{equation*}

\begin{itemize}
\item Significantly simpler because there is no $\with$, so we don't need (weak) focusing
\end{itemize}



\section{}

\subsection{Concurrency in ordered rewriting}

As an example of multi-step rewriting, observe that
\begin{equation*}
  % \octx = 
  \alpha_1 \oc (\alpha_1 \limp \alpha_2) \oc (\beta_2 \pmir \beta_1) \oc \beta_1 \Reduces \alpha_2 \oc \beta_2
  % = \octx''
  .
\end{equation*}
In fact, as shown in the adjacent \lcnamecref{fig:ordered-rewriting:concurrent-example},%
%
\begin{marginfigure}
  \begin{equation*}
  \begin{tikzcd}[row sep=large, column sep=tiny]
    &
    \makebox[1em][c]{$\alpha_1 \oc (\alpha_1 \limp \alpha_2) \oc (\beta_2 \pmir \beta_1) \oc \beta_1$}
      \dlar \drar \arrow[Reduces]{dd}
    &
    \\
    \alpha_2 \oc (\beta_2 \pmir \beta_1) \oc \beta_1
      \drar
    &&
    \alpha_1 \oc (\alpha_1 \limp \alpha_2) \oc \beta_2
      \dlar
    \\
    &
    \alpha_2 \oc \beta_2
    &
  \end{tikzcd}
\end{equation*}
  \caption{An example of concurrent ordered rewriting}\label{fig:ordered-rewriting:concurrent-example}
\end{marginfigure}
%
two sequences witness this rewriting: either
\begin{itemize*}[
  mode=unboxed,
  label=, afterlabel=
]
\item the initial state's left half, $\alpha_1 \oc (\alpha_1 \limp \alpha_2)$, is first rewritten to $\alpha_2$ and then its right half, $(\beta_2 \pmir \beta_1) \oc \beta_1$, is rewritten to $\beta_2$; or
\item \textit{vice versa}, the right half is first rewritten to $\beta_2$ and then the left half is rewritten to $\alpha_2$
\end{itemize*}.

Notice that these two sequences differ only in how non-overlapping, and therefore independent, rewritings of the initial state's two halves are interleaved.
Consequently, the two sequences can be -- and indeed should be -- considered essentially equivalent.
% In differing only by the order in which the non-overlapping left and right halves are rewritten, these two rewriting sequences are essentially equivalent.
The details of how the small-step rewrites are interleaved are irrelevant, so that
conceptually, at least, only the big-step trace from $\alpha_1 \oc (\alpha_1 \limp \alpha_2) \oc (\beta_2 \pmir \beta_1) \oc \beta_1$ to $\alpha_2 \oc \beta_2$ remains.
% The details of how the small-step rewrites are interleaved are -- and indeed should be -- swept away, so that conceptually only the big-step trace from $\alpha_1 \oc (\alpha_1 \limp \alpha_2) \oc (\beta_2 \pmir \beta_1) \oc \beta_1$ to $\alpha_2 \oc \beta_2$ remains.

More generally, this idea that the interleaving of independent actions is irrelevant is known as \vocab{concurrent equality}\autocite{Watkins+:CMU02}, and it forms the basis of concurrency.\autocite{??}
Concurrent equality also endows traces $\octx \Reduces \octx'$ with a free partially commutative monoid structure, \ie, traces form a trace monoid.


Because the two indivisual rewriting steps are independent, 
Nothing about the final result, $\alpha_2 \oc \beta_2$, suggests which rewriting sequence 


The rewritings of the left and right halves are not overlapping and therefore independent.
Their independence means that we may view the two rewriting sequences as equivalent -- the two rewriting steps

More generally, any non-overlapping rewritings are independent and may occur in any order.
Rewriting sequences that differ only by the order in which independent rewritings occur may be seen as equivalent sequences.
This equivalence relation, \vocab{concurrent equality}\autocite{Watkins+:CMU02}

because the left half of $\octx$ may be rewritten by the $\jrule{$\limp$D}$ rule to $\alpha_2$, and then the right half may be rewritten to $\beta_2$:

\subsection{Other properties of ordered rewriting}

As the relation $\Reduces$ forms a rewriting system, we may evaluate it along several standard dimensions: termination, confluence.


Because each rewriting step reduces the number of logical connectives present in the state~\parencref{fact:ordered-rewriting:reduction}, ordered rewriting is terminating.
%
\begin{theorem}[Termination]
  No infinite rewriting sequence $\octx_0 \reduces \octx_1 \reduces \octx_2 \reduces \dotsb$ exists.
\end{theorem}
%
\begin{proof}
  Beginning from state $\octx_0$, some state $\octx_i$ will eventually be reached such that either: $\octx_i \nreduces$; or $\card{\octx_i} = 0$ and $\octx_i \reduces \octx_{i+1}$.
  In the latter case, \cref{fact:ordered-rewriting:reduction} establishes $\card{\octx_{i+1}} < 0$, which is impossible.
\end{proof}

Although terminating, ordered rewriting is not confluent.
Confluence requires that all states with a common ancestor, \ie, states $\octx'_1$ and $\octx'_2$ such that $\octx'_1 \secudeR\Reduces \octx'_2$, be joinable, \ie, $\octx'_1 \Reduces\secudeR \octx'_2$.
Because ordered rewriting is directional\fixnote{Is this phrasing correct?} and the relation $\Reduces$ is not symmetric, some nondeterministic choices are irreversible.%
%
\begin{falseclaim}[Confluence]
  If\/ $\octx'_1 \secudeR\Reduces \octx'_2$, then $\octx'_1 \Reduces\secudeR \octx'_2$.
\end{falseclaim}
%
\begin{proof}[Counterexamples]
  Consider the state $\alpha \with \beta$.
  By the rewriting rules for additive conjunction, $\alpha \secuder \alpha \with \beta \reduces \beta$, and hence $\alpha \secudeR \alpha \with \beta \Reduces \beta$.
  However, being atoms, neither $\alpha$ nor $\beta$ reduces.
  And $\alpha \neq \beta$, so $\alpha \Reduces\secudeR \beta$ does \emph{not} hold.

  Even in the $\with$-free fragment, ordered rewriting is not confluent.
  For example,
  % consider the state $(\beta_1 \pmir \alpha) \oc \alpha \oc (\alpha \limp \beta_2)$.
  % By the rewriting rules for right- and left-handed implications,
  \begin{equation*}
    \nsecuder \beta_1 \oc (\alpha \limp \beta_2) \secudeR (\beta_1 \pmir \alpha) \oc \alpha \oc (\alpha \limp \beta_2) \Reduces (\beta_1 \pmir \alpha) \oc \beta_2 \nreduces
    .
    \qedhere
  \end{equation*}
\end{proof}


% Viewing the resource decomposition rules for left- and right-handed implications as rewriting rules is slightly problematic, however.%
% Notice that the premises of these rules both require proofs of $\oseq{\octx |-  A}$.
% In the refactored sequent calculus of \cref{fig:ordered-rewriting:decompose-seq-calc}, that dependence of judgments is fine.
% But for a rewriting system, including arbitrary[/general] proofs would be odd -- rewriting should be a syntax-directed process and should not depend on provability.



% We write the reflexive, transitive closure of $\reduces$ as $\Reduces$.%
% \footnote{This notation is adopted for its similarity with the standard $\pi$-calculus notation for weak transitions, $\cramped{\Reduces[\alpha]}$.}

% This rewriting system is a proper fragment of ordered logic.
% \begin{equation*}
%   \oseq{A \limp (C \pmir B) \dashv|- (A \limp C) \pmir B}
%   \enspace\text{but}\enspace
%   A \limp (C \pmir B) \Longarrownot\Reduces (A \limp C) \pmir B
% \end{equation*}


\section{Unbounded ordered rewriting}

\autocite{Aranda+:FMCO06}

Although a seemingly pleasant property, termination~\parencref{thm:ordered-rewriting:termination} significantly limits the expressiveness of ordered rewriting.
For example, without unbounded rewriting, we cannot even give ordered rewriting specifications of producer-consumer systems or finite automata.

As the proof of termination shows, rewriting is bounded
% $\card{\octx_0}$ is an upper bound on the length of any trace from state $\octx_0$,
precisely because
% $\octx_0$
states
consist of finitely many finite propositions.
To admit unbounded rewriting, we therefore choose to permit infinite propositions in the form of mutually recursive definitions, $\alpha \defd A$.
% could either permit states consisting of infinitely many finite propositions or states consisting of finitely many infinite propositions.
% We choose the latter route [...].
%%
%%
% Infinite propositions are described by mutually recursive definitions $\alpha \defd A$.
These definitions are collected into a signature, $\sig = (\alpha_i \defd A_i)_i$, which indexes the rewriting relations: $\reduces_{\sig}$ and $\Reduces_{\sig}$.%
\footnote{We frequently elide the indexing signature, as it is usually clear from context.} 
To rule out definitions like $\alpha \defd \alpha$ that do not correspond to sensible infinite propositions, we also require that definitions be \vocab{contractive}\autocite{Gay+Hole:AI05} -- \ie, that the body of each recursive definition begin with a logical connective at the top level.

By analogy with recursive types from functional programming\autocite{??}, we must now decide whether to treat definitions \emph{iso}\-re\-cur\-sively or \emph{equi}\-re\-cur\-sively.
Under an equirecursive interpretation, definitions $\alpha \defd A$ may be silently unrolled or rolled at will;
in other words, $\alpha$ is literally \emph{equal} to its unrolling, $A$.
In contrast, under an isorecursive interpretation, unrolling a recursively defined proposition would count as an explicit step of rewriting -- $\alpha \reduces A$, for example.

% Under the isorecursive interpretation, unrolling a recursively defined prop\-o\-sition counts as an explicit step of rewriting.
% We introduce the $\jrule{$\defd$D}$ rule to account for this unrolling:
% \begin{equation*}
%   \infer[\jrule{$\defd$D}]{\alpha \reduces_{\sig} A}{
%     \text{$(\alpha \defd A) \in \sig$}}
% \end{equation*}
% Because $A$ is seen as a proper subformula of [the recursively defined] $\alpha$, this unrolling rule aligns well with the rewriting-as-decomposition philosophy.%
% \footnote{In fact, we could have chosen to include recursive definitions in the sequent calculus, following \textcites{SchroederHeister:LICS93}{Tiu+Momigliano:JAL12} and others.
%   Had we done so, the $\jrule{$\defd$D}$ rule would be seen as the decomposition counterpart to the left rule
%   \begin{equation*}
%     \infer[\lrule{\defd}]{\oseq{\octx'_L \oc \alpha \oc \octx'_R |-_{\sig} C}}{
%       \bigl((\alpha \defd A) \in \sig\bigr) &
%       \oseq{\octx'_L \oc A \oc \octx'_R |-_{\sig} C}}
%   \end{equation*}
% }
% Conversely, there is no rule that permits the rolling of $A$ into $\alpha$, because such a rule would not be a decomposition.

We choose to interpret definitions equirecursively
because the equirecursive treatment, with its generous notion of equality, helps to minimize the overhead of recursively defined propositions.
As a simple example, under the equirecursive definition $\beta \defd a \limp \beta$, we have the trace
\begin{equation*}
  a \oc a \oc \beta = a \oc a \oc (a \limp \beta) \reduces a \oc \beta = a \oc (a \limp \beta) \reduces \beta
\end{equation*}
or, more concisely, $a \oc a \oc \beta \reduces a \oc \beta \reduces \beta$.
Had we chosen
% With
 an isorecursive treatment of the same definition, we would have only the more laborious
\begin{equation*}
  a \oc a \oc \beta \reduces a \oc a \oc (a \limp \beta) \reduces a \oc \beta \reduces a \oc (a \limp \beta) \reduces \beta
  .
\end{equation*}

% As a simple example of ordered rewriting with recursive definitions, consider rewriting under the definition $\beta \defd a \limp \beta$; we have the trace
% \begin{equation*}
%   a \oc a \oc \beta = a \oc a \oc (a \limp \beta) \reduces a \oc \beta = a \oc (a \limp \beta) \reduces \beta
%   .
% \end{equation*}



% Instead of allowing arbitrary infinite propositions, we require that infinite propositions have a regular, recursive structure:
% A signature of mutually recursive definitions
% \begin{equation*}
%   \sig = (\alpha_i \defd A_i)_i
%   ,
% \end{equation*}
% where the variables $\alpha_i$ may occur in the bodies $A_j$.
% %
% To rule out definitions like $\alpha \defd \alpha$ that do notcorrespond to sensible infinite propositions, we additionally require that definitions be \vocab{contractive}\autocite{Gay+Hole:AI05} -- that the body of each recursive definition begin with a logical connective at the top level.




% Contractivity justifies an \emph{equi}recursive treatment of propositions in which definitions may be silently unrolled (or rolled) at will.
% In other words, a proposition $\alpha \defd A$ is \emph{equal} to its unrolling, $[A/\alpha]A$.
% This stands in contrast with an \emph{iso}recursive treatment of definitions in which unrolling a recursively defined proposition would count as an explicit step of rewriting: isorecursively, $\alpha \defd A$ would not be equal to $[A/\alpha]A$, but $\alpha \reduces {[A/\alpha]A}$.

% The equirecursive treatment, with its generous notion of equality, helps to minimize the overhead of recursively defined propositions.
% As a simple example, under the equirecursive definition $\beta \defd a \limp \beta$, we have
% \begin{equation*}
%   a \oc a \oc \beta = a \oc a \oc (a \limp \beta) \reduces a \oc \beta = a \oc (a \limp \beta) \reduces \beta
% \end{equation*}
% or, more concisely, $a \oc a \oc \beta \reduces a \oc \beta \reduces \beta$.
% With an isorecursive treatment of the same definition, we would have only the more laborious
% \begin{equation*}
%   a \oc a \oc \beta \reduces a \oc a \oc (a \limp \beta) \reduces a \oc \beta \reduces a \oc (a \limp \beta) \reduces \beta
%   .
% \end{equation*}

% The proof of termination involves a finite upper bound on the number of rewriting steps that 
% Stated informally, termination means that As captured in \cref{fact:ordered-rewriting:reduction}, states $\octx$ that consist of finitely many finite propositions

% Although its development from the ordered sequent calculus, ordered rewriting as defined thus far is not terribly useful.
% Its main limitation is that finite states 
% With finite states $\octx$ consisting of 

% \subsection{Replication}

% \subsection{Recursively defined propositions}


\subsection{Replication}

In Milner's development of the $\pi$-calculus, there are two avenues to unbounded process behavior: recursive process definitions and replication.


\section{Extended examples of ordered rewriting}

\subsection{Encoding \aclp*{DFA}}

As an extended example, we will use ordered rewriting to specify how \iac{DFA} processes its input.
%
% \Acp{DFA} serve as an example of ordered rewriting,  can be used to specify how \iac{DFA} processes its input.
%
Given \iac{DFA} $\aut{A} = (Q, ?, F)$ over an input alphabet $\ialph$, the idea is to encode each state, $q \in Q$, as an ordered proposition, $\dfa{q}$, in such a way that the \ac{DFA}'s operational semantics are adequately captured by [ordered] rewriting.
%
% The basic idea is to define an encoding, $\dfa{q}$, of \ac{DFA} states as ordered propositions;
% this encoding should adequately reflect the \ac{DFA}'s operational semantics with ordered rewriting traces.
\fixnote{[In general, the behavior of \iac{DFA} state is recursive, so the proposition $\dfa{q}$ will be recursively defined.]}
%
% finite input words, $w \in \finwds{\ialph}$, are encoded as ordered contexts by $\emp \oc \rev{w}$

% \NewDocumentCommand \rev { s m } {
%   \IfBooleanTF {#1}
%     { (#2)^{\mathsf{R}} }
%     { #2^{\mathsf{R}} }
% }

% \begin{align*}
%   \rev{a} &= a \\
%   \rev*{w_1 \wc w_2} &= \rev{w_2} \oc \rev{w_1} \\
%   \rev{\emp} &= \octxe
% \end{align*}

Ideally, \ac{DFA} transitions $q \dfareduces[a] q'_a$ would be in bijective correspondence with rewriting steps $a \oc \dfa{q} \reduces \dfa{q}'_a$, where each input symbol $a$ is encoded by a matching [propositional] atom.
%
We will return to the possibility of this kind of tight correspondence in \cref{??}, but,
%
for now, we will content ourselves with a correspondence with traces rather than individual steps, adopting the following desiderata:
% Unfortunately, ordered rewriting's small step size turns out to be a poor match for [...], so in both cases we will instead content ourselves with corrspondances with \emph{traces}:
% a bijection between transitions $q \dfareduces[a] q'_a$ and \emph{traces} $a \oc \dfa{q} \Reduces \dfa{q}'_a$.
% Similarly, [...] a bijection between accepting states $q \in F$ and traces $\emp \oc \dfa{q} \Reduces \octxe$.
%
% This leads us to adopt the following as desiderata:
\begin{itemize}
\item
  $q \dfareduces[a] q'_a$ if, and only if, $a \oc \dfa{q} \Reduces \dfa{q}'_a$, for all input symbols $a \in \ialph$.
\item
  $q \in F$ if, and only if, $\emp \oc \dfa{q} \Reduces \one$, where the atom $\emp$ functions as an end-of-word marker.
% \item
%   $q \dfareduces[w] q'_w \in F$ if, and only if, $\emp \oc \rev{w} \oc \dfa{q} \Reduces \octxe$.
%   Also, $q \dfareduces[w] q'_w \notin F$ if, and only if, $\emp \oc \rev{w} \oc \dfa{q} \Reduces \top$.
\end{itemize}
Given the reversal (anti-)\-homo\-morph\-ism from finite words to ordered contexts defined in the adjacent \lcnamecref{fig:ordered-rewriting:reversal}%
\begin{marginfigure}
  \begin{align*}
    \rev*{w_1 \wc w_2} &= \rev{w_2} \oc \rev{w_1} \\
    \rev{\emp} &= \octxe \\
    \rev{a} &= a
  \end{align*}
  \caption{An (anti-)\-homo\-morph\-ism for reversal of finite words to ordered contexts}\label{fig:ordered-rewriting:reversal}
\end{marginfigure}%
, the first desideratum is subsumed by a third:
% property that covers finite words:
\begin{itemize}[resume*]
\item $q \dfareduces[w] q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$, for all finite words $w \in \finwds{\ialph}$.
\end{itemize}

From these desiderata [and the observation that \acp{DFA}' graphs frequently%
\fixnote{Actually, there is always at least one cycle in a well-formed \ac{DFA}.}
contain cycles], we arrive at the following encoding, in which each state is encoded by one of a collection of mutually recursive definitions:%
\fixnote{$q'_a$, using function or relation?}
\begin{gather*}
  \dfa{q} \defd
    \parens[size=big]{
      \bigwith_{a \in \ialph}(a \limp \dfa{q}'_a)}
    \with
    \parens[size=big]{\emp \limp \dfa{F}(q)}
  % \text{where
  %   $q \dfareduces[a] q'_a$ for all $a \in \ialph$
  %   and
  %   $\dfa{F}(q) = 
  %     \begin{cases*}
  %       \one & if $q \in F$ \\
  %       \top & if $q \notin F$
  %     \end{cases*}$%
  % }
  %
\shortintertext{where}
  %
  q \dfareduces[a] q'_a
  \text{, for all input symbols $a \in \ialph$,\quad and\quad}
  \dfa{F}(q) = 
    \begin{cases*}
      \one & if $q \in F$ \\
      \top & if $q \notin F$%
    \,.
    \end{cases*}
\end{gather*}
Just as each state $q$ has exactly one successor for each input symbol $a$, its encoding, $\dfa{q}$, has exactly one input clause, $(a \limp \dotsb)$, for each symbol $a$.



% The traces $a \oc \dfa{q} \Reduces \dfa{q}'_a$
% % for input symbols $a \in \ialph$
% suggest that $\dfa{q}$ should be a collection of clauses that input atoms $a$ from the left.
% And the traces $\emp \oc \dfa{q} \Reduces \octxe$ or $\emp \oc \dfa{q} \Reduces \top$ suggest that $\dfa{q}$ also contain a clause that inputs atom $\emp$ from the left.
% Thus, we arrive at the encoding


\newthought{For a concrete instance} of this encoding, recall from \cref{ch:automata} the \ac{DFA} (repeated in the adjacent \lcnamecref{fig:ordered-rewriting:dfa-example-ends-b})%
%
\begin{marginfigure}
  \begin{equation*}
    \mathllap{\aut{A}_2 = {}}
    \begin{tikzpicture}[baseline=(q_0.base)]
      \graph [automaton] {
        q_0
         -> [loop above, "a"]
        q_0
         -> ["b", bend left]
        q_1 [accepting]
         -> [loop above, "b"]
        q_1
         -> ["a", bend left]
        q_0;
      };
    \end{tikzpicture}
  \end{equation*}
  \caption{\Iac*{DFA} that accepts, from state $q_0$, exactly those words that end with $b$. (Repeated from \cref{fig:dfa-example-ends-b}.)}\label{fig:ordered-rewriting:dfa-example-ends-b}
\end{marginfigure}
%
that accepts exactly those words, over the alphabet $\ialph = \set{a,b}$, that end with $b$; that \ac{DFA} is encoded by the following definitions:
\begin{equation*}
  \begin{lgathered}
    \dfa{q}_0 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top) \\
    \dfa{q}_1 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one)
  \end{lgathered}
\end{equation*}
Indeed, just as the \ac{DFA} has a transition $q_0 \dfareduces[b] q_1$, its encoding admits a trace
\begin{align*}
  &b \oc \dfa{q}_0
     = b \oc \bigl((a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top)\bigr)
     \Reduces b \oc (b \limp \dfa{q}_1)
     \reduces \dfa{q}_1
  \,.
\intertext{And, just as $q_1$ is an accepting state, its encoding also admits a trace}
  &\emp \oc \dfa{q}_1 = \emp \oc \bigl((a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one)\bigr) \Reduces \emp \oc (\emp \limp \one) \reduces \one
  \,.
\end{align*}

\newthought{More generally}, this encoding is complete, in the sense that it simulates all \ac{DFA} transitions: $q \dfareduces[a] q'$ implies $a \oc \dfa{q} \Reduces \dfa{q}'$, for all states $q$ and $q'$ and input symbols $a$.

However, the converse does not hold -- the encoding is unsound because there are rewritings that cannot be simulated by \iac{DFA} transition.
% That is, $a \oc \dfa{q} \Reduces \dfa{q}'$ does \emph{not} imply $q \dfareduces[a] q'$.
% 
\begin{falseclaim}
  Let $\aut{A} = (Q, \mathord{\dfareduces}, F)$ be \iac{DFA} over the input alphabet $\ialph$.
  Then $a \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[a] q'$, for all input symbols $a \in \ialph$.
\end{falseclaim}
%
\begin{marginfigure}
    \centering
    % \subfloat[][]{\label{fig:ordered-rewriting:dfa-counterexample:dfa}%
      \begin{equation*}
        \aut{A}'_2 = 
      \begin{tikzpicture}[baseline=(q_0.base)]
        \graph [automaton] {
          q_0
           -> [loop above, "a"]
          q_0
           -> ["b", bend left]
          q_1 [accepting]
           -> [loop above, "b"]
          q_1
           -> ["a", bend left]
          q_0;
          %
%          { [chain shift={(2,0)}]
            s_1 [accepting, below=1.5em of q_1.south]
             -> [loop right, "b"]
            s_1
             -> ["a", bend left]
            q_0;
%          };
        };
      \end{tikzpicture}
    \end{equation*}
    % }
    % \subfloat[][]{\label{fig:ordered-rewriting:dfa-counterexample:encoding}%
      $\!\begin{aligned}
        \dfa{q}_0 &\defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top) \\
        \dfa{q}_1 &\defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one) \\
        \dfa{s}_1 &\defd (a \limp \dfa{q}_0) \with (b \limp \dfa{s}_1) \with (\emp \limp \one)
      \end{aligned}$%
    % }
    \caption{{fig:ordered-rewriting:dfa-counterexample:dfa}~A slightly modified version of the \ac*{DFA} from \cref{fig:ordered-rewriting:dfa-example-ends-b}; and {fig:ordered-rewriting:dfa-counterexample:encoding}~its encoding}\label{fig:ordered-rewriting:dfa-counterexample}
  \end{marginfigure}%
\begin{proof}[Counterexample]
  Consider the \ac{DFA} and encoding shown in the adjacent \lcnamecref{fig:ordered-rewriting:dfa-counterexample}; it is the same \ac{DFA} as shown in \cref{fig:ordered-rewriting:dfa-example-ends-b}, but with one added state, $s_1$, that is unreachable from $q_0$ and $q_1$.
    %
  % When encoded as an ordered rewriting specification, it corresponds to the following definitions:
  % \begin{equation*}
  %   \begin{lgathered}
  %     \dfa{q}_0 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top) \\
  %     \dfa{q}_1 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one) \\
  %     \dfa{s}_1 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{s}_1) \with (\emp \limp \one)
  %   \end{lgathered}
  % \end{equation*}
  Notice that, as a coinductive consequence of the equirecursive treatment of definitions, $\dfa{q}_1 = \dfa{s}_1$.
  Previously, we saw that $b \oc \dfa{q}_0 \Reduces \dfa{q}_1$; hence $b \oc \dfa{q}_0 \Reduces \dfa{s}_1$.
  However, the \ac{DFA} has no $q_0 \dfareduces[b] s_1$ transition (because $q_1 \neq s_1$), and so this encoding is unsound with respect to the operational semantics of \acp{DFA}.
\end{proof}

As this counterexample shows, the lack of adequacy stems from attempting to use an encoding that is not injective -- here, $q_1 \neq s_1$ even though $\dfa{q}_1 = \dfa{s}_1$.
In other words, eqality of state encodings is a coarser eqvivalence than equality of the states themselves.

One possible remedy for this lack of adequacy might be to revise the encoding to have a stronger nominal character.
By tagging each state's encoding with an atom that is unique to that state, we can make the encoding manifestly injective.
For instance, given the pairwise distinct atoms $\Set{q \given q \in F}$ and $\Set{\bar{q} \given q \in Q - F}$ to tag final and non-final states, respectively, we could define an alternative encoding, $\check{q}$:
%
\begin{gather*}
  \check{q} \defd
    \parens[size=big]{
      \bigwith_{a \in \ialph}(a \limp \check{q}'_a)}
    \with
    \parens[size=big]{\emp \limp \check{F}(q)}
  %
  \shortintertext{where}
  %
  q \dfareduces[a] q'_a
  \text{, for all input symbols $a \in \ialph$,\quad and\quad}
  \check{F}(q) =
    \begin{cases*}
      q & if $q \in F$ \\
      \bar{q} & if $q \notin F$%
    \,.
    \end{cases*}
\end{gather*}
%
Under this alternative encoding, the states $q_1$ and $s_1$ of \cref{fig:ordered-rewriting:dfa-counterexample} are no longer a counterexample to injectivity:
Because $q_1$ and $s_1$ are distinct states, they correspond to distinct tags, and so $\check{q}_1 \neq \check{s}_1$.

% One possible remedy
% % for this apparent lack of adequacy
% might be to revise the encoding to have a stronger nominal character % .
% by tagging each state's encoding with an atom that is unique to that state.
% For instance, given the pairwise distinct atoms $\set{q \given q \in F}$ and $\set{\bar{q} \given q \in Q - F}$ to tag final and non-final states, respectively, we could define an alternative encoding, $\check{q}$, that is manifestly injective:
% %
% % \begin{marginfigure}
% \begin{gather*}
%   \check{q} \defd
%     \parens[size=big]{
%       \bigwith_{a \in \ialph}(a \limp \check{q}'_a)}
%     \with
%     \parens[size=big]{\emp \limp \check{F}(q)}
%   %
%   \shortintertext{where}
%   %
%   q \dfareduces[a] q'_a
%   \text{, for all input symbols $a \in \ialph$,\quad and\quad}
%   \check{F}(q) =
%     \begin{cases*}
%       q & if $q \in F$ \\
%       \bar{q} & if $q \notin F$%
%     \,.
%     \end{cases*}
% \end{gather*}
% % \end{marginfigure}%
% % , the encoding can be made to be injective.
% % With this change, the alternative encoding is now injective: $\check{q} = \check{s}$ implies $q = s$.

Although such a solution is certainly possible, it seems unsatisfyingly ad~hoc.
A closer examination of the preceding counterexample reveals that the states $q_1$ and $s_1$, while not equal, are in fact bisimilar~\parencref{??}.
In other words, although the encoding is not, strictly speaking, injective, it is injective \emph{up to bisimilarity}: $\dfa{q} = \dfa{s}$ implies $q \asim s$.
This suggests a more elegant solution to the apparent lack of adequacy: the encoding's adequacy should be judged up to \ac{DFA} bisimilarity.
%
\renewcommand{\dfaadequacybisimbody}{%
  Let $\aut{A} = (Q, ?, F)$ be \iac{DFA} over the input alphabet $\ialph$.
  Then, for all states $q$, $q'$, and $s$:
  \begin{enumerate}
  \item\label{enum:ordered-rewriting:dfa-adequacy:1}
    $q \asim s$ if, and only if, $\dfa{q} = \dfa{s}$.
  \item\label{enum:ordered-rewriting:dfa-adequacy:2}
    $q \asim\dfareduces[a]\asim q'$ if, and only if, $a \oc \dfa{q} \Reduces \dfa{q}'$, for all input symbols $a \in \ialph$.    
    More generally, $q \asim\dfareduces[w]\asim q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$, for all finite words $w \in \finwds{\ialph}$.
  \item\label{enum:ordered-rewriting:dfa-adequacy:3}
    $q \in F$ if, and only if, $\emp \oc \dfa{q} \Reduces \one$.
  \end{enumerate}%
}%
%  
\begin{restatable*}[
  name=\ac*{DFA} adequacy up to bisimilarity,
  label=thm:ordered-rewriting:dfa-adequacy-bisim
]{theorem}{dfaadequacybisim}
  \dfaadequacybisimbody
% Let $\aut{A} = (Q, \mathord{\dfareduces}, F)$ be \iac{DFA} over the input alphabet $\ialph$.
%   Then, for all states $q$, $q'$, and $s$:
%   \begin{enumerate}
%   \item\label{enum:ordered-rewriting:dfa-adequacy:1}
%     $q \asim s$ if, and only if, $\dfa{q} = \dfa{s}$.
%   \item\label{enum:ordered-rewriting:dfa-adequacy:2}
%     $q \asim\dfareduces[a]\asim q'$ if, and only if, $a \oc \dfa{q} \Reduces \dfa{q}'$, for all input symbols $a \in \ialph$.    
%     More generally, $q \asim\dfareduces[w]\asim q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$, for all finite words $w \in \finwds{\ialph}$.
%   \item\label{enum:ordered-rewriting:dfa-adequacy:3}
%     $q \in F$ if, and only if, $\emp \oc \dfa{q} \Reduces \one$.
%   \end{enumerate}
\end{restatable*}

Before proving this \lcnamecref{thm:ordered-rewriting:dfa-adequacy-bisim}, we must first prove a \lcnamecref{lem:ordered-rewriting:dfa-traces}: the only traces from one state's encoding to another's are the trivial traces.
%
\begin{lemma}\label{lem:ordered-rewriting:dfa-traces}
  Let $\aut{A} = (Q, ?, F)$ be \iac{DFA} over the input alphabet $\ialph$.
  For all states $q$ and $s$, if $\dfa{q} \Reduces \dfa{s}$, then $\dfa{q} = \dfa{s}$.
\end{lemma}
%
\begin{proof}
  Assume that a trace $\dfa{q} \Reduces \dfa{s}$ exists.
  If the trace is trivial, then $\dfa{q} = \dfa{s}$ is immediate.
  Otherwise, the trace is nontrivial and consists of a strictly positive number of rewriting steps.
  By inversion, those rewriting steps drop one or more conjuncts from $\dfa{q}$ to form $\dfa{s}$.
  Every \ac{DFA} state's encoding contains exactly $\card{\ialph} + 1$ conjuncts -- one for each input symbol $a$ and one for the end-of-word marker, $\emp$.
  % Being the encoding of \iac{DFA} state, $\dfa{q}$ contains one $(\emp \limp \dotsb)$ conjunct and exactly one $(a \limp \dotsb)$ conjunct for each input symbol $a$.
  % Similarly, $\dfa{s}$ must contain the same.
  If even one conjunct is dropped from $\dfa{q}$, not enough conjuncts will remain to form $\dfa{s}$.
  Thus, a nontrivial trace $\dfa{q} \Reduces \dfa{s}$ cannot exist.
\end{proof}
%
\noindent
It is important to differentiate this \lcnamecref{lem:ordered-rewriting:dfa-traces} from the false claim that a state's encoding can take no rewriting steps.
There certainly exist nontrivial traces from $\dfa{q}$, but they do not arrive at the encoding of any state.

With this \lcnamecref{lem:ordered-rewriting:dfa-traces} now in hand, we can proceed to proving adequacy up to bisimilarity.
%
\dfaadequacybisim
%
\begin{proof}
  Each part is proved in turn.
  The proof of part~\ref{enum:ordered-rewriting:dfa-adequacy:2} % and~\ref{enum:ordered-rewriting:dfa-adequacy:4}
  depends on the proof of part~\ref{enum:ordered-rewriting:dfa-adequacy:1}.
  \begin{enumerate}[parsep=0em, listparindent=\parindent]
  %% Part one
  \item
    We shall show that bisimilarity coincides with equality of encodings, proving each direction separately.
    \begin{itemize}[parsep=0em, listparindent=\parindent]
    \item
      To prove that bisimilar \ac{DFA} states have equal encodings -- \ie, that $q \asim s$ implies $\dfa{q} = \dfa{s}$ -- a fairly straightforward proof by coinduction suffices.

      Let $q$ and $s$ be bisimilar states.
      By the definition of bisimilarity~\parencref{??}, two properties hold:
      \begin{itemize}
      \item For all input symbols $a$, the unique $a$-successors of $q$ and $s$ are also bisimilar.
      \item States $q$ and $s$ have matching finalities -- \ie, $q \in F$ if and only if $s \in F$.
      \end{itemize}
      Applying the coinductive hypothesis to the former property, we may deduce that, for all symbols $a$, the $a$-successors of $q$ and $s$ also have equal encodings.
      From the latter property, it follows that $\dfa{F}(q) = \dfa{F}(s)$.
      Because definitions are interpreted equirecursively, these equalities together imply that $q$ and $s$ themselves have equal encodings.

    \item
      To prove the converse -- that states with equal encodings are bisimilar -- we will show that the relation $\mathord{\simu{R}} = \Set{(q, s) \given \dfa{q} = \dfa{s}}$, which relates states if they have equal encodings, is a bisimulation and is therefore included in bisimilarity.
      \begin{itemize}
      \item
        The relation $\simu{R}$ is symmetric.
      \item
        We must show that $\simu{R}$-related states have $\simu{R}$-related $a$-successors, for all input symbols $a$.

        Let $q$ and $s$ be $\simu{R}$-related states.
        Being $\simu{R}$-related, $q$ and $s$ have equal encodings;
        because definitions are interpreted equirecursively, the unrollings of those encodings are also equal.
        By definition of the encoding, it follows that, for each input symbol $a$, the unique $a$-successors of $q$ and $s$ have equal encodings.
        Therefore, for each $a$, the $a$-successors of $q$ and $s$ are themselves $\simu{R}$-related.

      \item
        We must show that $\simu{R}$-related states have matching finalities.

        Let $q$ and $s$ be $\simu{R}$-related states, with $q$ a final state.
        Being $\simu{R}$-related, $q$ and $s$ have equal encodings;
        because definitions are interpreted equirecursively, the unrollings of those encodings are also equal.
        It follows that $\dfa{F}(q) = \dfa{F}(s)$, and so $s$ is also a final state.
      \end{itemize}
    \end{itemize}

  %% Part two
  \item
    We would like to prove that $q \asim\dfareduces[a]\asim q'$ if, and only if, $a \oc \dfa{q} \Reduces \dfa{q}'$, or, more generally, that $q \asim\dfareduces[w]\asim q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$.
    Because bisimilar states have equal encodings (part~\ref{enum:ordered-rewriting:dfa-adequacy:1}) and bisimilarity is reflexive (\cref{??}), it suffices to show two stronger statements:
    \begin{enumerate*}
    \item that $q \dfareduces[w] q'$ implies $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$; and
    \item that $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[w]\asim q'$.
    \end{enumerate*}
    %
    We prove these in turn.
    %
    \begin{enumerate}
    %% Subpart (a)
    \item
      We shall prove that $q \dfareduces[w] q'$ implies $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$ by induction over the structure of word $w$.
      \begin{itemize}
      \item
        Consider the case of the empty word, $\emp$; we must show that $q = q'$ implies $\dfa{q} \Reduces \dfa{q}'$.
        Because the encoding is a function, this is immediate.
      \item
        Consider the case of a nonempty word, $a \wc w$; we must show that $q \dfareduces[a]\dfareduces[w] q'$ implies $\rev{w} \oc a \oc \dfa{q} \Reduces \dfa{q}'$.
        Let $q'_a$ be an $a$-successor of state $q$ that is itself $w$-succeeded by state $q'$.
        There exists, by definition of the encoding, a trace
        \begin{equation*}
          \rev{w} \oc a \oc \dfa{q}
            \Reduces \rev{w} \oc a \oc (a \limp \dfa{q}'_a)
            \reduces \rev{w} \oc \dfa{q}'_a
            \Reduces \dfa{q}'
          \,,
        \end{equation*}
        with the trace's tail justified by an appeal to the inductive hypothesis.
        % Because $q'$ is a $w$-successor of $q'_a$, an appeal to the inductive hypothesis yields a trace $\rev{w} \oc \dfa{q}'_a \Reduces \dfa{q}'$.
      \end{itemize}

      % Let $q'$ be an $a$-successor of state $q$.
      % There exists, by definition of the encoding, a trace
      % \begin{equation*}
      %   a \oc \dfa{q} \Reduces a \oc (a \limp \dfa{q}') \reduces \dfa{q}'
      % \,.
      % \end{equation*}

    %% Subpart (b)
    \item
      We shall prove that $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[w]\asim q'$ by induction over the structure of word $w$.
      \begin{itemize}
      \item
        Consider the case of the empty word, $\emp$;
        we must show that $\dfa{q} \Reduces \dfa{q}'$ implies $q \asim q'$.
        By \cref{lem:ordered-rewriting:dfa-traces}, $\dfa{q} \Reduces \dfa{q}'$ implies that $q$ and $q'$ have equal encodings.
        Part~\ref{enum:ordered-rewriting:dfa-adequacy:1} can then be used to establish that $q$ and $q'$ are bisimilar.
      \item
        Consider the case of a nonempty word, $a \wc w$;
        we must show that $\rev{w} \oc a \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[a]\dfareduces[w]\asim q'$.
        By inversion\fixnote{Is this enough justification?}, the given trace can only begin by inputting $a$:
        \begin{equation*}
          \rev{w} \oc a \oc \dfa{q}
            \Reduces \rev{w} \oc a \oc (a \limp \dfa{q}'_a)
            \reduces \rev{w} \oc \dfa{q}'_a
            \Reduces \dfa{q}'
          \,,
        \end{equation*}
        where $q'_a$ is an $a$-successor of state $q$.
        An appeal to the inductive hypothesis on the trace's tail yields $q'_a \dfareduces[w]\asim q'$, and so the \ac{DFA} admits $q \dfareduces[a]\dfareduces[w]\asim q'$, as required.
      \end{itemize}
      % Assume that a trace $a \oc \dfa{q} \Reduces \dfa{q}'$ exists.
      % By the input lemma, $\dfa{q} \Reduces (a \limp A) \oc \octx'$ for some proposition $A$ and context $\octx'$ such that $A \oc \octx' \Reduces \dfa{q}'$.
      % Upon inversion of the trace from $\dfa{q}$, we conclude that $A = \dfa{q}'_a$, where $q'_a$ is an $a$-successor of $q$, and that $\octx'$ is empty -- in other words, we have a trace $\dfa{q}'_a \Reduces \dfa{q}'$.
      % Such a trace exists only if $\dfa{q}'_a = \dfa{q}'$.
      % By part~\ref{enum:ordered-rewriting:dfa-adequacy:1} of this \lcnamecref{thm:ordered-rewriting:dfa-adequacy-bisim}, it follows that $q'_a$ and $q'$ are bisimilar.
    \end{enumerate}

  %% Part three
  \item
    We shall prove that the final states are exactly those states $q$ such that $\emp \oc \dfa{q} \Reduces \one$.
    \begin{itemize}
    \item
      Let $q$ be a final state; accordingly, $\dfa{F}(q) = \one$.
      There exists, by definition of the encoding, a trace
      \begin{equation*}
        \emp \oc \dfa{q} \Reduces \emp \oc (\emp \limp \dfa{F}(q)) \reduces \dfa{F}(q) = \one
      \,.
      \end{equation*}

    \item
      Assume that a trace $\emp \oc \dfa{q} \Reduces \one$ exists.
      By inversion\fixnote{Is this enough justification?}, this trace can only begin by inputting $\emp$:
      \begin{equation*}
        \emp \oc \dfa{q} \Reduces \emp \oc (\emp \limp \dfa{F}(q)) \reduces \dfa{F}(q) \Reduces \one
      \,.
      \end{equation*}
      The tail of this trace, $\dfa{F}(q) \Reduces \one$, can exist only if $q$ is a final state.
    %
    \qedhere
    \end{itemize}

  % %% Part four
  % \item 
  %   We would like to prove that $q \asim\dfareduces[w]\asim q'$ if, and only if, $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$.
  %   Because bisimilar states have equal encodings (part~\ref{enum:ordered-rewriting:dfa-adequacy:1}) and bisimilarity is reflexive (\cref{??}), it suffices to show:
  %   \begin{enumerate*}
  %   \item that $q \dfareduces[w] q'$ implies $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$; and
  %   \item that $\rev{w} \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[w]\asim q'$.
  %   \end{enumerate*}

  %   Both statements can be established by induction over the structure of word $w$.
  %   The latter proof is slightly more involved and deserves a bit of explanation.
  %   \begin{itemize}
  %   \item Consider the case in which $w$ is the empty word; we must show that $\dfa{q} \Reduces \dfa{q}'$ implies $q \asim q'$.
  %     By \cref{lem:ordered-rewriting:dfa-traces}, $\dfa{q} \Reduces \dfa{q}'$ implies that $\dfa{q} = \dfa{q}'$.
  %     Part~\ref{enum:ordered-rewriting:dfa-adequacy:1} can then be used to establish $q$ and $q'$ as bisimilar.

  %   \item Consider the case of a nonempty word, $a \wc w$.
  %     We must show that $\rev{w} \oc a \oc \dfa{q} \Reduces \dfa{q}'$ implies $q \dfareduces[a]\dfareduces[w]\asim q'$.
  %     By inversion, the given trace must begin by inputting $a$:
  %     \begin{equation*}
  %       \rev{w} \oc a \oc \dfa{q} \Reduces \rev{w} \oc a \oc (a \limp \dfa{q}'_a) \reduces \rev{w} \oc \dfa{q}'_a \Reduces \dfa{q}'
  %       \,,
  %     \end{equation*}
  %     where $q'_a$ is an $a$-successor of state $q$.
  %     Appealing to the inductive hypothesis on the trace's tail yields $q'_a \dfareduces[w]\asim q'$, and so $q \dfareduces[a]\dfareduces[w]\asim q'$, as required.
  %   %
  %   \qedhere
  %   \end{itemize}
  \end{enumerate}
\end{proof}


\subsection{Encoding \aclp*{NFA}?}

We would certainly be remiss if we did not attempt to generalize the rewriting specification of \acp{DFA} to one for their nondeterministic cousins.

Differently from \ac{DFA} states, \iac{NFA} state $q$ may have several nondeterministic successors for each input symbol $a$.
To encode the \ac{NFA} state $q$, all of its $a$-successors are collected in an alternative conjunction underneath the left-handed input of $a$.
Thus, the encoding of \iac{NFA} state $q$ becomes
\begin{equation*}
  \nfa{q} \defd
    \parens[size=auto]{\displaystyle
      \bigwith_{a \in \ialph}
        \parens[size=big]{a \limp \parens{\bigwith_{q'_a} \nfa{q}'_a}}
    }
    \with
    \parens[size=big]{\emp \limp \nfa{F}(q)}
  \,,
\end{equation*}
where $\nfa{F}(q)$ is defined as for \acp{DFA}.

The adjacent \lcnamecref{fig:ordered-rewriting:nfa-example}
\begin{marginfigure}
  \centering
  % \subfloat[][]{\label{fig:ordered-rewriting:nfa-example:nfa}%
    \begin{tikzpicture}
      \graph [automaton] {
        q_0
         -> ["a,b", loop above]
        q_0
         -> ["b"]
        q_1 [accepting]
         -> ["a,b"]
        q_2
         -> ["a,b", loop above]
        q_2;
      };
    \end{tikzpicture}
  % }

%   \subfloat[][]{\label{fig:ordered-rewriting:nfa-example:encoding}%
      $\!\begin{aligned}
        \nfa{q}_0 &\defd (a \limp \nfa{q}_0) \with \bigl(b \limp (\nfa{q}_0 \with \nfa{q}_1)\bigr) \with (\emp \limp \top) \\
        \nfa{q}_1 &\defd (a \limp \nfa{q}_2) \with (b \limp \nfa{q}_2) \with (\emp \limp \one) \\
        \nfa{q}_2 &\defd (a \limp \nfa{q}_2) \with (b \limp \nfa{q}_2) \with (\emp \limp \top)
      \end{aligned}$
%     }

  \caption{{fig:ordered-rewriting:nfa-example:nfa}~\Iac*{NFA} that accepts exactly those words, over the alphabet $\ialph = \set{a,b}$, that end with $b$; and {fig:ordered-rewriting:nfa-example:encoding}~its encoding}\label{fig:ordered-rewriting:nfa-example}
\end{marginfigure}%
recalls from \cref{ch:automata} \iac{NFA} that accepts exactly those words, over the alphabet $\ialph = \set{a,b}$, that end with $b$.
Using the above encoding of \acp{NFA}, ordered rewriting does indeed simulate this \ac{NFA}.
For example, just as there are transitions $q_0 \nfareduces[b] q_0$ and $q_0 \nfareduces[b] q_1$, there are traces
\begin{equation*}
  \begin{tikzcd}[
    cells={inner xsep=0.65ex,
           inner ysep=0.4ex},
         % nodes={draw},
    row sep=0em,
    column sep=scriptsize
  ]
    &[-0.2em] \nfa{q}_0
    \\
    b \oc \nfa{q}_0 \Reduces b \oc \bigl(b \limp (\nfa{q}_0 \with \nfa{q}_1)\bigr) \reduces \nfa{q}_0 \with \nfa{q}_1
      \urar[reduces, start anchor=east]
      \drar[reduces, start anchor=base east]
    \\
    & \nfa{q}_1
  \end{tikzcd}
\end{equation*}

Unfortunately, while it does simulate \ac{NFA} behavior, this encoding is not adequate.
Like \ac{DFA} states, \ac{NFA} states that have equal encodings are bisimilar.
% \begin{proof}
%   Define a relation $\mathord{\simu{R}} = \set{(q, s) \given \nfa{q} = \nfa{s}}$; we will show that $\simu{R}$ is a bisimulation.
%   \begin{itemize}
%   \item Assume that $s \simu{R}^{-1} q \nfareduces[a] q'_a$.
%     By definition, $a \oc \nfa{q} \Reduces \nfa{q}'_a$.
%     Because $\nfa{q} = \nfa{s}$, it follows that $s \nfareduces[a] s'_a$ for some state $s'_a$ such that $\nfa{q}'_a = \nfa{s}'_a$ -- that is, $q'_a \simu{R} s'_a$.
%     Thus, $s \nfareduces[a]\simu{R}^{-1} q'_a$.
%   \item Assume that $q \simu{R} s$.
%     It follows that $\nfa{F}(q) = \nfa{F}(s)$.
%     Thus, $q$ is an accepting state if and only if $s$ is.
%   \end{itemize}
% \end{proof}
However, for \acp{NFA}, the converse does not hold: bisimilar states do not necessarily have equal encodings.
%
\begin{falseclaim}
  Let $\aut{A} = (Q, ?, F)$ be \iac{NFA} over input alphabet $\ialph$.
  Then $q \asim s$ implies $\nfa{q} = \nfa{s}$, for all states $q$ and $s$.
\end{falseclaim}
%
\begin{proof}[Counterexample]
  Consider the \ac{NFA} and encoding depicted in the adjacent \lcnamecref{fig:ordered-rewriting:nfa-counterexample}.
  \begin{marginfigure}
    \begin{alignat*}{2}
      \begin{tikzpicture}
        \graph [automaton] {
          q_0 [accepting]
           -> ["a", loop above]
          q_0
           -> ["a", overlay]
          q_1 [accepting, overlay]
           -> ["a", loop above, overlay]
          q_1;
        };
      \end{tikzpicture}
      &\quad&&
      \\
      &\quad& \nfa{q}_0 &\defd \bigl(a \limp (\nfa{q}_0 \with \nfa{q}_1)\bigr) \with (\emp \limp \one) \\
      &\quad& \nfa{q}_1 &\defd (a \limp \nfa{q}_1) \with (\emp \limp \one)
    \end{alignat*}
    \caption{\Iac*{NFA} that accepts all finite words over the alphabet $\ialph = \set{a}$}\label{fig:ordered-rewriting:nfa-counterexample}
  \end{marginfigure}
  It is easy to verify that the relation $\set{q_1} \times \set{q_0,q_1}$ is a bisimulation; in particular, $q_1$ simulates the $q_0 \nfareduces[a] q_1$ transition by its self-loop, $q_1 \nfareduces[a] q_1$.
  Hence, $q_0$ and $s_0$ are bisimilar.
  %
  % These same \acp{NFA} are encoded by the following definitions.
  % \begin{align*}
  %   \nfa{q}_0 &\defd (a \limp \nfa{q}_0) \with (\emp \limp \one)
  % \shortintertext{and}
  %   \nfa{s}_0 &\defd \bigl(a \limp (\nfa{s}_0 \with \nfa{s}_1)\bigr) \with (\emp \limp \one) \\
  %   \nfa{s}_1 &\defd (a \limp \nfa{s}_1) \with (\emp \limp \one)
  % \end{align*}
  It is equally easy to verify, by unrolling the definitions used in the encoding, that $\nfa{q}_0 \neq \nfa{s}_0$.
\end{proof}

For \acp{DFA}, bisimilar states do have equal encodings because the inherent determinism \ac{DFA} bisimilarity is a rather fine-grained equivalence.
Because each \ac{DFA} state has exactly one successor for each input symbol
The additional flexibility entailed by nondeterminism

Once again, it would be possible to construct an adequate encoding, by tagging each state with a unique atom.
% with a stronger nominal character

For the moment, we will put aside the question of an adequate encoding of \acp{NFA}.

\subsection{Binary representation of natural numbers}

As a further example of ordered rewriting, consider a rewriting specification of binary counters: binary representations of natural numbers equipped with increment and decrement operations.

\paragraph*{Binary representations}
In this setting, we represent a natural number in binary by
% A binary representation of a natural number is
an ordered context that consists of a big-endian sequence of atoms $b_0$ and $b_1$, prefixed by the atom $e$; leading $b_0$s are permitted.
For example, both $\octx = e \oc b_1$ and $\octx' = e \oc b_0 \oc b_1$ are valid binary representations of the natural number $1$.

To be more precise, we inductively define a relation, $\aval{}{}$, 
% [between binary representations and the natural number [value]s that they represent.]
that assigns to each binary representation a unique natural number denotation.
% , defined inductively by the following rules.
% between ordered contexts and natural numbers that is inductively defined by the following rules.
When $\aval{\octx}{n}$, we say that $\octx$ denotes, or represents, natural number $n$ in binary.
%
\newcommand{\ooavalrules}{%
  \infer[\jrule{$e$-V}]{\aval{e}{0}}{}
  \and
  \infer[\jrule{$b_0$-V}]{\aval{\octx \oc b_0}{2n}}{
    \aval{\octx}{n}}
  \and
  \infer[\jrule{$b_1$-V}]{\aval{\octx \oc b_1}{2n+1}}{
    \aval{\octx}{n}}%
}%
\begin{inferences}
  \ooavalrules
\end{inferences}
% [In addition to assigning each binary representation a natural number value,]
Besides providing a denotational semantics of binary numbers, the $\aval{}{}$ relation also serves to implicitly characterize the well-formed binary numbers as those ordered contexts $\octx$ that form the relation's domain of definition.%
% Implicit in this definition is 
\footnote{Alternatively, the well-formed binary numbers could be described more explicitly by the grammar
% More precisely, the binary numbers are those contexts that are generated by the following grammar:
\begin{equation*}
  \octx \Coloneqq e \mid \octx \oc b_0 \mid \octx \oc b_1
  \,.
\end{equation*}%
}

These properties\fixnote{which properties?} of the $\aval{}{}$ relation are proved as the following adequacy \lcnamecref{thm:ordered-rewriting:binary-adequacy}.
%
\newcommand{\ooavaltheorem}{%
  \begin{theorem}[Adequacy of binary representations]\label{thm:ordered-rewriting:binary-adequacy}%
    \leavevmode
    \begin{thmdescription}
    \item[Functional]
      For every binary number $\octx$, there exists a unique natural number $n$ such that $\aval{\octx}{n}$.
      % [If $\aval{\octx}{n}$ and $\aval{\octx}{n'}$, then $n = n'$.]
    \item[Surjectivity]
      For every natural number $n$, there exists a binary number $\octx$ such that $\aval{\octx}{n}$.
      % Moreover, when the rule for $b_0$ is restricted to nonzero even numbers, the representation is unique.
    \item[Value]
      If $\aval{\octx}{n}$, then $\octx \nreduces$.
    \end{thmdescription}
  \end{theorem}%
}%
%
\ooavaltheorem
\begin{proof}
  The three claims may be proved by induction over the structure of $\octx$, and by induction on $n$, respectively.
\end{proof}

Notice that the above $\jrule{$e$-V}$ and $\jrule{$b_0$-V}$ rules overlap when the denotation\fixnote{represented natural number?} is $0$, giving rise to the leading $b_0$s that make the $\aval{}{}$ relation surjective:
for example, both $\aval{e \oc b_1}{1}$ and $\aval{e \oc b_0 \oc b_1}{1}$ hold.
However, if the rule for $b_0$ is restricted to \emph{nonzero} even numbers, then each natural number has a unique, canonical representation that is free of leading $b_0$s.%
\footnote{
  A restriction of the $b_0$ rule to nonzero even numbers is:
  \begin{equation*}
    \infer{\aval{\octx \oc b_0}{2n}}{
      \aval{\octx}{n} & \text{($n > 0$)}}
  \,.
  \end{equation*}
  The leading-$b_0$-free representations could alternatively be seen as the canonical representatives of the equivalence classes induced by the equivalence relation among binary numbers that have the same denotation: $\octx \equiv \octx'$ if $\aval{\octx}{n}$ and $\aval{\octx'}{n}$ for some $n$.}


% This leads to a nontrivial equivalence relation over binary numbers: binary numbers $\octx$ and $\octx'$ are equivalent up to leading $b_0$s if both $\octx$ and $\octx'$ represent the same $n$.
% % $\aval{\octx}{n}$ and $\aval{\octx}{n}$ for some $n$.
% Corresponding to the [...] of leading $b_0$s.

% Define a nontrivial equivalence relation on binary numbers. 

% If the rule for $\octx \oc b_0$ is restricted to apply to only strictly positive even numbers


% (\octx, n) R(~) (\octx', n) iff \octx ~ n and \octx' ~ n
% R(~) is an equivalence relation.
% ~/R(~) = {[(\octx, n)] | \octx ~ n}
% \octx ~/R(~) n iff \octx is leading-b0-free and \octx ~ n

% Let ~ be an equivalence relation over X.
% Let [-] : X -> X/~ be the surjection that maps to equivalence classes
% Let s : X/~ -> X be an injective function such that [s(c)] = c.

% This function describes an adequate representation because it forms a bijection (up to leading $b_0$s) between binary counters and natural numbers.
% %
% \begin{theorem}[Representational adequacy]
%   Up to leading $b_0$s, the $\aval{}{}$ relation is a bijection:
%   \begin{itemize}[noitemsep]
%   \item
%     For every binary counter $\octx$, there exists a unique natural number $n$ such that $\aval{\octx}{n}$.
%   \item
%     Conversely, for every natural number $n$, there exists a binary counter $\octx$, unique up to leading $b_0$s, such that $\aval{\octx}{n}$.
%   \item
%     For all binary counters $\octx$ and $\octx'$ that are syntactically equal modulo leading $b_0$s, $\aval{\octx}{n}$ if, and only if, $\aval{\octx'}{n}$.
%   \end{itemize}
% \end{theorem}
% %
% \begin{proof}
%   The two claims may be proved by induction over the structure of the binary counter $\octx$, and by induction on the natural number $n$, respectively.
% \end{proof}

% Alternatively, binary counters could be organized around leading-$b_0$--free representations.
% Leading-$b_0$--free representations form a retract within the binary counters, with the 
% \begin{equation*}
%   \begin{lgathered}
%     r(e) = e \\
%     r(\octx \oc b_0) =
%       \begin{cases*}
%         e & if $r(\octx) = e$ \\
%         r(\octx) \oc b_0 & otherwise
%       \end{cases*} \\
%     r(\octx \oc b_1) = r(\octx) \oc b_1
%   \end{lgathered}
% \end{equation*}

% Notice that the representations that are free of leading $b_0$s form a retract 

% \begin{inferences}
%   \infer{\aval{e}{0}}{}
%   \and
%   \infer{\aval{\octx \oc b_0}{2n+2}}{
%     \aval{\octx}{' n+1}}
%   \and
%   \infer{\aval{\octx \oc b_1}{2n+1}}{
%     \aval{\octx}{n}}
%   \and
%   \infer{\aval{\octx \oc b_0}{' 2n+2}}{
%     \aval{\octx}{' n+1}}
%   \and
%   \infer{\aval{\octx \oc b_1}{' 2n+1}}{
%     \aval{\octx}{n}}
% \end{inferences}

% % bin = +{ e: 1, b0: pos, b1: bin }
% % pos = +{ b0: pos, b1: bin }
% %
% % bin = &{ i: pos, d: +{ z: 1, s: bin  } }
% % pos = &{ i: pos, d: bin }
% %
% % e = (e * b1 / i) & (z / d) & (e * z / h)
% % b0 = (b1 / i) & (d * (s \ b1) * s) & (b0 * s / h)
% % b1 = (i * b0 / i) & (h * b1' * s / d) & (b1 * s / h)
% % b1' = (z \ 1) & (s \ b0)

% % C b0 d --> C d (s \ b1) s --> C' b1 s
% % 2(n+1) --> 2(n+1)-1 + 1 --> 2n+1 + 1

% % e b1 d --> e d b1' s --> z b1' s --> e s
% % 2(0)+1 --> 2(0) + 1 --> 2(0) + 1 --> 0 + 1

% % C b1 d --> C d b1' s --> C' s b1' s --> C' i b0 s
% % 2(n+1)+1 --> 2(n+1) + 1 --> 2(n + 1) + 1 --> 
% \begin{equation*}
%   \begin{lgathered}
%     e \defd (e \fuse b_1 \pmir i) \with (z \pmir d) \\
%     b_0 \defd (b_1 \pmir i) \with (d \fuse b_1 \fuse s \pmir d) \\
%     b_1 \defd (i \fuse b_0 \pmir i) \with (d \fuse b'_1 \pmir d) \\
%     p_0 \defd () \with (d \fuse b_1 \pmir d) \\
%     b'_1 \defd (z \limp e \fuse s) \with (s \limp i \fuse b_0 \fuse s)
%   \end{lgathered}
% \end{equation*}

% \begin{equation*}
%   \begin{lgathered}
%     e \defd (e \fuse b_1 \pmir i) \with (z \pmir d) \\
%     b_0 \defd (b_1 \pmir i) \with (d \fuse b'_0 \pmir d) \with (c \fuse b^c_0 \pmir c) \\
%     b^c_0 \defd (z \limp z) \with (s \limp b_0 \fuse s) \\
%     b'_0 \defd (z \limp z) \with (s \limp b_1 \fuse s) \\
%     b_1 \defd (b_0 \pmir i) \with (d \fuse ((z \limp e \fuse s) \with (s \limp b_0 \fuse s)) \pmir d)
%   \end{lgathered}
% \end{equation*}

% % e b1 d --> e s
% % e b1 b1 d --> e b1 d ... --> e s ... --> e i b0 s

% % 2(n+1)+1 - 1 --> 2(n+1-1)+1

% % e b1 d --> e d b1' --> z b1' --> e s
% % e b1 b0 d --> e s b0' --> e b1 s
% % e b1 b0 b0 d --> e b1 s b0' --> e b1 b1 s
% % e b1 b1 d --> e s b1' --> e i b0 s --> e b1 b0 s
% % e b1 b0 b1 d --> e b1 s b1' --> e b1 i b0 s --> e b1 b0 b0 s

% \begin{inferences}
%   \infer{\aval{e}{e}}{}
%   \and
%   \infer{\aval{\octx \oc b_0}{e}}{
%     \aval{\octx}{e}}
%   \and
%   \infer{\aval{\octx \oc b_0}{\octx' \oc b_0}}{
%     \aval{\octx}{\octx'}}
%   \and
%   \infer{\aval{\octx \oc b_1}{\octx' \oc b_1}}{
%     \aval{\octx}{\octx'}}
% \end{inferences}
% By analogy with functional computation, the ordered contexts $\octx$ that appear in this relation will serve as values -- end results of computations.

% The relation $\aval{}{}$ defines an adequate representation because it is, in fact, a bijection (up to leading $b_0$s) between ordered contexts and natural numbers.

% If we restrict our attention to counters $\octx$ that are free of leading $b_0$s, then the $\aval{}{}$ relation is a bijection with the natural numbers.
% %
% Right-unique: $\aval{\octx}{n}$ and $\aval{\octx}{n'}$, then $n = n'$.
% Left-total:

% \begin{theorem}[Representational adequacy]
%   For all natural numbers $n$, there exists a context $\octx$, unique up to leading $b_0$s, such that $\aval{\octx}{n}$.
%   Moreover, the relation $\aval{}{}$ is functional -- \ie, if $\aval{\octx}{n}$ and $\aval{\octx}{n'}$, then $n = n'$.
% \end{theorem}
% \begin{proof}
%   The first part follows by induction on the natural number $n$; the second part follows by induction on the structure of the context $\octx$.
% \end{proof}
% %
% In other words, the binary representations that are free of leading $b_0$s form a retract.


\paragraph{An increment operation}
To use ordered rewriting to describe an increment operation on binary representations, we introduce a new, uninterpreted atom $i$ that will serve as an increment instruction.

Given a binary number $\octx$ that represents $n$, we may append $i$ to form a computational state, $\octx \oc i$.
For $i$ to adequately represent the increment operation, the state $\octx \oc i$ must meet two conditions, captured by the following global desiderata:
% \lcnamecref{thm:increment-structural-adequacy}.
%global desiderata: 
\begin{theorem}\label{thm:increment-structural-adequacy}
  Let $\octx$ be a binary representation of $n$.
  Then:
  \begin{itemize}[nosep]
  \item
    \emph{some} computation from $\octx \oc i$ results in a binary representation of $n+1$ -- that is, $\octx \oc i \Reduces\aval{}{n+1}$; and
  \item
    \emph{any} computation from $\octx \oc i$ results in a binary representation of $n+1$ -- that is, $\octx \oc i \Reduces\aval{}{n'}$ only if $n' = n+1$.%
    \fixnote{Compare \enquote{If $\octx \oc i \Reduces \octx'$, then $\octx' \Reduces\aval{}{n+1}$.}}
    % Moreover, computations preserve an absence of leading $b_0$s.\fixnote{Is this necessary?}
  \end{itemize}
\end{theorem}
\noindent
For example, because $e \oc b_1$ denotes $1$, a computation $e \oc b_1 \oc i \Reduces\aval{}{2}$ must exist; moreover, every computation $e \oc b_1 \oc i \Reduces\aval{}{n'}$ must satisfy $n' = 2$.

\newthought{To implement these} global desiderata locally, the previously uninterpreted atoms $e$, $b_0$, and $b_1$ are now given mutually recursive definitions that describe how they may be rewritten when the increment instruction, $i$, is encountered.
\begin{description}[font=\color{structure}]
\item[$e \defd e \fuse b_1 \pmir i$]
  To increment $e$, append $b_1$ as a new most\fixnote{or least?} significant bit, resulting in $e \oc b_1$;
  the rewriting sequence $e \oc i \reduces e \fuse b_1 \reduces e \oc b_1$ is entailed by this definition.
\item[$b_0 \defd b_1 \pmir i$]
  To increment a binary number ending in $b_0$, flip that bit to $b_1$;
  the entailed rewriting step is $\octx \oc b_0 \oc i \reduces \octx \oc b_1$.
\item[$b_1 \defd i \fuse b_0 \pmir i$]
  To increment a binary number ending in $b_1$, flip that bit to $b_0$ and carry the increment over to the more significant bits;
  the entailed rewriting sequence is $\octx \oc b_1 \oc i \reduces \octx \oc (i \fuse b_0) \reduces \octx \oc i \oc b_0$.
\end{description}
Comfortingly, $1+1 = 2$: that is, a computation
% $e \oc b_1 \oc i \Reduces \aval{e \oc b_1 \oc b_0}{2}$, namely:
$e \oc b_1 \oc i \Reduces e \oc i \oc b_0 \Reduces e \oc b_1 \oc b_0$ indeed exists.

\newthought{It should also} be possible to permit several increments at once, such as in $e \oc b_1 \oc i \oc i$.
We could, of course, handle the increments sequentially from left to right, fully computing a binary value before moving on to the subsequent increment:
\begin{equation*}
  e \oc b_1 \oc i \oc i \Reduces e \oc b_1 \oc b_0 \oc i \reduces e \oc b_1 \oc b_1
  \,.
\end{equation*}
However, a strictly sequential treatment of increments would be rather disappointing.
Because the ordered rewriting framework\fixnote{wc?} is inherently concurrent, a truly concurrent treatment of multiple increments would be far more satisfying.

For example, consider the several computations of $(1+1)+1 = 3$ from $e \oc b_1 \oc i \oc i$:
\begin{equation*}
  \begin{tikzcd}[
    cells={inner xsep=0.65ex,
           inner ysep=0.4ex},
    row sep=0em,
    column sep=scriptsize
  ]
    &[-0.2em]
    e \oc b_1 \oc b_0 \oc i
      \drar[reduces, start anchor=base east,
                     end anchor=north west]
    &[-0.2em]
    \\
    e \oc b_1 \oc i \oc i \Reduces e \oc i \oc b_0 \oc i
      \urar[Reduces, start anchor=north east,
                     end anchor=base west]
      \ar[Reduces, gray, dashed]{rr}
      \drar[reduces, start anchor=base east,
                     end anchor=west]
    &&
    e \oc b_1 \oc b_1
    \\
    &
    e \oc i \oc b_1
      \urar[Reduces, start anchor=east,
                     end anchor=base west]
    &
  \end{tikzcd}
\end{equation*}
In other words, once the leftmost increment is carried past the least significant bit, the two increments can be processed concurrently -- the increments' rewriting steps can be interleaved, with no observable difference between the various interleavings.
We can even abstract from the interleavings by writing simply $e \oc i \oc b_0 \oc i \Reduces e \oc b_1 \oc b_1$.

Unfortunately, a concurrent treatment of increments falls outside the domain of \cref{??}.
Intermediate computational states, such as ...,
\begin{equation*}
  e \oc i \oc b_0 \oc i \reduces e \oc i \oc b_1
\end{equation*}
because $e \oc i \oc b_0$ is simply not a binary value.
An adequacy theorem stronger than \cref{??} is needed.

The situation here is roughly analogous to the desire, in a functional language, for stronger metatheorems than a big-step, natural sematics admits, and we adopt a similar solution.

\newthought{To this end}, we define a binary relation, $\ainc{}{}$, that assigns a natural number denotation to each intermediate computational state, not only to the terminal values as $\aval{}{}$ did..%
\footnote{Like the $\aval{}{}$ relation does for values, the $\ainc{}{}$ relation also serves to implicitly characterize the valid intermediate states as those contexts that form the relation's domain of definition.
As with values, the valid intermediate states could also be enumerated more explicitly and syntactically with a grammar:
\begin{equation*}
  \octx \Coloneqq e \mid \octx \oc b_0 \mid \octx \oc b_1 \mid \octx \oc i \mid e \fuse b_1 \mid \octx \oc (i \fuse b_0)
\end{equation*}}%
%
\newcommand{\aincrules}{%
  \infer[\jrule{$e$-I}]{\ainc{e}{0}}{}
  \and
  \infer[\jrule{$b_0$-I}]{\ainc{\octx \oc b_0}{2n}}{
    \ainc{\octx}{n}}
  \and
  \infer[\jrule{$b_1$-I}]{\ainc{\octx \oc b_1}{2n+1}}{
    \ainc{\octx}{n}}
  \and
  \infer[\jrule{$i$-I}]{\ainc{\octx \oc i}{n+1}}{
    \ainc{\octx}{n}}
  \\
  \infer[\jrule{$\fuse_1$-I}]{\ainc{e \fuse b_1}{1}}{}
  \and
  \infer[\jrule{$\fuse_2$-I}]{\ainc{\octx \oc (i \fuse b_0)}{2(n+1)}}{
    \ainc{\octx}{n}}%
}%
%
\begin{inferences}
  \aincrules
\end{inferences}
Binary values should themselves be valid, terminal computational states, so the first three rules are carried over from the $\aval{}{}$ relation.
The $\jrule{$i$-I}$ rule allows multiple increment instructions to be interspersed throughout the state.
Lastly, because the atomicity of ordered rewriting steps is very fine-grained, the $\jrule{$\fuse_1$-I}$ and $\jrule{$\fuse_2$-I}$ rules are needed to completely describe the valid intermediate states and their denotations.
For instance, the state $e \oc i$ first rewrites to the intermediate $e \fuse b_1$ before eventually rewriting to $e \oc b_1$; the state $\octx \oc (i \fuse b_0)$ has a similar status.

With this $\ainc{}{}$ relation in hand, we can now prove a stronger, small-step adequacy theorem.
%
\newcommand{\smallincadequacytheorem}{%
\begin{theorem}[Small-step adequacy of increments]%
  \leavevmode
  \begin{thmdescription}
  \item[Value soundness]
    If $\aval{\octx}{n}$, then $\ainc{\octx}{n}$ and $\octx \nreduces$.
  \item[Preservation]
    If $\ainc{\octx}{n}$ and $\octx \reduces \octx'$, then $\ainc{\octx'}{n}$.
  \item[Progress]
    If $\ainc{\octx}{n}$, then either
    \begin{itemize*}[
      mode=unboxed, label=, afterlabel=,
      before=\unskip:\space,
      itemjoin=;\space, itemjoin*=; or\space%
    ]
    \item $\octx \reduces \octx'$ for some $\octx'$; or
    \item $\aval{\octx}{n}$.\fixnote{Compare with \enquote{If $\ainc{\octx}{n}$, then $\aval{\octx}{n}$ if, and only if, $\octx \nreduces$.}}
    \end{itemize*}
  \item[Termination]
    If $\ainc{\octx}{n}$, then every rewriting sequence from $\octx$ is finite.
  \end{thmdescription}
\end{theorem}%
}%
%
\smallincadequacytheorem
\begin{proof}
  Each part is proved separately.
  \begin{description}[
    parsep=0pt, listparindent=\parindent,
    labelsep=0.35em
  ]
  \item[Value soundness]
    can be proved by structural induction on the derivation of $\aval{\octx}{n}$.
  \item[Preservation and progress]
    can likewise be proved by structural induction on the derivation of $\ainc{\octx}{n}$.
    In particular, the $e \fuse b_1$ and $\octx \oc (i \fuse b_0)$ rules
  \item[Termination]
    can be proved using an explicit termination measure, $\card{\octx}$, that is strictly decreasing across each rewriting, $\octx \reduces \octx'$.
    Specifically, we use a measure (see the adjacent \lcnamecref{fig:ordered-rewriting:binary-counter:measure}),
    % For valid states $\octx$, we define a measure $\card{\octx}$ that is strictly decreasing across each rewriting $\octx \reduces \octx'$ (see the adjacent \lcnamecref{fig:ordered-rewriting:binary-counter:measure}).
    \begin{marginfigure}
      \begin{equation*}
        \begin{lgathered}[t]
          \card{e} = 0 \\
          \card{\octx \oc b_0} = \card{\octx} \\
          \card{\octx \oc b_1} = \card{\octx} + 2 \\
          \card{\octx \oc i} = \card{\octx} + 4
        \end{lgathered}
        \qquad
        \begin{lgathered}[t]
          \card{e \fuse b_1} = 3 \\
          \card{\octx \oc (i \fuse b_0)} = \card{\octx} + 5
        \end{lgathered}
      \end{equation*}
      \caption{A termination measure, adapted from the standard amortized work analysis of increment for binary counters}\label{fig:ordered-rewriting:binary-counter:measure}
    \end{marginfigure}%
    adapted from the standard amortized work analysis of increment for binary counters\autocite{??}, for which $\octx \reduces \octx'$ implies $\card{\octx} > \card{\octx'}$.
    % That is, if $\octx$ is a valid state and $\octx \reduces \octx'$, then $\card{\octx} > \card{\octx'}$.
    Because the measure is always nonnegative, only finitely many such rewritings can occur.

    As an example case, consider the intermediate state $\octx \oc b_0 \oc i$ and its rewriting $\octx \oc b_0 \oc i \reduces \octx \oc b_1$.
    It follows that $\card{\octx \oc b_0 \oc i} = \card{\octx} + 4 > \card{\octx} + 2 = \card{\octx \oc b_1}$.
  \qedhere
  \end{description}
\end{proof}

\begin{corollary}[Big-step adequacy of increments]
  \leavevmode
  \begin{thmdescription}
  \item[Evaluation]
    If $\ainc{\octx}{n}$, then $\octx \Reduces\aval{}{n}$.
    In particular, if $\aval{\octx}{n}$, then $\octx \oc i \Reduces\aval{}{n+1}$.
  \item[Preservation]
    If $\ainc{\octx}{n}$ and $\octx \Reduces \octx'$, then $\ainc{\octx'}{n}$.
    In particular, if $\aval{\octx}{n}$ and $\octx \oc i \Reduces\aval{}{n'}$, then $n' = n+1$.
  \end{thmdescription}
\end{corollary}
\begin{proof}
  The two parts are proved separately.
  \begin{description}[labelsep=0.35em]
  \item[Evaluation] can be proved by repeatedly appealing to the progress and preservation results\parencref{??}.
    By the accompanying termination result, a binary value must eventually be reached.
  \item[Preservation] can be proved by structural induction on the given rewriting sequence.
  %
  \qedhere
  \end{description}
\end{proof}

\newthought{But, of course}, a few isolated examples do not make a proof.



By analogy with functional programming, the above adequacy conditions can be seen as stating evaluation and termination results for a big-step, evaluation semantics of increments, with $\aval{\octx}{n}$ acting as a kind of typing judgment -- admittedly, a very precise one.

In functional programming, big-step results like these are usually proved by first providing a small-step operational semantics, then characterizing the valid intermediate states that arise with small steps, and finally establishing type preservation, progress, and termination results for the small-step semantics.
We will adopt the same proof strategy here.

In this case, the small-step operational semantics already exists -- it is simply the individual rewriting steps entailed by the definitions of $e$, $b_0$, and $b_1$.
So our first task is to characterize the valid intermediate states that arise during a computation.
To this end, we define a binary relation, $\ainc{}{}$, that, like the $\aval{}{}$ relation, serves the dual purposes of enumerating the valid intermediate states and assigning to each state a natural number denotation.%
\footnote{As with values, we could also choose to enumerate the valid immediate states more explicitly and syntactically with a grammar:
  \begin{equation*}
    \octx \Coloneqq e \mid \octx \oc b_0 \mid \octx \oc b_1 \mid \octx \oc i \mid e \fuse b_1 \mid \octx \oc (i \fuse b_0)
  \end{equation*}}
% To this end, we define a binary relation, $\ainc{}{}$, between computational states and the natural numbers that they represent;
\begin{inferences}
  \infer{\ainc{e}{0}}{}
  \and
  \infer{\ainc{\octx \oc b_0}{2n}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc b_1}{2n+1}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc i}{n+1}}{
    \ainc{\octx}{n}}
  \\
  \infer{\ainc{e \fuse b_1}{1}}{}
  \and
  \infer{\ainc{\octx \oc (i \fuse b_0)}{2(n+1)}}{
    \ainc{\octx}{n}}
\end{inferences}
Binary values should themselves be valid, terminal computational states, so the first three rules are carried over from the $\aval{}{}$ relation.
The fourth rule, involving $i$, allows multiple increments to be interspersed throughout the counter.

Because ordered rewriting steps are quite fine-grained, two final rules are needed to completely describe the valid intermediate states and their denotations.
For instance, the state $e \oc i$ first rewrites to $e \fuse b_1$ before eventually rewriting to $e \oc b_1$.



Having characterized the valid intermediate states, we may state and prove the small-step adequacy of increments: preservation, progress, and termination.
%
\begin{theorem}[Small-step adequacy of increments]%
  \leavevmode
  \begin{thmdescription}[nosep]
  \item[Value inclusion]
    If $\aval{\octx}{n}$, then $\ainc{\octx}{n}$.
  \item[Preservation]
    If $\ainc{\octx}{n}$ and $\octx \reduces \octx'$, then $\ainc{\octx'}{n}$.
  \item[Progress]
    If $\ainc{\octx}{n}$, then either
    \begin{itemize*}[
      mode=unboxed, label=, afterlabel=,
      before=\unskip:\space,
      itemjoin=;\space, itemjoin*=; or\space%
    ]
    \item $\octx \reduces \octx'$ for some $\octx'$; or
    \item $\octx \nreduces$ and $\aval{\octx}{n}$.
    \end{itemize*}
  \item[Termination]
    If $\ainc{\octx}{n}$, then every rewriting sequence from $\octx$ is finite.
  \end{thmdescription}
\end{theorem}
%
\begin{proof}
  Each part is proved separately.
  \begin{description}[
    parsep=0pt, listparindent=\parindent,
    labelsep=0.35em
  ]
  \item[Value inclusion]
    can be proved by structural induction on the derivation of $\aval{\octx}{n}$.
  \item[Preservation and progress]
    can likewise be proved by structural induction on the derivation of $\ainc{\octx}{n}$.
    In particular, the $e \fuse b_1$ and $\octx \oc (i \fuse b_0)$ rules
  \item[Termination]
    can be proved using an explicit termination measure, $\card{\octx}$, that is strictly decreasing across each rewriting, $\octx \reduces \octx'$.
    Specifically, we use a measure (see the adjacent \lcnamecref{fig:ordered-rewriting:binary-counter:measure}),
    % For valid states $\octx$, we define a measure $\card{\octx}$ that is strictly decreasing across each rewriting $\octx \reduces \octx'$ (see the adjacent \lcnamecref{fig:ordered-rewriting:binary-counter:measure}).
    \begin{marginfigure}
      \begin{equation*}
        \begin{lgathered}[t]
          \card{e} = 0 \\
          \card{\octx \oc b_0} = \card{\octx} \\
          \card{\octx \oc b_1} = \card{\octx} + 2 \\
          \card{\octx \oc i} = \card{\octx} + 4
        \end{lgathered}
        \qquad
        \begin{lgathered}[t]
          \card{e \fuse b_1} = 3 \\
          \card{\octx \oc (i \fuse b_0)} = \card{\octx} + 5
        \end{lgathered}
      \end{equation*}
      \caption{A termination measure, adapted from the standard amortized work analysis of increment for binary counters}\label{fig:ordered-rewriting:binary-counter:measure}
    \end{marginfigure}%
    adapted from the standard amortized work analysis of increment for binary counters\autocite{??}, for which $\octx \reduces \octx'$ implies $\card{\octx} > \card{\octx'}$.
    % That is, if $\octx$ is a valid state and $\octx \reduces \octx'$, then $\card{\octx} > \card{\octx'}$.
    Because the measure is always nonnegative, only finitely many such rewritings can occur.

    As an example case, consider the intermediate state $\octx \oc b_0 \oc i$ and its rewriting $\octx \oc b_0 \oc i \reduces \octx \oc b_1$.
    It follows that $\card{\octx \oc b_0 \oc i} = \card{\octx} + 4 > \card{\octx} + 2 = \card{\octx \oc b_1}$.
  \qedhere
  \end{description}
\end{proof}

\begin{theorem}[Big-step adequacy of increments]\leavevmode
  \begin{thmdescription}
  \item[Preservation]
    If $\ainc{\octx}{n}$ and $\octx \Reduces\aval{}{n'}$, then $n' = n$.
  \item[Termination?]
    If $\ainc{\octx}{n}$, then $\octx \Reduces\aval{}{n}$.
  \end{thmdescription}
\end{theorem}
\begin{proof}
  Both parts are consequences of the small-step adequacy of increments \parencref{??}.
  \begin{description}
  \item[Preservation]
    is proved by structural induction on the given rewriting sequence.
    The base case follows [...] by an inner structural induction on the derivation of $\aval{\octx}{n'}$.
    The inductive case can be proved by first appealing to small-step preservation \parencref{??} and then to the inductive hypothesis.
  \item[Termination?]
    is proved by repeatedly appealing to small-step progress \parencref{??}.
    The small-step termination [...] \parencref{??} ensures that a value will be reached after finitely many such appeals.
  %
  \qedhere
  \end{description}
\end{proof}

\begin{corollary}[Structural adequacy of increments]
  If $\aval{\octx}{n}$, then $\octx \oc i \Reduces\aval{}{n'}$ if, and only if, $n' = n+1$.
\end{corollary}



% For example, incrementing [a representation of] $1$ should result in [a representation of] $2$, as evidenced by a trace $e \oc b_1 \oc i \Reduces e \oc b_1 \oc b_0$.

% Given a binary number $\octx$ that represents $n$, we may append $i$ to form a computational state, $\octx \oc i$, that should compute a binary representation of $n+1$ and thereby increment the number.
% For example, incrementing [a representation of] $1$ should result in [a representation of] $2$, as evidenced by a trace $e \oc b_1 \oc i \Reduces e \oc b_1 \oc b_0$.

% Conversely, any computation

% To describe\fixnote{implement?} the increment operation using ordered rewriting, the previously uninterpreted atoms $e$, $b_0$, and $b_1$ are now given mutually recursive definitions that describe how they may be rewritten when $i$ is encountered.
% \begin{description}[font=\color{structure}]
% \item[$e \defd e \fuse b_1 \pmir i$]
%   To increment $e$, append $b_1$ as a most significant bit, resulting in $e \oc b_1$.
% \item[$b_0 \defd b_1 \pmir i$]
%   To increment a binary number that has $b_0$ as its least significant bit, simply flip that bit to $b_1$.
% \item[$b_1 \defd i \fuse b_0 \pmir i$]
%   To increment a binary number that has $b_1$ as its least significant bit, flip that bit to $b_0$ and carry the increment over to the more significant bits.
% \end{description}


As an example computation, consider incrementing $e \oc b_1$ twice, as captured by the state $e \oc b_1 \oc i \oc i$.
\begin{equation*}
  \begin{tikzcd}[
    cells={inner xsep=0.65ex,
           inner ysep=0.4ex},
    row sep=0em,
    column sep=scriptsize
  ]
    &[-0.2em]
    e \oc b_1 \oc b_0 \oc i
      \drar[reduces, start anchor=base east,
                     end anchor=west]
    &[-0.2em]
    \\
    e \oc b_1 \oc i \oc i \Reduces e \oc i \oc b_0 \oc i
      \urar[Reduces, start anchor=east,
                     end anchor=base west]
      \drar[reduces, start anchor=base east,
                     end anchor=west]
    &&
    e \oc b_1 \oc b_1
    \\
    &
    e \oc i \oc b_1
      \urar[Reduces, start anchor=east,
                     end anchor=base west]
    &
  \end{tikzcd}
\end{equation*}

First, processing of the leftmost increment begins: the least significant bit is flipped, and the increment is carried over to the more significant bits.
This corresponds to the reduction $e \oc b_1 \oc i \oc i \Reduces e \oc i \oc b_0 \oc i$.
Next, either of the two remaining increments may be processed -- that is, either $e \oc i \oc b_0 \oc i \Reduces e \oc b_1 \oc b_0 \oc i$ or $e \oc i \oc b_0 \oc i \Reduces e \oc i \oc b_1$.


% Conversely, any complete computation from $\octx \oc i$ must have as its result a binary rrepresentation of $n+1$.

% These two properties ensure that the atom $i$ adequately characterizes an increment operation:
% \begin{itemize}
% \item 
% \end{itemize}

% For this to be an adequate description of an increment operation, it should satisfy two desiderata:
% \begin{enumerate*}
% \item
% \end{enumerate*}
% Formally, these desiderata are captured by the following adequacy theorem:
% \begin{itemize}
% \item If $\aval{\octx}{n}$, then $\octx \oc i \Reduces\aval{}{n+1}$.
% \item If $\aval{\octx}{n}$, then $\octx \oc i \Reduces\aval{}{n'}$ implies $n' = n+1$.
% \end{itemize}

% By analogy with functional programming, ...

% Appending $i$ to a counter will initiate an increment, with ordered rewriting used to compute, step by step, a binary representation of the incremented value.



% \begin{itemize}
% \item
%   If counter $\octx$ represents $n$, then $\octx \oc i$ can compute a representation of $n+1$ and, conversely, any computation from $\octx \oc i$ results in a representation of $n+1$.
%   That is, if $\aval{\octx}{n}$, then $\octx \oc i \Reduces\aval{}{n'}$ if, and only if, $n' = n+1$.
% \end{itemize}

% \begin{equation*}
%   \octx \Coloneqq e \mid \octx \oc b_0 \mid \octx \oc b_1 \mid \octx \oc i
% \end{equation*}
% The binary counters

% If counter $\octx$ represents $n$, then $\octx \oc i$ should compute to a representation of $n+1$.
% If $\octx$ represents $n$ and $\octx \oc i$ can reduce to $n'$, then $n' = n+1$.
% \begin{itemize}
% \item 
% \end{itemize}

% The basic idea is to assign $e$, $b_0$, and $b_1$ recursive definitions that enable them to interact with these atoms $i$.

% The basic idea is to This atom is appended to a counter to initiate an increment 
% By appending this atom to a counter, This atom is appended to a counter
% ordered rewriting of 
% Because of these increments,
% To initiate an increment of a counter $\octx$, we simply append an uninterpreted atom $i$ to the counter; the atom $i$
% %
% % \begin{desiderata*}[Computational adequacy -- increments]\label{des:ordered-rewriting:increments}\leavevmode
%   \begin{itemize}[noitemsep]
%   \item If $\aval{\octx}{n}$ and $\octx \oc i \Reduces\aval{}{n'}$, then $n' = n+1$.
%   \item In addition, if $\aval{\octx}{n}$, then $\octx \oc i \Reduces\aval{}{n+1}$.
%   \end{itemize}
% % \end{desiderata*}



% Because of the new increment operation, the previously uninterpreted atoms $e$, $b_0$, and $b_1$ are now given mutually recursive definitions that describe how they may be rewritten when encountering $i$:
% % \begin{equation*}
% %   \begin{lgathered}
% %     e \defd e \fuse b_1 \pmir i \\
% %     b_0 \defd b_1 \pmir i \\
% %     b_1 \defd i \fuse b_0 \pmir i
% %   \end{lgathered}
% % \end{equation*}
% \begin{description}[font=\color{structure}]
% \item[$e \defd e \fuse b_1 \pmir i$]
%   To increment $e$, append $b_1$ as a most significant bit, resulting in $e \oc b_1$.
% \item[$b_0 \defd b_1 \pmir i$]
%   To increment a binary number that has $b_0$ as its least significant bit, simply flip that bit to $b_1$.
% \item[$b_1 \defd i \fuse b_0 \pmir i$]
%   To increment a binary number that has $b_1$ as its least significant bit, flip that bit to $b_0$ and carry the increment over to the more significant bits.
% \end{description}

% \begin{description}
% \item[$e \defd e \fuse b_1 \pmir i$]
%   To increment the counter $e$, which represents $0$, introduce $b_1$ as a new most significant bit, resulting in the counter $e \oc b_1$, which represents $1$.
%   That is, because $\aval{e}{0}$, there should exist a trace $e \oc i \Reduces \aval{e \oc b_1}{1}$.
%   % Having started at value $0$ (\ie, $\aval{e}{0}$), an increment results in value $1$ (\ie, $\aval{e \oc b_1}{1}$).
% \item[$b_0 \defd b_1 \pmir i$]
%   Because $\aval{\octx \oc b_0}{2n}$ when $\aval{\octx}{n}$, there should exist a trace $\octx \oc b_0 \oc i \Reduces \aval{\octx \oc b_1}{2n+1}$.
%   To increment a counter that ends with least significant bit $b_0$, simply flip that bit to $b_1$.
%   That is, $\octx \oc b_0 \oc i \reduces \octx \oc b_1$.
%   % Having started at value $2n$ (\ie, $\aval{\octx \oc b_0}{2n}$ with $\aval{\octx}{n}$), an increment results in value $2n+1$ (\ie, $\aval{\octx \oc b_1}{2n+1}$).
% \item[$b_1 \defd i \fuse b_0 \pmir i$]
%   Because $\aval{\octx \oc b_1}{2n+1}$ when $\aval{\octx}{n}$, there should exist a trace $\octx \oc b_1 \oc i \Reduces \aval{\octx' \oc b_0}{2n+2}$, provided that there exists a trace $\octx \oc i \Reduces \aval{\octx'}{n+1}$.
%   To increment a counter that ends with least significant bit $b_1$, flip that bit to $b_0$ and propagate the increment to the more significant bits as a carry.
%   That is, $\octx \oc b_1 \oc i \Reduces \octx \oc i \oc b_0$.
%   % Having started at value $2n+1$ (\ie, $\cval{\octx \oc b_1} = 2\cval{\octx}+1$), an increment results in value $2n+2 = 2(n+1)$ (\ie, $\cval{\octx \oc i \oc b_0} = 2\cval{\octx}+1$).
% \end{description}

% As an example computation, consider incrementing $e \oc b_1$ twice, as captured by the state $e \oc b_1 \oc i \oc i$.
% \begin{equation*}
%   \begin{tikzcd}[
%     cells={inner xsep=0.65ex,
%            inner ysep=0.4ex},
%     row sep=0em,
%     column sep=scriptsize
%   ]
%     &[-0.2em]
%     e \oc b_1 \oc b_0 \oc i
%       \drar[reduces, start anchor=base east,
%                      end anchor=west]
%     &[-0.2em]
%     \\
%     e \oc b_1 \oc i \oc i \Reduces e \oc i \oc b_0 \oc i
%       \urar[Reduces, start anchor=east,
%                      end anchor=base west]
%       \drar[reduces, start anchor=base east,
%                      end anchor=west]
%     &&
%     e \oc b_1 \oc b_1
%     \\
%     &
%     e \oc i \oc b_1
%       \urar[Reduces, start anchor=east,
%                      end anchor=base west]
%     &
%   \end{tikzcd}
% \end{equation*}

% First, processing of the leftmost increment begins: the least significant bit is flipped, and the increment is carried over to the more significant bits.
% This corresponds to the reduction $e \oc b_1 \oc i \oc i \Reduces e \oc i \oc b_0 \oc i$.
% Next, either of the two remaining increments may be processed -- that is, either $e \oc i \oc b_0 \oc i \Reduces e \oc b_1 \oc b_0 \oc i$ or $e \oc i \oc b_0 \oc i \Reduces e \oc i \oc b_1$.


We should like to prove the correctness of this specification of increments by establishing a computational adequacy result:
%
\begin{theorem}[Adequacy of increments]\label{thm:ordered-rewriting:binary-counter:inc-adequacy}
  If $\aval{\octx}{n}$ and $\octx \oc i \Reduces\aval{}{n'}$, then $n' = n+1$.
  Moreover, if $\aval{\octx}{n}$, then $\octx \oc i \Reduces\aval{}{n+1}$.
\end{theorem}
%
By analogy with functional programming, this \lcnamecref{thm:ordered-rewriting:binary-counter:inc-adequacy} can be seen as stating evaluation and termination results for a big-step evaluation semantics of increments --
the judgment $\aval{\octx}{n}$ is acting as a kind of typing judgment, with $n$ being the \enquote{type} [abstract interpretation?] of the counter $\octx$.

In functional programming, these sorts of big-step results are proved by first providing a small-step operational semantics, then characterizing the valid intermediate states that arise with small steps, and finally establishing type preservation, progress, and termination results for the small-step semantics.
We will adopt the same strategy here.

First, we define a relation, $\ainc{}{}$, that characterizes the valid intermediate states that arise during increments.

To prove this \lcnamecref{thm:ordered-rewriting:increments}, we will first introduce an auxiliary relation, $\ainc{}{}$, that characterizes the valid states that arise during increments.
This relation is defined inductively by the following rules.
%
\begin{inferences}
  \infer{\ainc{e}{0}}{}
  \and
  \infer{\ainc{\octx \oc b_0}{2n}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc b_1}{2n+1}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc i}{n+1}}{
    \ainc{\octx}{n}}
  \\
  \infer{\ainc{e \fuse b_1}{1}}{}
  \and
  \infer{\ainc{\octx \oc (i \fuse b_0)}{2(n+1)}}{
    \ainc{\octx}{n}}
\end{inferences}
The latter two

% \begin{lemma}[Value inclusion]
%   If $\aval{\octx}{n}$, then $\ainc{\octx}{n}$.
% \end{lemma}
% %
% \begin{proof}
%   By structural induction on the derivation of $\aval{\octx}{n}$.
% \end{proof}

% \begin{theorem}[Preservation]
%   If $\ainc{\octx}{n}$ and $\octx \reduces \octx'$, then $\ainc{\octx'}{n}$.
% \end{theorem}
% %
% \begin{proof}
%   By structural induction on the derivation of $\ainc{\octx}{n}$.
%   % We will show a representative cases.
%   % \begin{itemize}
%   % % \item Consider the case in which
%   % %   \begin{equation*}
%   % %     \octx
%   % %     =
%   % %     \infer{\ainc{\octx_0 \oc i}{n_0+1}}{
%   % %       \ainc{\octx_0}{n_0}}
%   % %     =
%   % %     n
%   % %   \end{equation*}
%   % %   and $\octx = \octx_0 \oc i \reduces \octx'_0 \oc i = \octx'$ because $\octx_0 \reduces \octx'_0$, for some $\octx_0$, $\octx'_0$, and $n_0$.
%   % %   By the inductive hypothesis, $\ainc{\octx'_0}{n_0}$.
%   % %   And so, $\octx' = \ainc{\octx'_0 \oc i}{n_0+1} = n$, as required.
%   % 
%   % % \item Consider the case in which
%   % %   \begin{equation*}
%   % %     \octx
%   % %     =
%   % %     \infer{\ainc{\octx_0 \oc b_1 \oc i}{(2n_0+1)+1}}{
%   % %       \infer{\ainc{\octx_0 \oc b_1}{2n_0+1}}{
%   % %         \ainc{\octx_0}{n_0}}}
%   % %     =
%   % %     n
%   % %   \end{equation*}
%   % %   and $\octx = \octx_0 \oc b_1 \oc i \reduces \octx_0 \oc (i \fuse b_0) = \octx'$, for some $\octx_0$ and $n_0$.
%   % %   It immediately follows that $\octx' = \ainc{\octx_0 \oc (i \fuse b_0)}{2(n_0+1)} = 2n_0+2 = n$, as required.
%   % 
%   % \item Consider the case in which
%   %   \begin{equation*}
%   %     \octx
%   %     =
%   %     \infer{\ainc{\octx_0 \oc (i \fuse b_0)}{2(n_0+1)}}{
%   %       \ainc{\octx_0}{n_0}}
%   %     =
%   %     n
%   %   \end{equation*}
%   %   and $\octx = \octx_0 \oc (i \fuse b_0) \reduces \octx_0 \oc i \oc b_0 = \octx'$, for some $\octx_0$ and $n_0$.
%   %   It immediately follows that
%   %   \begin{equation*}
%   %     \octx'
%   %     =
%   %     \infer{\ainc{\octx_0 \oc i \oc b_0}{2(n_0+1)}}{
%   %       \infer{\ainc{\octx_0 \oc i}{n_0+1}}{
%   %         \ainc{\octx_0}{n_0}}}
%   %     =
%   %     n
%   %     \,,
%   %   \end{equation*}
%   %   as required.
%   % \qedhere
%   % \end{itemize}
% \end{proof}


% \begin{theorem}[Progress]
%   If $\ainc{\octx}{n}$, then either $\octx \reduces \octx'$ or $\aval{\octx}{n}$.
% \end{theorem}
% %
% \begin{proof}
%   By structural induction on the derivation of $\ainc{\octx}{n}$.
%   % \begin{itemize}
%   % \item Consider the case in which
%   %   \begin{equation*}
%   %     \octx
%   %     =
%   %     \infer{\ainc{\octx_0 \oc i}{n_0+1}}{
%   %       \ainc{\octx_0}{n_0}}
%   %     =
%   %     n
%   %   \end{equation*}
%   %   for some $\octx_0$ and $n_0$.
%   % \end{itemize}
% \end{proof}

% Because rewriting is nondeterministic, we cannot take \enquote{$\ainc{\octx}{n}$ implies $\octx \Reduces\aval{}{n}$} as a statement of termination.

% \begin{theorem}[Termination]
%   If $\ainc{\octx}{n}$, then there is no infinite rewriting of $\octx$.
% \end{theorem}
% %
% \begin{proof}
%   For valid states $\octx$, we define a measure $\card{\octx}$ that is strictly decreasing across each rewriting $\octx \reduces \octx'$ (see the adjacent \lcnamecref{fig:ordered-rewriitting:binary-counter:measure}).
%   \begin{marginfigure}
%     \begin{equation*}
%       \begin{lgathered}
%         \card{e} = 0 \\
%         \card{\octx \oc b_0} = \card{\octx} \\
%         \card{\octx \oc b_1} = \card{\octx} + 2 \\
%         \card{\octx \oc i} = \card{\octx} + 4 \\
%         \card{e \fuse b_1} = 3 \\
%         \card{\octx \oc (i \fuse b_0)} = \card{\octx} + 5
%       \end{lgathered}
%     \end{equation*}
%   \end{marginfigure}%
%   That is, if $\octx$ is a valid state and $\octx \reduces \octx'$, then $\card{\octx} > \card{\octx'}$.
%   Because the measure is nonnegative, only finitely many such rewrittings can occour. 

%   As an example case, consider the valid state $\octx \oc b_0 \oc i$ and its rewritting  $\octx \oc b_0 \oc i \reduces \octx \oc b_1$.
%   It follows from the definition that $\card{\octx \oc b_0 \oc i} = \card{\octx} + 4 > \card{\octx} + 2 = \card{\octx \oc b_1}$.
% \end{proof}


% %
% \begin{proof}[Counterexample]
%   Small-step preservation does \emph{not} hold for $\ainc{}{}$.
%   As a specific counterexample, notice that $\ainc{\octx \oc b_1 \oc i}{2n+2}$ and $\octx \oc b_1 \oc i \reduces \octx \oc (i \fuse b_0)$, but $\ainc{\octx \oc (i \fuse b_0) \not}{2n+2}$.
%   Similarly, $\ainc{e \oc i}{1}$ and $e \oc i \reduces e \fuse b_1$, but $\ainc{e \fuse b_1 \not}{1}$.
% \end{proof}

% \begin{theorem}[Big-step preservation]
%   If $\ainc{\octx}{n}$ and $\octx \Reduces \ainc{\octx'}{n'}$, then $n = n'$.
% \end{theorem}


%  Consider the case in which $\octx = \octx_0 \oc b_1 \oc i \reduces \octx_0 \oc (i \fuse b_0) \Reduces \ainc{\octx'}{n'}$ and $n = 2n_0+2$ for some $\octx_0$ and $ n_0$ such that $\ainc{\octx_0}{n_0}$.
%     By inversion, $\octx_0 \oc i \oc b_0 \Reduces \ainc{\octx'}{n'}$.

% \begin{theorem}[Big-step evaluation]
%   If $\ainc{\octx}{n}$, then $\octx \Reduces \aval{\octx'}{n}$.
% \end{theorem}
% %
% \begin{proof}
%   By nested innduction, first on the natural number $n$ and then on the context $\octx$.
%   \begin{itemize}
%   \item Consider the case in which $\octx = \octx_0 \oc b_1 \oc i$ and $n = 2n_0+2$ for some $\octx_0$ and $ n_0$ such that $\ainc{\octx_0}{n_0}$.
%     By the inductive hypothesis, $\octx_0 \Reduces \aval{\octx'_0}{n_0}$, for some $\octx'_0$.
%     Notice that $\octx'_0 \oc b_1 \oc i \Reduces \octx'_0 \oc i \oc b_0$.
%     By the inductive hypothesis again, $\octx'_0 \oc i \Reduces \aval{\octx''_0}{n_0+1}$.
%     Framing $b_0$ on to the right, $\octx \Reduces \octx'_0 \oc b_1 \oc i \Reduces \octx'_0 \oc i \oc b_0 \Reduces \aval{\octx''_0 \oc b_0}{2(n_0+1)} = n$.

%   \item Consider the case in which $\octx = \octx_0 \oc b_0$ and $n = 2n_0$ for some $\octx_0$ and $n_0$ such that $\ainc{\octx_0}{n_0}$.
%     By the inductive hypothesis, $\octx_0 \Reduces \aval{\octx'_0}{n_0}$ for some $\octx'_0$.
%     Framing $b_0$ on to the right, $\octx = \octx_0 \oc b_0 \Reduces \aval{\octx'_0 \oc b_0}{2n_0} = n$.

%   \item Consider the case in which $\octx = e \oc i$ and $n = 1$.
%     It follows that $\octx = e \oc i \Reduces \aval{e \oc b_1}{1} = n$.
%   \end{itemize}
% \end{proof}

% \begin{theorem}[Big-step determinism]
%   If $\ainc{\octx}{n}$, then $\octx \Reduces \aval{\octx'}{n}$.
% \end{theorem}


% To correct this, there are two choices.
% First, we could introduce the following rules.
% \begin{inferences}
%   \infer{\ainc{e \fuse b_1}{1}}{}
%   \and
%   \infer{\ainc{\octx \oc (i \fuse b_0)}{2n+2}}{
%     \ainc{\octx}{n}}
% \end{inferences}
% Second, we could prove a big-step preservation result:
% \begin{theorem}[Big-step preservation]
%   If $\ainc{\octx}{n}$ and $\octx \Reduces \ainc{\octx'}{n'}$, then $n = n'$.
% \end{theorem}
% %
% \begin{proof}
%   \begin{itemize}
%   \item Consider the case in which $\octx = e \oc i$ and $n = 1$ and $e \fuse b_1 \Reduces\ainc{}{n'}$.
%     By inversion, $e \fuse b_1 \reduces \ainc{e \oc b_1}{1} = n'$.
%   \item Consider the case in which $\octx = \octx_0 \oc b_0 \oc i$ and $n = 2n_0+1$ and $\octx_0 \oc b_1 \Reduces\ainc{}{n'}$ for some $\octx_0$ and $n_0$ such that $\ainc{\octx_0}{n_0}$.
%     Notice that $\ainc{\octx_0 \oc b_1}{2n_0+1}$, and so $n' = 2n_0+1 = n$, by the inductive hypothesis.
%   \item Consider the case in which $\octx = \octx_0 \oc b_1 \oc i$ and $n = 2n_0+2$ and $\octx_0 \oc (i \fuse b_0) \Reduces\ainc{}{n'}$ for some $\octx_0$ and $n_0$ such that $\ainc{\octx_0}{n_0}$.
%     By [...], $\octx_0 \oc i \oc b_0 \Reduces\ainc{}{n'}$.
%     Notice that $\ainc{\octx_0 \oc i \oc b_0}{2(n_0+1)}$, and so $n' = 2(n_0+1) = n$, by the inductive hypothesis.
%   \item Consider the case in which $\octx = \octx_0 \oc i$ and $n = n_0+1$ and $\octx_0 \reduces \octx'_0$ and $\octx'_0 \oc i \Reduces\ainc{}{n'}$ for some $\octx_0$, $\octx'_0$, and $n_0$ such that $\ainc{\octx_0}{n_0}$.
%   \end{itemize}
% \end{proof}


% \begin{theorem}[Preservation and progress]\leavevmode
%   \begin{description}[nosep]
% %  \item[Unicity] If $\ainc{\octx}{n}$ and $\ainc{\octx}{n'}$, then $n = n'$.
% %  \item[Preservation] If $\ainc{\octx}{n}$ and $\octx \Reduces \octx'$, then $\ainc{\octx'}{n}$.
%   \item[Weak preservation] If $\ainc{\octx}{n}$ and $\octx \Reduces \ainc{\octx'}{n'}$, then $n = '$.
% %  \item[Progress] If $\ainc{\octx}{n}$, then either $\octx \reduces \octx'$ or $\aval{\octx}{n}$.
%   \item[Termination] If $\ainc{\octx}{n}$, then $\octx \Reduces\aval{}{n}$.
%   \end{description}
% \end{theorem}
% %
% \begin{proof}
%   \begin{description}
%   \item[Termination]
%     Assume that $\ainc{\octx}{n}$; we must show that $\octx \Reduces\aval{}{n}$.
%     \begin{itemize}
%     \item Consider the case in which $\octx = \octx_0 \oc b_0$ and $n = 2n_0$ for some $\octx_0$ and $n_0$ such that $\ainc{\octx_0}{n_0}$.
%       By the inductive hypothesis, $\octx_0 \Reduces\aval{}{n_0}$.
%       It follows that $\octx = \octx_0 \oc b_0 \Reduces\aval{}{2n_0} = n$.

%     \item The case in which $\octx = \octx_0 \oc b_1$ and $n = 2n_0+1$ for some $\octx_0$ and $n_0$ such that $\ainc{\octx_0}{n_0}$ is analogous.

%     \item Consider the case in which $\octx = \octx_0 \oc b_0 \oc i$ and $n = 2n_0+1$ for some $\octx_0$ and $n_0$ such that $\ainc{\octx_0}{n_0}$.
%       By the inductive hypothesis, $\octx_0 \Reduces \aval{\octx'_0}{n_0}$ for some $\octx'_0$.
%       It follows that $\octx_0 \oc b_0 \oc i \Reduces \octx'_0 \oc b_0 \oc i \reduces \octx'_0 \oc b_1$, and moreover, $\aval{\octx'_0 \oc b_1}{2n_0+1}$.
%       So, indeed, $\octx \Reduces \aval{}{2n_0+1}$.

%     \item
%     \end{itemize}
%   \end{description}
% \end{proof}

\paragraph{A decrement operation}
Binary counters
% \newthought{These binary counters}
may also be equipped with a decrement operation.
Instead of examining decrements \emph{per se}, we will implement a closely related operation: the normalization of binary representations to what might be called \vocab{head-unary form}.%
\footnote{We will frequently abuse terminology, using \enquote*{head-unary normalization} and \enquote*{decrement} interchangably.}
An ordered context $\octx$ will be said to be in head-unary form if it has one of two forms: $\octx = z$; or $\octx = \octx' \oc s$, for some binary number $\octx'$.

Just as appending the atom $i$ to a counter initiates an increment, appending an uninterpreted atom $d$ will cause the counter to begin normalizing to head-unary form.
The following \lcnamecref{thm:decrement-adequacy} serves as a specification of head-unary normalization, relating a value's head-unary form to its denotation.
%
\begin{theorem}[Structural adequacy of decrements]
  If $\aval{\octx}{n}$, then:
  \begin{itemize}[nosep]
  \item $\octx \oc d \Reduces z$ if, and only if, $n=0$;
  \item $\octx \oc d \Reduces \octx' \oc s$ for some $\octx'$ such that $\aval{\octx'}{n-1}$, if $n > 0$; and
  \item $\octx \oc d \Reduces \octx' \oc s$ only if $n > 0$ and $\aval{\octx'}{n-1}$.
  \end{itemize}
\end{theorem}
%
\noindent
For example, because $e \oc b_1$ denotes $1$, a computation $e \oc b_1 \oc d \Reduces \octx' \oc s$ must exist, for some $\aval{\octx'}{0}$.

\newthought{Once again}, to implement these desiderata locally, the recursive definitions of $e$, $b_0$, and $b_1$ will be revised with an additional clause that handles decrements;
also, a recursively defined proposition $b'_0$ is introduced:
% 
% Similarly to the use of the atom $i$ to describe 
% Similarly to the way $i$ initiates increments, a decrement is triggered by appending an [uninterpreted] atom $d$ to the counter;
% $d$ is then processed from right to left by the counter's individual bits.
% To support this, the definitions of $e$, $b_0$, and $b_1$ are revised with an addition clause each:
\begin{description}[font=\color{structure}]
\item[$e \defd (\dotsb \pmir i) \with (z \pmir d)$]
  Because $e$ denotes $0$, its head-unary form is simply $z$.
  % Because $e$ denotes $0$, it may be put into head-unary form by replacing it with $z$.
\item[$b_0 \defd (\dotsb \pmir i) \with (d \fuse b'_0 \pmir d)$]
  Because $\octx \oc b_0$ denotes $2n$ if $\octx$ denotes $n$, its head-unary form can be contructed by recursively putting the more significant bits into head-unary form and appending $b'_0$ to process that result.
  % To put $\octx \oc b_0$ into head-unary form, recursively put the more significant bits into head-unary form and append $b'_0$ to process that result.
\item[$b'_0 \defd (z \limp z) \with (s \limp b_1 \fuse s)$]
  If the more significant bits have head-unary form $z$ and therefore denote $0$, then $\octx \oc b_0$ also denotes $0$ and has head-unary form $z$.
  Otherwise, if they have head-unary form $\octx' \oc s$ and therefore denote $n > 0$, then $\octx \oc b_0$ denotes $2n$ and has head-unary form $\octx' \oc b_1 \oc s$, which can be constructed by replacing $s$ with $b_1 \oc s$.
  % If the more significant bits, $\octx$, have $z$ as their head-unary form, then so does $\octx \oc b_0$; otherwise, if their head-unary form ends with $s$, then
\item[$b_1 \defd (\dotsb \pmir i) \with (b_0 \fuse s \pmir d)$]
  Because $\octx \oc b_1$ denotes $2n+1$ if $\octx$ denotes $n$, its head-unary form, $\octx \oc b_0 \oc s$, can be constructed by flipping the least significant bit to $b_0$ and appending $s$.
  % To put $\octx \oc b_1$ into head-unary form, decrement the least significant bit to $b_0$ and append $s$.
\end{description}
%
Comfortingly, $2-1 = 1$: the head-unary form of $e \oc b_1$ is $e \oc b_0 \oc b_1 \oc s$:
\begin{equation*}
  e \oc b_1 \oc b_0 \oc d \Reduces e \oc b_1 \oc d \oc b'_0 \Reduces e \oc b_0 \oc s \oc b'_0 \Reduces e \oc b_0 \oc b_1 \oc s
  \,.
\end{equation*}


\newthought{At this point}, we would like to prove the adequacy of decrements.
However, having just revised the definitions of $e$, $b_0$, and $b_1$, we must first recheck the adequacy of binary representation\parencref[see]{??}.
%
Unfortunately, the newly introduced alternative conjunctions, together with the fine-grained atomicity of ordered rewriting, cause [...].
%
\begin{falseclaim}[Adequacy of binary representations]%
  \leavevmode
  \begin{thmdescription}
  \item[Functional]
    For every binary number $\octx$, there exists a unique natural number $n$ such that $\aval{\octx}{n}$.
  \item[Surjectivity]
    For every natural number $n$, there exists a binary number $\octx$ such that $\aval{\octx}{n}$.
  \item[Values]
    If $\aval{\octx}{n}$, then $\octx \nreduces$.
  \end{thmdescription}
\end{falseclaim}
\begin{proof}[Counterexample]
  Although the $\aval{}{}$ relation remains functional and surjective, it does not satisfy [...].
  Because $\aval{e}{0}$, the counter $e$ is a value (with denotation $0$).
  However, because the atomicity of ordered rewriting is extremely fine-grained, $e$ can be rewritten:
  \begin{equation*}
    \begin{tikzcd}[
      cells={inner xsep=0.65ex,
             inner ysep=0.4ex},
      row sep=0em,
      column sep=scriptsize,
      /tikz/column 2/.append style={anchor=west}
    ]
      &[-0.2em] e \mathrlap{{} \fuse b_1 \pmir i}
      \\
      e = (e \fuse b_1 \pmir i) \with (z \pmir d)
        \urar[reduces, start anchor=east]
        \drar[reduces, start anchor=base east]
      \\
      & z \mathrlap{{} \pmir d}
    \end{tikzcd}
    \hphantom{{} \fuse b_1 \pmir i}
  \end{equation*}
  That $e$ is an active proposition violates our conception of values as inactive.
\end{proof}

\newthought{At this point}, we would like to prove the adequacy of decrements.
However, having just revised the definitions of $e$, $b_0$, and $b_1$, we must first recheck the adequacy of increments.
%
Unfortunately, the newly introduced alternative conjunctions, together with the fine-grained atomicity of ordered rewriting, cause the preservation and progress properties to fail.
%
\begin{falseclaim}[Small-step adequacy of increments]%
  \leavevmode
  \begin{thmdescription}
  \item[Value inclusion]
    If $\aval{\octx}{n}$, then $\ainc{\octx}{n}$.
  \item[Preservation]
    If $\ainc{\octx}{n}$ and $\octx \reduces \octx'$, then $\ainc{\octx'}{n}$.
  \item[Progress]
    If $\ainc{\octx}{n}$, then either%
    \begin{itemize*}[
      mode=unboxed, label=, afterlabel=,
      before=\unskip:\space,
      itemjoin=;\space, itemjoin*=; or\space%
    ]  
    \item $\octx \reduces \octx'$ for some $\octx'$
    \item $\octx \nreduces$ and $\aval{\octx}{n}$
    \end{itemize*}
  \item[Termination]
    If $\ainc{\octx}{n}$, then every rewriting sequence from $\octx$ is finite.
  \end{thmdescription}
\end{falseclaim}
\begin{proof}[Counterexample]
  As a counterexample to preservation, notice that $e \oc i$ denotes $1$ and that
\begin{equation*}
  e \oc i = (e \fuse b_1 \pmir i) \with (z \pmir d)
    \reduces (e \fuse b_1 \pmir i) \oc i
  \,,
\end{equation*}
but that $(e \fuse b_1 \pmir i) \oc i$ does not have a denotation under the $\ainc{}{}$ relation.

  Even worse, computations can now enter stuck states -- $e \oc i \reduces (z \pmir d) \oc i \nreduces$, for example.
  It's difficult to imagine assigning denotations to these stuck states, making them counterexamples to preservation.
  Even if denotations were somehow assigned to them, such states would anyway violate the desired progress theorem.
\end{proof}

In both cases, these counterexamples arise from the very fine-grained atomicity of ordered rewriting.
Now that the definitions of $e$, $b_0$, and $b_1$ include alternative conjunctions, [...].

\begin{theorem}
  \begin{thmdescription}
  \item[Evaluation]
    If $\ainc{\octx}{n}$, then $\octx \Reduces\aval{}{n}$.
    In particular, if $\aval{\octx}{n}$, then $\octx \Reduces\aval{n+1}$.
  \item[Preservation]
    If $\ainc{\octx}{n}$ and $\octx \Reduces\aval{}{n'}$, then $n' = n$.
  \end{thmdescription}
\end{theorem}
\begin{proof}
  By structural induction on the given derivation of $\ainc{\octx}{n}$.
\end{proof}

The solution is to chain several small rewriting steps together into a single, larger atomic step. 


\section{Weakly focused rewriting}

\Textcite{Andreoli:??}'s observation was that propositions can be partitioned into two classes, or \vocab{polarities}\fixnote{reference?}, according to the invertibility of their sequent calculus rules, and that [...].



The ordered propositions are polarized into two classes, the positive and negative propositions, according to the invertibility of their sequent calculus rules.
\begin{syntax*}
  Positive props. &
    \p{A} & \p{\alpha} \mid \p{A} \fuse \p{B} \mid \one \mid \dn \n{A}
  \\
  Negative props. &
    \n{A} & \n{\alpha} \mid
    % \begin{array}[t]{@{{} \mid {}}l@{}}
              \p{A} \limp \n{B} \mid \n{B} \pmir \p{A} \mid % \\
              \n{A} \with \n{B} \mid \top \mid \up \p{A}
            % \end{array}
\end{syntax*}
The positive propositions are those propositions that have invertible left rules, such as ordered conjunction;
the negative propositions are those that have invertible right rules, such as the ordered implications.

\begin{syntax*}
  Ordered contexts &
    \octx & \octx_1 \oc \octx_2 \mid \octxe \mid \p{A}
\end{syntax*}

Left rules for negative connectives may be chained together into a single \vocab{left-focusing phase}, reflected by the pattern judgment $\lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}}$.
Following \textcite{Zeilberger:??}, this judgment can be read as a function of an in-focus negative proposition, $\n{A}$, that produces the ordered contexts $\octx_L$ and $\octx_R$ and the positive consequent $\p{C}$ as outputs.

The left-focus judgment is defined inductively on the structure of the in-focus proposition by the following rules.
\begin{inferences}
  \infer[\lrule{\limp}']{\lfocus{\octx_L \oc \p{A}}{\p{A} \limp \n{B}}{\octx_R}{\p{C}}}{
    \lfocus{\octx_L}{\n{B}}{\octx_R}{\p{C}}}
  \and
  \infer[\lrule{\pmir}']{\lfocus{\octx_L}{\n{B} \pmir \p{A}}{\p{A} \oc \octx_R}{\p{C}}}{
    \lfocus{\octx_L}{\n{B}}{\octx_R}{\p{C}}}
  \\
  \infer[\lrule{\with}_1]{\lfocus{\octx_L}{\n{A} \with \n{B}}{\octx_R}{\p{C}}}{
    \lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}}}
  \and
  \infer[\lrule{\with}_2]{\lfocus{\octx_L}{\n{A} \with \n{B}}{\octx_R}{\p{C}}}{
    \lfocus{\octx_L}{\n{B}}{\octx_R}{\p{C}}}
  \and
  \text{(no $\lrule{\top}$ rule)}
  \\
  \infer[\lrule{\up}]{\lfocus{}{\up \p{A}}{}{\p{A}}}{}
\end{inferences}
These rules parallel the usual sequent calculus rules, maintaining focus on the subformulas of negative polarity.
First, the $\lrule{\up}$ rule finishes a left-focusing phase by producing the consequent $\p{A}$ from $\up \p{A}$.

Second, the $\lrule{\limp}'$ and $\lrule{\pmir}'$ rules diverge slightly from the usual left rules for left- and right-handed implication in that they have no premises decomposing [the antecedent\fixnote{wc?}] $\p{A}$.
This would mean that a weakly focused sequent calculus based on $\lrule{\limp}'$ and $\lrule{\pmir}'$ would be incomplete for provability.
It is possible to [...]\autocite{Simmons:CMU??}.
However, because our goal here is a rewriting framework and such a framework is inherently incomplete\fixnote{Is this right?}, [...].


\begin{equation*}
  \infer[\jrule{$\dn$D}]{\octx_L \oc \dn \n{A} \oc \octx_R \reduces \p{C}}{
    \lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}}}
\end{equation*}

Consider the recursively defined proposition $\alpha \defd (\beta \limp \alpha) \with (\gamma \limp \one)$.
Previously, in the unfocused rewriting framework, it took two steps to rewrite $\beta \oc \alpha$ into $\alpha$:
\begin{equation*}
  \beta \oc \alpha = \beta \oc \bigl((\beta \limp \alpha) \with (\gamma \limp \one)\bigr)
    \reduces \beta \oc (\beta \limp \alpha)
    \reduces \alpha
\end{equation*}
Now, in the polarized, weakly focused rewriting framework, the analogous recursive definition is $\n{\alpha} \defd (\p{\beta} \limp \up \dn \n{\alpha}) \with (\p{\gamma} \limp \up \one)$, and it takes only one step to rewrite $\p{\beta} \oc \dn \n{\alpha}$ into $\dn \n{\alpha}$:
\begin{equation*}
  \p{\beta} \oc \dn \n{\alpha} = \p{\beta} \oc \dn \bigl((\p{\beta} \limp \up \dn \n{\alpha}) \with (\p{\gamma} \limp \up \one)\bigr)
    \reduces \dn \n{\alpha}
\end{equation*}
because $\lfocus{\p{\beta}}{\n{\alpha}}{}{\dn \n{\alpha}}$.

Notice that, because the left-focus judgment is defined inductively, there are some recursively defined negative propositions that cannot successfully be put in focus.
For example, under the definition $\n{\alpha} \defd \p{\beta} \limp \n{\alpha}$, there are no contexts $\octx_L$ and $\octx_R$ and conseqeunt $\p{C}$ for which $\lfocus{\octx_L}{\n{\alpha}}{\octx_R}{\p{C}}$ is derivable.

In addition to the $\jrule{$\dn$D}$ rule for decomposing $\dn \n{A}$, weakly focused ordered rewriting retains the $\jrule{$\fuse$D}$ and $\jrule{$\one$D}$ rules for decomposing $\p{A} \fuse \p{B}$ and $\one$ and the compatability rules, $\jrule{$\reduces$C}_{\jrule{L}}$ and $\jrule{$\reduces$C}_{\jrule{R}}$.
Together, these five rules and the left focus\fixnote{focal?} rules comprise the weakly focused ordered rewriting framework; they are summarized in \cref{??}.
%
\begin{figure}
  \begin{syntax*}
    Positive props. &
      \p{A} & \p{\alpha} \mid \p{A} \fuse \p{B} \mid \one \mid \dn \n{A}
    \\
    Negative props. &
      \n{A} & \n{\alpha} \mid
      % \begin{array}[t]{@{{} \mid {}}l@{}}
                \p{A} \limp \n{B} \mid \n{B} \pmir \p{A} \mid % \\
                \n{A} \with \n{B} \mid \top \mid \up \p{A}
              % \end{array}
    \\
    Ordered contexts &
      \octx & \octx_1 \oc \octx_2 \mid \octxe \mid \p{A}
  \end{syntax*}
  \begin{inferences}[Rewriting: $\octx \reduces \octx'$ and $\octx \Reduces \octx'$]
    \infer[\jrule{$\dn$D}]{\octx_L \oc \dn \n{A} \oc \octx_R \reduces \p{C}}{
      \lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}}}
    \and
    \infer[\jrule{$\fuse$D}]{\p{A} \fuse \p{B} \reduces \p{A} \oc \p{B}}{}
    \and
    \infer[\jrule{$\one$D}]{\one \reduces \octxe}{}
    \\
    \text{(no $\jrule{$\plus$D}$ and $\jrule{$\zero$D}$ rules)}
    \\
    \infer[\jrule{$\reduces$C}_{\jrule{L}}]{\octx_1 \oc \octx_2 \reduces \octx'_1 \oc \octx_2}{
      \octx_1 \reduces \octx'_1}
    \and
    \infer[\jrule{$\reduces$C}_{\jrule{R}}]{\octx_1 \oc \octx_2 \reduces \octx'_1 \oc \octx_2}{
      \octx_1 \reduces \octx'_1}
  \end{inferences}
  \begin{inferences}
    \infer[\jrule{$\Reduces$R}]{\octx \Reduces \octx}{}
    \and
    \infer[\jrule{$\Reduces$T}]{\octx \Reduces \octx''}{
      \octx \reduces \octx' & \octx' \Reduces \octx''}
  \end{inferences}

  \begin{inferences}[Left focus: $\lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}}$]
    \infer[\lrule{\limp}']{\lfocus{\octx_L}{\p{A} \limp \n{B}}{\octx_R}{\p{C}}}{
      \lfocus{\octx_L \oc \p{A}}{\n{B}}{\octx_R}{\p{C}}}
    \and
    \infer[\lrule{\pmir}']{\lfocus{\octx_L}{\n{B} \pmir \p{A}}{\octx_R}{\p{C}}}{
      \lfocus{\octx_L}{\n{B}}{\p{A} \oc \octx_R}{\p{C}}}
    \\
    \infer[\lrule{\with}_1]{\lfocus{\octx_L}{\n{A} \with \n{B}}{\octx_R}{\p{C}}}{
      \lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}}}
    \and
    \infer[\lrule{\with}_2]{\lfocus{\octx_L}{\n{A} \with \n{B}}{\octx_R}{\p{C}}}{
      \lfocus{\octx_L}{\n{B}}{\octx_R}{\p{C}}}
    \and
    \text{(no $\lrule{\top}$ rule)}
    \\
    \infer[\lrule{\up}]{\lfocus{}{\up \p{A}}{}{\p{A}}}{}
  \end{inferences}
  \caption{A weakly focused ordered rewriting framework}
\end{figure}

Weakly focused ordered rewriting is sound with respect to the unfocused rewriting framework of \cref{??}.
Given a depolarization function $\erase{}$ that maps polarized propositions and contexts to their unpolarized counterparts,%
\begin{marginfigure}
  \begin{equation*}
    \begin{aligned}[t]
      \erase{\octx_1 \oc \octx_2}
        &= \erase*{\octx_1} \oc \erase*{\octx_2} \\
      \erase{\octxe} &= \octxe \\
      \erase{\p{A}} &= \erase{\p{A}}
    \end{aligned}
    \qquad
    \begin{gathered}[t]
      \erase{\dn \n{A}} = \erase{\n{A}}
      \\
      \erase{\up \p{A}} = \erase{\p{A}}
      % \\
      % \erase{\p{A} \fuse \p{B}} &= \erase{\p{A}} \fuse \erase{\p{B}}
      \\
      \begin{array}{@{}l@{}}
        \erase{\p{A} \limp \n{B}} \\
        \quad{} = \erase{\p{A}} \limp \erase{\n{B}}
      \end{array}
      \\
      \rlap{\emph{etc.}}
    \end{gathered}
  \end{equation*}
  \caption{Depolarization of propositions and contexts}
\end{marginfigure}%
%
we may state and prove the following soundness theorem for weakly focused rewriting.
%
\begin{theorem}[Soundness of weakly focused rewriting]
  If $\octx \Reduces \octx'$, then $\erase*{\octx} \Reduces \erase{\octx'}$.
\end{theorem}
\begin{proof}
  By structural induction on the given rewriting step, after generalizing the inductive hypothesis to include:
  \begin{itemize}[nosep]
  \item If $\octx \reduces \octx'$, then $\erase*{\octx} \Reduces \erase{\octx'}$.
  \item If $\lfocus{\octx_L}{\n{A}}{\octx_R}{\p{C}}$, then $\erase{\octx_L \oc \dn \n{A} \oc \octx_R} \Reduces \erase{\p{C}}$.
  %
  \qedhere
  \end{itemize}
\end{proof}
%
\noindent
A completeness theorem also holds, but we forgo its development because it is not essential to the remainder of this work.

Second, with the lone exception negative propositions are latent\autocite{??} -- 

\section{Revisiting automata}

\begin{gather*}
  \dfa{q} \defd
    \parens[size=big]{\bigwith_{a \in \ialph}(a \limp \up \dn \dfa{q}'_a)}
    \with
    (\emp \limp \up \dfa{F}(q))
\shortintertext{where}
  q \dfareduces[a] q'_a
  \text{, for all $a \in \ialph$\quad and\quad}
  \dfa{F}(q) = \begin{cases*}
                 \one & if $q \in F$ \\
                 \dn \top & if $q \notin F$
               \end{cases*}
\end{gather*}

\begin{theorem}[\ac*{DFA} adequacy up to bisimilarity]
  \dfaadequacybisimbody
\end{theorem}

Lemma\cref{??} is still needed, but now has a much different proof.
Previously, the proof of \cref{??} relied on a very specific and delicate property of \acp{DFA}, namely that each \ac{DFA} state has one and only one $a$-successor for each input symbol $a$.
Now, with weakly focused ordered rewriting, the \lcnamecref{??}'s proof is much less fragile.
With the larger granularity of individual rewriting steps that the weakly focused framework affords, a state's encoding is a latent proposition 

\section{Revisiting binary counters}

With ordered rewriting now based on a weakly focused sequent calculus, we can revisit our previous attempt to extend binary counters with support for decrements or head-unary normalization.

The propositions $e$, $b_0$, $b'_0$, and $b_1$ are recursively defined in nearly the same way as before.
With one exception discussed below, only the necessary shifts are inserted to consistently assign a negative polarity to the defined atoms $e$, $b_0$, $b'_0$, and $b_1$ and a positive polarity to the uninterpreted atoms $i$, $d$, $z$, and $s$.
\begin{equation*}
  \begin{lgathered}
    e \defd (e \fuse b_1 \pmir i) \with (z \pmir d) \\
    b_0 \defd (\up \dn b_1 \pmir i) \with (d \fuse b'_0 \pmir d) \\
    b'_0 \defd (z \limp z) \with (s \limp b_1 \fuse s) \\
    b_1 \defd (i \fuse b_0 \pmir i) \with (b_0 \fuse s \pmir d)
  \end{lgathered}
\end{equation*}

\paragraph*{Values}
Once again, we use the same $\aval{}{}$ relation to assign a unique natural number denotation to each binary representation.
\begin{inferences}
  \ooavalrules
\end{inferences}
Because the underlying ordered rewriting framework has changed, we must verify that $\aval{}{}$ is adequate -- inparticular, the [...] property that values cannot be independently rewritten.
%
\ooavaltheorem
\begin{proof}
  By induction over the structure of $\octx$.
  As an example, consider the case in which $\aval{e}{0}$.
  Indeed, $e \nreduces$ because $e = (e \fuse b_1 \pmir i) \with (z \pmir d)$ and
  \begin{equation*}
    \lfocus{\octx_L}{(e \fuse b_1 \pmir i) \with (z \pmir d)}{\octx_R}{\p{C}}
    \text{\ only if $\octx_L = \octxe$ and either $\octx_R = i$ or $\octx_R = d$.}
  \end{equation*}
  The other cases are similar.
\end{proof}

\paragraph*{Increment}
Previously, under the unfocused rewriting framework\fixnote{wc?}, rewriting $e \oc i$ into $e \fuse b_1$ took two small steps:
\begin{equation*}
  e \oc i = \bigl((e \fuse b_1 \pmir i) \with (z \pmir d)\bigr) \oc i
    \reduces (e \fuse b_1 \pmir i) \oc i
    \reduces e \fuse b_1
\end{equation*}
But now, with weakly focused rewriting, those two steps are combined into one atomic whole: $e \oc i \reduces e \fuse b_1$.

As for the unfocused rewriting implementation of binary increments, we use a $\ainc{}{}$ relation to assign a natural number denotation to each computational state.
In fact, the specific definition of the $\ainc{}{}$ remains unchanged from \cref{??}: 
\begin{inferences}
  \aincrules
\end{inferences}

The only exception to [...] is the appearance of $\up \dn b_1$ in the definition of $b_0$.
Without this double shift, $e \oc b_0 \oc i$ would be latent, unable to rewrite to a value until a second increment is appended, because the necessary $\lfocus{}{(b_1 \pmir i) \with (d \fuse b'_0 \pmir d)}{i}{b_1}$ is not derivable.
However, with the double shift, $e \oc b_0 \oc i \reduces e \oc b_1$ because $\lfocus{}{(\up \dn b_1 \pmir i) \with (d \fuse b'_0 \pmir d)}{i}{\dn b_1}$ is derivable.


With weakly focused rewriting, it is no longer possible to reach the stuck state $...$.
\smallincadequacytheorem
\begin{proof}
  As before, each part is proved separately.
  \begin{description}[
    parsep=0pt, listparindent=\parindent,
    labelsep=0.35em
  ]
  \item[Value soundness, preservation, and progress]
    can be proved by structural induction on the derivation of $\ainc{\octx}{n}$.
  \item[Termination]
    can be proved using the same explicit termination measure, $\card{\octx}$, as in \cref{??}.
  %
  \qedhere
  \end{description}
\end{proof}


\paragraph*{Decrements}

\begin{inferences}
  \infer[\jrule{$d$-D}]{\adec{\octx \oc d}{n}}{
    \ainc{\octx}{n}}
  \and
  \infer[\jrule{$b'_0$-D}]{\adec{\octx \oc b'_0}{2n}}{
    \adec{\octx}{n}}
  \and
  \infer[\jrule{$z$-D}]{\adec{z}{0}}{}
  \and
  \infer[\jrule{$s$-D}]{\adec{\octx \oc s}{n+1}}{
    \ainc{\octx}{n}}
  \\
  \infer[\jrule{$\fuse_1$-D}]{\adec{\octx \oc (d \fuse b'_0)}{2n}}{
    \ainc{\octx}{n}}
  \\
  \infer[\jrule{$\fuse_2$-D}]{\adec{\octx \oc (b_0 \fuse s)}{2n+1}}{
    \ainc{\octx}{n}}
  \and
  \infer[\jrule{$\fuse_3$-D}]{\adec{\octx \oc (b_1 \fuse s)}{2n+2}}{
    \ainc{\octx}{n}}
\end{inferences}

\begin{theorem}[Small-step adequacy of decrements]
  \leavevmode
  \begin{thmdescription}
  \item[Preservation]
    If $\adec{\octx}{n}$ and $\octx \reduces \octx'$, then $\adec{\octx'}{n}$.
  \item[Progress]
    If $\adec{\octx}{n}$, then [either]:
    \begin{itemize}[nosep]
    \item $\octx \reduces \octx'$, for some $\octx'$;
    \item $n = 0$ and $\octx = z$; or
    \item $n > 0$ and $\octx = \octx' \oc s$, for some $\octx'$ such that $\ainc{\octx'}{n-1}$.
    \end{itemize}
  \item[Termination]
    If $\adec{\octx}{n}$, then every rewriting sequence from $\octx$ is finite.
  \end{thmdescription}
\end{theorem}
\begin{proof}
  \begin{description}
  \item[Preservation and progress]
    are proved, as before, by structural induction on the given derivation of $\adec{\octx}{n}$.
  \item[Termination] is proved by exhibiting a measure, $\card[d]{}$, that is strictly decreasing across each rewriting.
    Following the example of termination for increment-only binary counters\parencref{??}, we could try to assign a constant amount of potential to each of the counter's constituents.
    Leaving these potentials as unknowns, we can generate a set of constraints from the allowed rewritings and then attempt to solve them.

    For instance, here are several rewritings and their corresponding potential constraints.
    \begin{center}
      \begin{tabular}{@{}c@{\quad}c@{}}
        \emph{Some selected rewritings} & \emph{Potential constraints}
        \\
        $\octx \oc b_1 \oc i \reduces \octx \oc (i \fuse b_0) \reduces \octx \oc i \oc b_0$
        & $b_1 + i > i + b_0 + 1$
        \\
        $\octx \oc b_0 \oc d \reduces \octx \oc (d \fuse b'_0) \reduces \octx \oc d \oc b'_0$
        & $b_0 + d > d + b'_0 + 1$
        \\
        $\octx \oc s \oc b'_0 \reduces \octx \oc (b_1 \fuse s) \reduces \octx \oc b_1 \oc s$
        & $s + b'_0 > b_1 + s + 1$
        % \\
        % $\octx \oc b_1 \oc d \reduces \octx \oc (b_0 \fuse s) \reduces \octx \oc b_0 \oc s$
        % & $b_1 + d > b_0 + s + 1$
      \end{tabular}
    \end{center}
    These constraints are satisfiable only if $b_1 > b_0 > b'_0 > b_1$, which is, of course, impossible.

    However, notice that each $b_1$ that arises from an interaction between $s$ and $b'_0$ will never participate in further rewritings because any increments remaining to the left of $b_1$ will only involve more significant bits, not this less significant $b_1$.
    A similar argument can be made for all bits that occur between the rightmost $i$ and the terminal $s$, suggesting that those bits be assigned no potential at all.

    This leads to the termination measure, $\card[d]{}$, and its auxiliary measures, $\card[i]{}$ and $\card[s]{}$, shown in the adjacent \lcnamecref{??}.
    (Note that the measure $\card[i]{}$ is not the same as the measure used for increment-only binary counters\parencref{??}.)x




    is proved by exhibiting a pair of measures, $\card{\octx}_d$ and $\card{\octx}_s$, ordered lexicographically:
    \begin{itemize}
    \item If $\adec{\octx}{n}$ and $\octx \reduces \octx'$, then either:
      \begin{itemize*}[label=, afterlabel=]
      \item $\card{\octx}_d > \card{\octx'}_d$; or
      \item $\card{\octx}_d = 0$ and $\card{\octx}_s > \card{\octx'}_s$.
      % \item $\card{\octx} > \card{\octx'}$; or
      % \item $n = 0$ and $\octx' = z$; or
      % \item $n > 0$ and $\octx' = \octx'' \oc s$, for some $\octx''$ such that $\ainc{\octx''}{n-1}$.
      % \item $\octx = \octx_0 \oc (b_1 \fuse s) \reduces \octx_0 \oc b_1 \oc s = \octx'$.
      \end{itemize*}
    \end{itemize}
    These measures are shown in the adjacent \lcnamecref{??}, %
    \begin{marginfigure}
      \begin{equation*}
        \begin{lgathered}[t]
          \card{\octx \oc s}_s = \card{\octx} \\
          \card{e} = 0 \\
          \card{\octx \oc b_0} = \card{\octx} + 4 \\
          \card{\octx \oc b_1} = \card{\octx} + 6 \\
          \card{\octx \oc i} = \card{\octx} + 8 \\
          \card{e \fuse b_1} = 7 \\
          \card{\octx \oc (i \fuse b_0)} = \card{\octx} + 13
        \end{lgathered}
        \qquad
        \begin{lgathered}[t]
          \card{\octx \oc d}_d = \card{\octx} + 1 \\
          \card{\octx \oc b'_0}_d = \card{\octx}_d + 2 \\
          \card{z}_d = 0 \\
          \card{\octx \oc s}_d = 0 \\
          \card{\octx \oc (d \fuse b'_0)}_d = \card{\octx} + 4 \\
          \card{\octx \oc (b_0 \fuse s)}_d = 1 \\
          \card{\octx \oc (b_1 \fuse s)}_d = 1
        \end{lgathered}
      \end{equation*}
    \end{marginfigure}
    rely on an auxiliary measure, $\card{\octx}$, for increment states.
    Unfortunately, it is not possible to simply reuse the measure from \cref{??}.
    In that measure, each $b_0$ bit was assigned no potential.
    With decrements, however, $b_0$ needs to carry enough potential to transfer to $b'_0$ in case a decrement instruction is encountered.

    For the rewritings $\octx \oc b_1 \oc i \reduces \octx \oc (i \fuse b_0) \reduces \octx \oc i \oc b_0$, the assigned potentials must satisfy $b_1 + i > i + b_0 + 1$


    No 

        
    % e d --> z   1 > 0
    % b0 d --> d * b0' --> d b0'  4 > 3 > 2
    % b1 d --> b0 * s --> b0 s    6 > 1 > 0
    % z b0' --> z                 2 > 0
    % s b0' --> b1* s --> b1 s    2 > 1 > 0
    % e i --> e * b1 --> e b1     8 > 7 > 6
    % b0 i --> b1                 12 > 6
    % b1 i --> i * b0 --> i b0    14 > 13 > 12

    % e + i > e + b1 + 1  
    % b0 + i > b1
    % b1 + i > i + b0 + 1
    % e + d > z
    % b0 + d > d + b0' + 1
    % b1 + d > s + 1
    % z + b0' > z
    % s + b0' > s + 1

    % b1 d --> b0 * s --> b0 s      2 + d > 1 > 0
    % b0 d --> d * b'0 --> d b'0    b0 + d > d + 2 + 1 > d + 2
    % z b'0 --> z
    % s b'0 --> b1 * s --> b1 s

    As an example case, consider the intermediate state $\octx \oc (b_1 \fuse s)$ and its rewriting $\octx \oc (b_1 \fuse s) \reduces \octx \oc b_1 \oc s$.
    It follows $\card{\octx \oc (b_1 \fuse s)}_d = 1 > 0 = \card{\octx \oc b_1 \oc s}_d$.
    Any subsequent rewritings of $\octx$ are justified by a decrease in $\card{\octx \oc b_1 \oc s}_s > \card{\octx}$.
  \end{description}
\end{proof}

\begin{corollary}[Big-step adequacy of decrements]
  If $\adec{\octx}{n}$, then:
  \begin{itemize}[nosep]
  \item $\octx \Reduces z$ if, and only if, $n = 0$;
  \item $\octx \Reduces \octx' \oc s$ for some $\octx'$ such that $\ainc{\octx'}{n-1}$, if $n > 0$; and
  \item $\octx \Reduces \octx' \oc s$ only if $n > 0$ and $\ainc{\octx'}{n-1}$.
  \end{itemize}
\end{corollary}
\begin{proof}
  From the small-step preservation result of \cref{??}, it is possible to prove, using a structural induction on the given trace, a big-step preservation result: namely, that $\adec{\octx}{n}$ and $\octx \Reduces \octx'$ only if $\adec{\octx'}{n}$.
  Each of the above claims then follows from either progress and termination\parencref{??} or big-step preservation together with inversion.
\end{proof}

%   \begin{itemize}
%   \item
%     In the left-to-right direction, preservation yields $\adec{z}{n}$; by inversion, $n$ can only be $0$.
%     The right-to-left direction follows immediately from productivity.
%   \item
%     This second statement follows immediately from productivity.
%   \item
%     Preservation yields $\adec{\octx' \oc s}{n}$; by inversion, $n$ must be strictly positive with $\ainc{\octx'}{n-1}$.
%   \end{itemize}
% \end{proof}

    \begin{equation*}
      \begin{lgathered}[t]
        \card[d]{\octx \oc d} = \card[i]{\octx} + 1 \\
        \card[d]{\octx \oc b'_0} = \card[d]{\octx} + 2 \\
        \card[d]{z} = 0 \\
        \card[d]{\octx \oc s} = \card[s]{\octx}
        \\[\jot]
        \card[d]{\octx \oc (d \fuse b'_0)} = \card[d]{\octx \oc d \oc b'_0} + 1 \\
        \card[d]{\octx \oc (b_0 \fuse s)} = \card[d]{\octx \oc b_0 \oc s} + 1 \\
        \card[d]{\octx \oc (b_1 \fuse s)} = \card[d]{\octx \oc b_1 \oc s} + 1
      \end{lgathered}
      \qquad
      \begin{lgathered}[t]
        \card[i]{e} = 0 \\
        \card[i]{\octx \oc b_0} = \card[i]{\octx} + 4 \\
        \card[i]{\octx \oc b_1} = \card[i]{\octx} + 6 \\
        \card[i]{\octx \oc i} = \card[i]{\octx} + 8
        \\[\jot]
        \card[i]{e \fuse b_1} = \card[i]{e \oc b_1} + 1 \\
        \card[i]{\octx \oc (i \fuse b_0)} = \card[i]{\octx \oc i \oc b_0} + 1
      \end{lgathered}
      \qquad
      \begin{lgathered}[t]
        \card[s]{e} = \card[i]{e} = 0 \\
        \card[s]{\octx \oc b_0} = \card[s]{\octx} \\
        \card[s]{\octx \oc b_1} = \card[s]{\octx} \\
        \card[s]{\octx \oc i} = \card[i]{\octx \oc i} = \card[i]{\octx} + 8
        \\[\jot]
        \card[s]{e \fuse b_1} = \card[s]{e \oc b_1} + 1 \\
        \card[s]{\octx \oc (i \fuse b_0)} = \card[s]{\octx \oc i \oc b_0} + 1
      \end{lgathered}
    \end{equation*}

    \begin{itemize}
    \item If $\adec{\octx}{n}$ and $\octx \reduces \octx'$, then $\card[d]{\octx} > \card[d]{\octx'}$.
    \item If $\ainc{\octx}{n}$ and $\octx \reduces \octx'$, then $\card[i]{\octx} > \card[i]{\octx'}$ and $\card[s]{\octx} > \card[s]{\octx'}$.
    \end{itemize}

% b1 d --> b0 s  |-|i + 7 > |-|s + 1
% s b0' --> b1 s  |-|s + 2 > |-|s + 1


\section{Temporary}

% \begin{theorem}[Behavioral adequacy of decrements]
%   If $\adec{\octx}{n}$, then:
%   \begin{itemize}[nosep]
%   \item $\octx \Reduces z$ if, and only if, $n = 0$;
%   \item $\octx \Reduces \octx' \oc s$ for some $\octx'$ such that $\ainc{\octx'}{n-1}$, if $n > 0$;
%   \item $\octx \Reduces \octx' \oc s$ only if $n > 0$ and $\ainc{\octx'}{n-1}$.
%   \end{itemize}
% \end{theorem}

\begin{inferences}
  \infer{\adec{\octx \oc d}{n}}{
    \ainc{\octx}{n}}
  \and
  \infer{\adec{\octx \oc b'_0}{2n}}{
    \adec{\octx}{n}}
  \and
  \infer{\adec{z}{0}}{}
  \and
  \infer{\adec{\octx \oc s}{n+1}}{
    \ainc{\octx}{n}}
  \\
  \infer{\adec{\octx \oc (d \fuse b'_0)}{2n}}{
    \adec{\octx}{n}}
  \and
  \infer{\adec{\octx \oc (b_1 \fuse s)}{2n+2}}{
    \ainc{\octx}{n}}
  \and
  \infer{\adec{\octx \oc (b_0 \fuse s)}{2n+1}}{
    \ainc{\octx}{n}}
\end{inferences}
As the first rule exhibits, a binary number and its head-unary form denote the same value.
The last three rules are included by analogy with the $e \fuse b_1$ and $i \fuse b_0$ rules of the $\ainc{}{}$ relation.

\begin{falseclaim}[Small-step adequacy of decrements]\leavevmode
  \begin{thmdescription}
  \item[Preservation]
    If $\adec{\octx}{n}$ and $\octx \reduces \octx'$, then $\adec{\octx'}{n}$.
  \item[Progress]
    If $\adec{\octx}{n}$, then either:
    \begin{itemize}[nosep]
    \item $\octx \reduces \octx'$;
    \item $n = 0$ and $\octx = z$; or
    \item $n > 0$ and $\octx = \octx' \oc s$ for some $\octx'$ such that $\ainc{\octx'}{n-1}$.
    \end{itemize}
  \item[Productivity]
    If $\adec{\octx}{n}$, then every rewriting sequence from $\octx$ has a finite prefix $\octx \Reduces \octx'$ such that either:
    \begin{itemize}[nosep]
    \item $n = 0$ and $\octx' = z$; or
    \item $n > 0$ and $\octx' = \octx'_0 \oc s$, for some $\octx'_0$ such that $\ainc{\octx'_0}{n-1}$.
    \end{itemize}
  \end{thmdescription}
\end{falseclaim}
\begin{proof}
  The fine-grained atomicity of ordered rewriting, together with the use of alternative conjunction in the recursively defined propositions $e$, $b_0$, $b'_0$, and $b_1$, causes both preservation and progress properties to fail.

  As a counterexample to preservation, $\adec{e \oc d}{0}$ and $e \oc d \reduces (z \pmir d) \oc d$, but $\adec{(z \pmir d) \oc d}{0}$ does \emph{not} hold.

  Even worse, the fine-grained atomicity of ordered rewriting means that computations can enter stuck states, which shouldn't have denotations and which would violate progress if they were somehow assigned denotations.
  For example, $\adec{e \oc d}{0}$ and $e \oc d \reduces (e \fuse b_1 \pmir i) \oc d \nreduces$.

  $\ainc{e \oc i}{0}$ and $e \oc i \reduces (z \pmir d) \oc i \nreduces$
\end{proof}


\newthought{These binary counters} may also be equipped with a decrement operation.
Although \enquote{decrement} is a convenient name for this operation, it is more accurate to implement decrements by converting the binary representation to what might be called \emph{head-unary form}: an ordered context $\octx$ is said to be in head-unary form if either: $\octx = z$; or $\octx = \octx_0 \oc s$ for some binary representation $\octx_0$.

Similar to how the atom $i$ is used to describe increments, a decrement is initiated by appending an atom $d$ to the counter; $d$ is then processed from right to left by the counter's bits.
To support this, the definitions of $e$, $b_0$, and $b_1$ are revised
\begin{equation*}
  \begin{lgathered}
    e \defd (e \fuse b_1 \pmir i) \with (\dotsb \pmir d) \\
    b_0 \defd (b_1 \pmir i) \with (\dotsb \pmir d) \\
    b_1 \defd (i \fuse b_0 \pmir i) \with (\dotsb \pmir d)
  \end{lgathered}
\end{equation*}

To initiate a decrement of a counter $\octx$, we append the uninterpreted atom $d$ to the counter, forming $\octx \oc d$.

To implement the decrement operation, we instead

Although \enquote{decrement} is a convenient name for this operation, it is perhaps more accurate to think of this operation as putting the binary representation into a head-unary form: either $z$ or $\octx' \oc s$ for some $\ainc{\octx'}{n-1}$.
\begin{itemize}
\item If $\ainc{\octx}{n}$, then:
  \begin{itemize}
  \item $n = 0$ if, and only if, $\octx \oc d \Reduces z$; and
  \item $n > 0$ implies $\octx \oc d \Reduces \octx' \oc s$ for some $\octx'$ such that $\ainc{\octx'}{n-1}$; and
  \item $\octx \oc d \Reduces \octx' \oc s$ implies $n > 0$ and $\ainc{\octx'}{n-1}$.
  \end{itemize}
\end{itemize}

\begin{equation*}
  \begin{lgathered}
    e \defd (e \fuse b_1 \pmir i) \with (z \pmir d) \\
    b_0 \defd (b_1 \pmir i) \with (d \fuse b'_0 \pmir d) \\
    b'_0 \defd (z \limp z) \with (s \limp b_1\fuse s) \\
    b_1 \defd (i \fuse b_0 \pmir i) \with (b_0 \fuse s \pmir d)
  \end{lgathered}
\end{equation*}

\begin{description}
\item[$e \defd \dotsb \with (z \pmir d)$]
  Because the counter $e$ represents $0$, its head-unary form is simply $z$.
%
\item[$b_1 \defd \dotsb \with (b_0 \fuse s \pmir d)$]
  Because the counter $\octx \oc b_1$ represents $2n+1 > 0$ when $\octx$ represents $n$, its head-unary form must then be the successor of a counter representing $2n$ -- that is, $\octx \oc b_0 \oc s$.
%
\item[$b_0 \defd \dotsb \with (d \fuse b'_0 \pmir d)$]
  The natural number that the counter $\octx \oc b_0$ represents could be either zero or positive, depending on whether $\octx$ represents zero or a positive natural number.
  Thus, to put $\octx \oc b_0$ into head-unary form, we first put $\octx$ into head-unary form and then use $b'_0$ to branch on the result.
%
\item[$b'_0 \defd (z \limp z) \with (s \limp b_1 \fuse s)$]
  If the head-unary form of $\octx$ is $z$, then $\octx \oc b_0$ also represents $0$ and has head-unary form $z$.
  Otherwise, if the head-unary form of $\octx$ is $\octx' \oc s$ for some $\ainc{\octx'}{n'}$, then $\octx \oc b_0$ represents $2n'+2$ and has head-unary form $\octx' \oc b_1 \oc s$.
\end{description}

Decrements actually do not literally decrement the counter, but instead put it into a \enquote{head unary} form in which the couter is either $z$ or $s$ with a binary counter beneath.


We will use the same strategy for proving the adequacy of decrements as we did for increments:
Characterize the valid states
\begin{inferences}
  \infer{\adec{\octx \oc d}{n}}{
    \ainc{\octx}{n}}
  \and
  \infer{\adec{\octx \oc b'_0}{2n}}{
    \adec{\octx}{n}}
  \and
  \infer{\adec{z}{0}}{}
  \and
  \infer{\adec{\octx \oc s}{n+1}}{
    \ainc{\octx}{n}}
  \\
  \infer{\ainc{e \fuse b_1 \pmir i}{0}}{}
  \and
  \infer{\ainc{z \pmir d}{0}}{}
  \\
  \infer{\ainc{\octx \oc (b_1 \pmir i)}{2n}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc (d \fuse b'_0 \pmir d)}{2n}}{
    \ainc{\octx}{n}}
  \and
  \infer{\adec{\octx \oc (d \fuse b'_0)}{2n}}{
    \ainc{\octx}{n}}
  \\
  \infer{\ainc{\octx \oc (i \fuse b_0 \pmir i)}{2n+1}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc (b_0 \fuse s \pmir d)}{2n+1}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc (i \fuse b_0)}{2n+2}}{
    \ainc{\octx}{n}}
  \and
  \infer{\adec{\octx \oc (b_0 \fuse s)}{2n+1}}{
    \ainc{\octx}{n}}
  \\
  \infer{\adec{\octx \oc (z \limp z)}{2n}}{
    \adec{\octx}{n}}
  \and
  \infer{\adec{\octx \oc (s \limp b_1 \fuse s)}{2n}}{
    \adec{\octx}{n}}
  \and
  \infer{\adec{\octx \oc (b_1 \fuse s)}{2n+2}}{
    \ainc{\octx}{n}}
\end{inferences}

Notice that $\adec{e \oc s \oc b'_0}{0}$ but $e \oc s \oc b'_0 \Reduces \adec{e \oc b_1 \oc s}{1}$.
If we revise the $s$ rule to use $n+1$, then a different problem arises: $\adec{e \oc b_1 \oc d}{0}$ but $e \oc b_1 \oc d \Reduces \adec{e \oc b_0 \oc s}{1}$.

\begin{theorem}[Adequacy]
  If $\ainc{\octx}{n}$, then:
  \begin{itemize}[nosep]
  \item $n = 0$ if and only if $\octx \oc d \Reduces z$; and
  \item $n > 0$ implies $\octx \oc d \Reduces \octx' \oc s$ and $\ainc{\octx'}{n-1}$;
  \item $\octx \oc d \Reduces \octx' \oc s$ implies $n > 0$ and $\ainc{\octx'}{n-1}$.
  \end{itemize}
\end{theorem}
%
\begin{proof}
  
\end{proof}

\begin{theorem}[Small-step adequacy]\leavevmode
  \begin{description}[nosep, font=\emph]
  \item[Preservation] If $\adec{\octx}{n}$ and $\octx \reduces \octx'$, then $\adec{\octx'}{n}$.
  \item[Progress] If $\adec{\octx}{n}$, then either:
    \begin{itemize}[nosep]
    \item $\octx \reduces \octx'$;
    \item $n = 0$ and $\octx = z$; or
    \item $n = n'+1$ and $\octx = \octx' \oc s$ for some $n'$ and $\octx'$ such that $\ainc{\octx'}{n'}$.
    \end{itemize}
  \end{description}
\end{theorem}



\section{}

\begin{corollary}[Big-step adequacy of decrements]
  If $\adec{\octx}{n}$, then:
  \begin{itemize}
  \item $\octx \Reduces \atmR{z}$ if, and only if, $n = 0$;
  \item $\octx \Reduces \octx' \oc \atmR{s}$ for some $\octx'$ such that $\ainc{\octx'}{n-1}$, if $n > 0$; and
  \item $\octx \Reduces \octx' \oc \atmR{s}$ only if $n > 0$ and $\ainc{\octx'}{n-1}$.
  \end{itemize}
\end{corollary}




\section{}

\subsection{Automata}

\begin{enumerate}
\item
  Traces do not imply DFA transitions:
  \begin{equation*}
    \begin{lgathered}
      \dfa{q}_0 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \top) \\
      \dfa{q}_1 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{q}_1) \with (\emp \limp \one) \\
      \dfa{s}_1 \defd (a \limp \dfa{q}_0) \with (b \limp \dfa{s}_1) \with (\emp \limp \one)
    \end{lgathered}
  \end{equation*}
  \begin{marginfigure}
    \begin{equation*}
      \begin{tikzpicture}[baseline=(q_0.base)]
        \graph [automaton] {
          q_0
           -> [loop above, "a"]
          q_0
           -> ["b", bend left]
          q_1 [accepting]
           -> ["b", loop above]
          q_1
           -> ["a", bend left]
          q_0;
          s_1 [below=0.05 of q_1, accepting]
           -> [loop right, "b"]
          s_1
           -> ["a", bend left]
          q_0;
        };
      \end{tikzpicture}
    \end{equation*}
  \end{marginfigure}
  Notice that $b \oc \dfa{q}_0 \Reduces \dfa{q}_1 = \dfa{s}_1$ but $s_1$ is not reachable from $q_0$.
  ($\dfa{q}_1 = \dfa{s}_1$ is proved coinductively.)

\item
  NFA bisimilarity does not imply equality of encodings:
  \begin{equation*}
    \begin{lgathered}
      \nfa{q}_0 \defd (a \limp (\nfa{q}_0 \with \nfa{q}_1)) \with (\emp \limp \one) \\
      \nfa{q}_1 \defd (a \limp \nfa{q}_1) \with (\emp \limp \one)
    \end{lgathered}
  \end{equation*}
  \begin{marginfigure}
    \begin{equation*}
      \begin{tikzpicture}[baseline=(q_0.base)]
        \graph [automaton] {
          q_0 [accepting]
           -> [loop above, "a"]
          q_0
           -> ["a"]
          q_1 [accepting]
           -> ["a", loop above]
          q_1;
        };
      \end{tikzpicture}
    \end{equation*}
  \end{marginfigure}
  Notice that $q_0$ and $q_1$ are bisimilar, as witnessed by the reflexive closure of $\{(q_0,q_1)\}$.
  However, $\nfa{q}_0 \neq \nfa{q}_1$.

\item
  NFA similarity does not imply reduction.
  In the above example, NFA states $q_0$ and $q_1$ are bisimilar, andhence $q_1$ simulates $q_0$ (and vice versa).
  However, neither $\nfa{q}_0 \Reduces \nfa{q}_1$ nor $\nfa{q}_1 \Reduces \nfa{q}_0$ hold.

\item
  Even if an alternative, flatter encoding is used, NFA similarity does not imply reduction.
  Consider the following NFAs:
  \begin{align*}
   &\begin{lgathered}
      \nfa{q}_0 \defd (a \limp \nfa{q}_1) \with (\emp \limp \top) \\
      \nfa{q}_1 \defd (a \limp \nfa{q}_1) \with (a \limp \nfa{q}_2) \with (\emp \limp \one) \\
      \nfa{q}_2 \defd (a \limp \nfa{q}_2) \with (\emp \limp \one)
    \end{lgathered}
  \shortintertext{and}
   &\begin{lgathered}
      \nfa{s}_0 \defd (a \limp \nfa{s}_1) \with (\emp \limp \top) \\
      \nfa{s}_1 \defd (a \limp \nfa{s}_1) \with (\emp \limp \one)
    \end{lgathered}
  \end{align*}
  \begin{marginfigure}
    \begin{align*}
      \begin{tikzpicture}[baseline=(q_0.base)]
        \graph [automaton] {
          q_0
           -> ["a"]
          q_1 [accepting]
           -> [loop above, "a"]
          q_1
           -> ["a"]
          q_2 [accepting]
           -> ["a", loop above]
          q_2;
        };
      \end{tikzpicture}
      \\
      \begin{tikzpicture}[baseline=(s_0.base)]
        \graph [automaton] {
          s_0
           -> ["a"]
          s_1 [accepting]
           -> [loop above, "a"]
          s_1;
        };
      \end{tikzpicture}
    \end{align*}
  \end{marginfigure}
  As witnessed by the relation $\{(q_0,s_0), (q_1,s_1), (q_2,s_1)\}$, state $s_0$ simulates $q_0$.
  However, $\nfa{q}_0 \Longarrownot\Reduces \nfa{s}_0$.
  Essentially, similarity and reduction do not coincide because similarity is successor-congruent, whereas reduction is not $\limp$-congruent.

\item
  Focusing with eager inversion does not solve this problem.
  For DFAs, we would be able to prove:
  \begin{itemize}[nosep]
  \item $q$ and $s$ are bisimular if, and only if, $\dfa{q} = \dfa{s}$.
  \item $q \misa\dfareduces[a]\asim q'$ if, and only if, $a \oc \dfa{q} \reduces \dfa{q}'$.
  \end{itemize}

\item
  For NFAs, we will be able to prove:
  \begin{itemize}[nosep]
  \item $q$ and $s$ are bisimular if, and only if, $\nfa{q} \cong \nfa{s}$.
  \item $q \misa\nfareduces[a]\asim q'$ if, and only if, $a \oc \nfa{q} \cong^{-1}\reduces\cong \nfa{q}'$.
  \end{itemize}
\end{enumerate}


\subsection{Extended example: \Acp*{NFA}}

As an example of ordered rewriting, consider a specification of \acp{NFA}.
Recall from \cref{ch:automata} the \ac{NFA} (repeated in the adjacent \lcnamecref{fig:ordered-rewriting:nfa-example-ends-b})
%
\begin{marginfigure}
  \begin{equation*}
    \mathllap{\aut{A}_1 = {}}
    \begin{tikzpicture}[baseline=(q_0.base)]
      \graph [automaton] {
        q_0
         -> [loop above, "a,b"]
        q_0
         -> ["b"]
        q_1 [accepting]
         -> ["a,b"]
        q_2
         -> [loop above, "a,b"]
        q_2;
      };
    \end{tikzpicture}
  \end{equation*}
  \caption{\Iac*{NFA} that accepts, from state $q_0$, exactly those words that end with $b$. (Repeated from \cref{fig:nfa-example-ends-b}.)}\label{fig:ordered-rewriting:nfa-example-ends-b}
\end{marginfigure}%
%
that accepts exactly those words, over the alphabet $\ialph = \Set{a, b}$, that end with $b$.
We may represent that \ac{NFA} as a rewriting specification using a collection of recursive definitions, one for each of the \ac{NFA}'s states:%
\fixnote{Should I include ${} \with (\emp \limp \top)$?}
\begin{equation*}
  % \sig = \parens[size=auto]{
  \begin{lgathered}
    \nfa{q}_0 \defd (a \limp \nfa{q}_0) \with (b \limp (\nfa{q}_0 \with \nfa{q}_1)) \with (\emp \limp \top) \\
    \nfa{q}_1 \defd (a \limp \nfa{q}_2) \with (b \limp \nfa{q}_2) \with (\emp \limp \one) \\
    \nfa{q}_2 \defd (a \limp \nfa{q}_2) \with (b \limp \nfa{q}_2) \with (\emp \limp \top)
  \end{lgathered}
  % }
\end{equation*}
The \ac{NFA}'s acceptance of words is represented by the existence of traces.
For example, because the word $ab$ ends with $b$, a trace $\emp \oc b \oc a \oc \nfa{q}_0
% \Reduces \emp \oc b \oc \nfa{q}_0
% \Reduces \emp \oc \nfa{q}_1
\Reduces \octxe$ exists.
On the other hand, $\emp \oc a \oc b \oc \nfa{q}_0 \Longarrownot\Reduces \octxe$ because the word $ba$ does not end with $b$.

More generally, \iac{NFA} $\aut{A} = (Q, \mathord{\nfareduces}, F)$ over an input alphabet $\ialph$ can be represented as the ordered rewriting specification in which each state $q \in Q$ corresponds to a recursively defined proposition $\nfa{q}$:
\begin{equation*}
  \nfa{q} \defd
  \parens[size=auto]{\displaystyle
      \bigwith_{a \in \ialph}
        \parens[size=big]{a \limp \bigwith_{q'_a \in \nfapow(q,a)} \nfa{q}'_a}
    }
    \with
    \parens[size=big]{\emp \limp \nfa{F}(q)}
  \enspace\text{where\enspace
    $\nfa{F}(q) =
       \begin{cases*}
         \one & if $q \in F$ \\
         \top & if $q \notin F$\rlap{ .}
       \end{cases*}$}
\end{equation*}
After defining a representation, $\nfawds{w}$, of words $w$ (see adjacent \lcnamecref{fig:ordered-rewriting:words-represent})%
%
\begin{marginfigure}
  \begin{align*}
    \nfawds{\emp} &= \octxe \\
    \nfawds{a \wc w} &= \nfawds{w} \oc a
  \end{align*}
  \caption{Words as ordered contexts}\label{fig:ordered-rewriting:words-represent}
\end{marginfigure}%
%
, we may state and prove that ordered rewriting under these definitions is sound and complete with respect to the \ac{NFA} semantics given in \cref{ch:automata}.


\begin{theorem}
  \begin{itemize}
  \item $q \nfareduces[a] q'$ if, and only if, $a \oc \nfa{q} \Reduces \nfa{q}'$.
  \item $q \in F$ if, and only if, $\emp \oc \nfa{q} \Reduces \octxe$.
  \end{itemize}
\end{theorem}


\clearpage


\begin{falseclaim}
  Let $\aut{A} = (Q, \mathord{\nfareduces}, F)$ be \iac{NFA} over the input alphabet $\ialph$.
  Then:
  \begin{itemize}[nosep]
  \item $q \nfareduces[a]\asim s'$ if, and only if, $a \oc \nfa{q} \Reduces \nfa{s}'$.
  \item $q \asim s$ if, and only if, $\nfa{q} = \nfa{s}$.
  \end{itemize}
\end{falseclaim}
%
\begin{proof}[Counterexample]
  First, $q \asim s$ does not imply $\nfa{q} = \nfa{s}$.
  Consider the following \ac{NFA} and its corresponding definitions:
  \begin{equation*}
    \begin{tikzpicture}
      \graph [automaton] {
        q [accepting]
         -> ["a"]
        { s_1 [accepting] ->[loop right, "a" right] s_1 ,
          s_2 [accepting] ->[loop right, "a" right] s_2 };
      };
    \end{tikzpicture}
    \qquad
    \begin{lgathered}[b]
      \nfa{q} \defd (a \limp \nfa{s}_1) \with (a \limp \nfa{s}_2) \with (\emp \limp \one) \\
      \nfa{s}_1 \defd (a \limp \nfa{s}_1) \with (\emp \limp \one) \\
      \nfa{s}_2 \defd (a \limp \nfa{s}_2) \with (\emp \limp \one)
    \end{lgathered}
  \end{equation*}
  Observe that the universal binary relation on states is a bisimulation: every state has an $a$-successor and every state is an accepting state.
  Therefore, all pairs of states are bisimilar; in particular, $q \asim s_1$.
  However, $\nfa{q} \neq \nfa{s}_1$.

  Second, $a \oc \nfa{q} \Reduces \nfa{s}'$ does not imply $q \nfareduces[a]\asim s'$.
  Consider the following \ac{NFA} and its corresponding definitions:
  \begin{equation*}
    \begin{tikzpicture}
      \graph [automaton] {
        q_1 -> ["a"] q_2 [accepting]
         -> ["a"]
        { s_1 [accepting] ->[loop right, "a" right] s_1 ,
          s_2             ->[loop right, "a" right] s_2 };
      };
    \end{tikzpicture}
    \qquad
    \begin{lgathered}[b]
      \nfa{q}_1 \defd (a \limp \nfa{q}_2) \with (\emp \limp \top) \\
      \nfa{q}_2 \defd (a \limp \nfa{s}_1) \with (a \limp \nfa{s}_2) \with (\emp \limp \one) \\
      \nfa{s}_1 \defd (a \limp \nfa{s}_1) \with (\emp \limp \one) \\
      \nfa{s}_2 \defd (a \limp \nfa{s}_2) \with (\emp \limp \top)
    \end{lgathered}
  \end{equation*}
  Observe that $a \oc \nfa{q}_1 \Reduces \nfa{q}_2 \Reduces \nfa{s}_1$.
  However, $q_2 \nsim s_1$, and so $q_1 \nfareduces[a]\asim s_1$ does \emph{not} hold.
  To see why $q_2 \nsim s_1$, notice that $q_2 \nfareduces[a] s_2 \notin F$ is not matched from $s_1$, which has only $s_1 \nfareduces[a] s_1 \in F$.
\end{proof}


\begin{definition}
  A binary relation $\simu{R}$ on states is a simulation if:
  \begin{itemize}
  \item $s \simu{R}^{-1}\nfareduces[a] q'$ implies $s \nfareduces[a]\simu{R}^{-1} q'$; and
  \item $s \simu{R}^{-1} q \in F$ implies $s \in F$.
  \end{itemize}
  Similarity, $\lesssim$, is the largest simulation.
\end{definition}


\begin{lemma}
  If $\nfa{q} \secudeR \nfa{s}$, then $q \lesssim s$.
\end{lemma}
\begin{proof}
  We must check two properties:
  \begin{itemize}
  \item Suppose that $\nfa{s} \Reduces \nfa{q}$ and $q \nfareduces[a] q'_a$ for some state $q'_a$; we must show that $s \nfareduces[a] s'_a$ and $\nfa{s}'_a \secudeR \nfa{q}'_a$, for some state $s'_a$.
    According to the definition, the definiens of $\nfa{q}$ contains a clause $(a \limp \nfa{q}'_a)$.
    Because $\nfa{s} \Reduces \nfa{q}$, the definiens of $\nfa{s}$ also contains the clause $(a \limp \nfa{q}'_a)$.
    It follows that $s \nfareduces[a] q'_a$ and $\nfa{q}'_a \secudeR \nfa{q}'_a$.
  \item Suppose that $\nfa{s} \Reduces \nfa{q}$ and $q \in F$; we must show that $s \in F$.
    According to the definition, the definiens of $\nfa{q}$ contains a clause $(\emp \limp \one)$.
    Because $\nfa{s} \Reduces \nfa{q}$, the definiens of $\nfa{s}$ also contains the clause $(\emp \limp \one)$.
    It follows that $s \in F$.
  \qedhere
  \end{itemize}
\end{proof}


\begin{theorem}[Adequacy]
  Let $\aut{A} = (Q, \mathord{\nfareduces}, F)$ be \iac{NFA} over the input alphabet $\ialph$.
  If $q \nfareduces[a] q'$, then $a \oc \nfa{q} \Reduces \nfa{q}'$.
  Moreover, if $a \oc \nfa{q} \Reduces \nfa{s}'$, then $q \nfareduces[a]\gtrsim s'$.
\end{theorem}
%
\begin{proof}
  The first part follows by construction.

  To prove the second part, suppose $a \oc \nfa{q} \Reduces \nfa{s}'$.
  By the lemma, $\nfa{q} \Reduces (a \limp B) \oc \octx'_a$ and $B \oc \octx'_a \Reduces \nfa{s}'$ for some $B$ and $\octx'_a$.
  By inversion, $\octx'_a = \octxe$ and $B = \nfa{q}'_a$ for some state $q'_a$ such that $q \nfareduces[a] q'_a$.
  Therefore, $\nfa{q}'_a \Reduces \nfa{s}'$.
  By the lemma, $s' \lesssim q'_a$ and so $q \nfareduces[a]\gtrsim s'$.
\end{proof}


\begin{theorem}[Adequacy]
  Let $\aut{A} = (Q, \mathord{\nfareduces}, F)$ be \iac{NFA} over the input alphabet $\ialph$.
  Then:
  \begin{enumerate}
  \item If $q \nfareduces[a]\asim s'$, then $a \oc \nfa{q} \Reduces \nfa{s}'$.
  \item If $q \asim s$, then $\nfa{q} = \nfa{s}$.
  \item If $\nfa{q} = \nfa{s}$, then $q \asim s$.
  \item If $a \oc \nfa{q} \Reduces \nfa{s}'$, then $q \nfareduces[a]\asim s'$.
  \end{enumerate}
\end{theorem}
%
\begin{proof}
  \begin{enumerate}
  \item Suppose that $q \nfareduces[a] q' \asim s'$; we must show that $a \oc \nfa{q} \Reduces \nfa{s}'$.
    By construction, $a \oc \nfa{q} \Reduces \nfa{q}'$.
    It follows from part [...] that $\nfa{q}' = \nfa{s}'$, and so $a \oc \nfa{q} \Reduces \nfa{s}'$.

  \item Suppose $q \asim s$; we must show that $\nfa{q} = \nfa{s}$.
    \begin{itemize}
    \item Choose an arbitrary symbol $a \in \ialph$.
      If $q \nfareduces[a] q'_a$, then there exists \iac{NFA} state $s'_a$ such that $s \nfareduces[a] s'_a \misa q'_a$, and, by the coinductive hypothesis, $\nfa{q}'_a = \nfa{s}'_a$.
      Conversely, if $s \nfareduces[a] s'_a$, then there exists \iac{NFA} state $q'_a$ such that $q \nfareduces[a] q'_a$ and $\nfa{q}'_a = \nfa{s}'_a$.
    \item Also, $q$ is an accepting state if and only if $s$ is an accepting state.
    \end{itemize}
    Therefore, the definientia of $\nfa{q}$ and $\nfa{s}$ are equal, and, by the equirecursive interpretation of definitions, so are the definienda $\nfa{q}$ and $\nfa{s}$.

  \item Suppose that $\nfa{s} = \nfa{q}$ and $q \nfareduces[a] q'$; we must show that $s \nfareduces[a] s'$ and $\nfa{s}' = \nfa{q}'$, for some \ac{NFA} state $s'$.
    By its definition, the definiens of $\nfa{q}$ therefore contains the clause $(a \limp \nfa{q}')$.
    Because $\nfa{s} = \nfa{q}$, the definiens of $\nfa{s}$ must also contain a clause $(a \limp \nfa{s}')$ for some state $s'$ such that $s \nfareduces[a] s'$ and $\nfa{s}' = \nfa{q}'$.

    Symmetrically, if $\nfa{q} = \nfa{s}$ and $s \nfareduces[a] s'$, then $q \nfareduces[a] q'$ and $\nfa{q}' = \nfa{s}'$, for some state $q'$.

    
  \item Suppose $a \oc \nfa{q} \Reduces \nfa{q}'$.
    By the lemma, $a \oc \nfa{q} \Reduces (a \limp B) \oc \octx'_a$ and $B \oc \octx'_a \Reduces \nfa{q}'$ for some $B$ and $\octx'_a$.
    By inversion, $B = \nfa{q}'_a$ and $\octx'_a = \octxe$.
    Therefore, $\nfa{q}'_a \Reduces \nfa{q}'$.
    How to show that $q'_a \asim q'$?
  \end{enumerate}
\end{proof}
%
\begin{proof}
  By coinduction on $q \asim s$.
  \begin{itemize}
  \item Suppose $\nfa{s} = \nfa{q}$ and $q \nfareduces[a] q'$; we must show that $s \nfareduces[a] s'$ and $\nfa{s}' = \nfa{q}'$ for some \ac{NFA} state $s'$.
    It follows from the coinductive hypothesis that $a \oc \nfa{s} = a \oc \nfa{q} \Reduces \nfa{q}'$.
  \end{itemize}
\end{proof}
%
\begin{proof}
  In the left-to-right directions, by unrolling the definition of $\nfa{q}$ (and a structural induction on the word $w$).

  In the right-to-left directions, by structural induction on the given trace, using the following lemma:
  \begin{quotation}
    \normalsize
    If $a \oc \octx \Reduces \octx''$ and there is no $\octx''_0$ for which $\octx'' = a \oc \octx''_0$, then\\ $\octx \Reduces (a \limp B) \oc \octx'$ for some $B$ and $\octx'$ such that $B \oc \octx' \Reduces \octx''$.
  \end{quotation}

  Assume that $a \oc \nfa{q} \Reduces \nfa{q}'$.
  Using the above lemma, $\nfa{q} \Reduces (a \limp B) \oc \octx'$ for some $B$ and $\octx'$ such that $B \oc \octx' \Reduces \nfa{q}'$.
  By inversion on the trace from $\nfa{q}$, it must be that $B = \bigwith_{q'_a \in \nfapow(q,a)} \nfa{q}'_a$ and $\octx' = \octxe$.
  Further inversion on the trace from $B \oc \octx'$ establishes that $q' \in \nfapow(q,a)$ and hence $q \nfareduces[\smash{a}] q'$.
\end{proof}






\begin{equation*}
  \nfa{q} \defd
    \parens[size=auto]{\displaystyle
      \bigwith_{a \in \ialph}
        \parens[size=big]{a \limp \nfa{q}'_a \fuse \nfa{v}_a}
    }
    \with
    \parens[size=big]{\emp \limp \nfa{\sftterm}(q)}
    \enspace\text{where\enspace
      $q'_a = \sftnext(q,a)$ and
      $v_a = \sftout(q,a)$ and $v = \sftterm(q)$}
\end{equation*}


\subsection{Extended example: Binary representation of natural numbers}

As a second example, consider a rewriting specification of the binary representation of natural numbers with increment and decrement operations.

% \NewDocumentCommand \aval { m m } { #1 \approx_{\text{\normalfont\scshape v}} #2 }
% \NewDocumentCommand \ainc { m m } { #1 \approx_{\text{\normalfont\scshape i}} #2 }
% \NewDocumentCommand \adec { m m } { #1 \approx_{\text{\normalfont\scshape d}} #2 }

\NewDocumentCommand \cinc { m } { \mathbb{I}(#1) }
\NewDocumentCommand \cnat { m } { \cinc{#1} }
\NewDocumentCommand \cdec { m } { \mathbb{D}(#1) }

For this specification, a natural number is represented in binary by
% A binary representation of a natural number is
an ordered context consisting of a big-endian sequence of atoms $b_0$ and $b_1$, prefixed by the atom $e$; leading $b_0$s are permitted.
For example, both $\octx = e \oc b_1$ and $\octx = e \oc b_0 \oc b_1$ are valid binary representations of the natural number $1$.

More generally, let $\cval{}$ be the partial function from ordered contexts to natural numbers defined as follows; we say that the ordered context $\octx$ \emph{represents} natural number $n$ if $\cval{\octx} = n$.
\begin{equation*}
  \begin{lgathered}
    \cval{e} = 0 \\
    \cval{\octx \oc b_0} = 2\cval{\octx} \\
    \cval{\octx \oc b_1} = 2\cval{\octx} + 1
  \end{lgathered}
\end{equation*}
The partial function \(\cval{}\) defines an adequate representation because, up to leading $b_0$s, the natural numbers and valid binary representations (\ie, the domain of definition of $\cval{}$) are in bijective correspondence.
%
\begin{theorem}[Representational adequacy]
  For all natural numbers \(n \in \mathbb{N}\), there exists a context \(\octx\) such that \(\cval{\octx} = n\).
  Moreover, if \(\cval{\octx_1} = n\) and \(\cval{\octx_2} = n\), then \(\octx_1\) and \(\octx_2\) are identical up to leading \(b_0\)s.
\end{theorem}
\begin{proof}
  The first part follows by induction on the natural number \(n\); the second part follows by induction on the structure of the contexts \(\octx_1\) and \(\octx_2\).
\end{proof}

Next, we may describe an increment operation on these binary representations as an ordered rewriting specification; because of these increments, [...].
To indicate that an increment should be performed, a new, uninterpreted atom $i$ is introduced.
The previously uninterpreted atoms $e$, $b_0$, and $b_1$ are now given mutually recursive definitions that describe their interactions with $i$.
\begin{description}
\item[$e \defd e \fuse b_1 \pmir i$]
  To increment the counter $e$, introduce $b_1$ as a new most significant bit, resulting in the counter $e \oc b_1$.
  That is, $e \oc i \Reduces e \oc b_1$.
  Having started at value $0$ (\ie, $\cval{e} = 0$), an increment results in value $1$ (\ie, $\cval{e \oc b_1} = 1$).
\item[$b_0 \defd b_1 \pmir i$]
  To increment a counter that ends with least significant bit $b_0$, simply flip that bit to $b_1$.
  That is, $\octx \oc b_0 \oc i \Reduces \octx \oc b_1$.
  Having started at value $2n$ (\ie, $\cval{\octx \oc b_0} = 2\cval{\octx}$), an increment results in value $2n+1$ (\ie, $\cval{\octx \oc b_1} = 2\cval{\octx}+1$).
\item[$b_1 \defd i \fuse b_0 \pmir i$]
  To increment a counter that ends with least significant bit $b_1$, flip that bit to $b_0$ and propagate the increment on to the more significant bits as a carry.
  That is, $\octx \oc b_1 \oc i \Reduces \octx \oc i \oc b_0$.
  Having started at value $2n+1$ (\ie, $\cval{\octx \oc b_1} = 2\cval{\octx}+1$), an increment results in value $2n+2 = 2(n+1)$ (\ie, $\cval{\octx \oc i \oc b_0} = 2\cval{\octx}+1$).
\end{description}

As an example, consider incrementing $e \oc b_1$ twice, as captured by the state $e \oc b_1 \oc i \oc i$.
First, processing of the leftmost increment begins: the least significant bit is flipped, and the increment is carried over to the more significant bits.
This corresponds to the reduction $e \oc b_1 \oc i \oc i \Reduces e \oc i \oc b_0 \oc i$.
Next, either of the two remaining increments may be processed -- that is, either $e \oc i \oc b_0 \oc i \Reduces e \oc b_1 \oc b_0 \oc i$ or $e \oc i \oc b_0 \oc i \Reduces e \oc i \oc b_1$.

\begin{tikzcd}[]
  && e \oc b_1 \oc b_0 \oc i \drar[Reduces] &
  \\
  e \oc b_1 \oc i \oc i \rar[Reduces]
   & e \oc i \oc b_0 \oc i \urar[Reduces] \drar[Reduces] \arrow[Reduces, gray, dashed]{rr}
   && e \oc b_1 \oc b_1
  \\
   && e \oc i \oc b_1 \urar[Reduces] &
\end{tikzcd}

\begin{equation*}
  \begin{aligned}
  \MoveEqLeft[.5]
  e \oc b_1 \oc i \oc i \\
   &\Reduces e \oc i \oc b_0 \oc i \\
   &\Reduces e \oc b_1 \oc b_0 \oc i \\
   &\Reduces e \oc b_1 \oc b_1
\end{aligned}
\begin{aligned}
  \MoveEqLeft[.5]
  e \oc b_1 \oc i \oc i \\
   &\reduces e \oc (i \fuse b_0 \pmir i) \oc i \oc i
    \reduces e \oc (i \fuse b_0) \oc i
    \reduces e \oc i \oc b_0 \oc i \\
   &\reduces (e \fuse b_1 \pmir i) \oc i \oc b_0 \oc i
    \reduces (e \fuse b_1) \oc b_0 \oc i
    \reduces e \oc b_1 \oc b_0 \oc i \\
   &\reduces e \oc b_1 \oc (b_1 \pmir i) \oc i
    \reduces e \oc b_1 \oc b_1
\end{aligned}
\end{equation*}

% \begin{equation*}
%   \begin{lgathered}
%     e \defd e \fuse b_1 \pmir i \\
%     b_0 \defd b_1 \pmir i \\
%     b_1 \defd i \fuse b_0 \pmir i
%   \end{lgathered}
% \end{equation*}

% First representation, then computation.

% \begin{equation*}
%   \begin{lgathered}
%     e \defd (e \fuse b_1 \pmir i) \with (z \pmir d) \\
%     b_0 \defd (b_1 \pmir i) \with (d \fuse b'_0 \pmir d) \\
%     b_1 \defd (i \fuse b_0 \pmir i) \with (b_0 \fuse s \pmir d) \\
%     b'_0 \defd (z \limp z) \with (s \limp b_1 \fuse s)
%   \end{lgathered}
% \end{equation*}



% \begin{theorem}
%   % If $\cval{\octx} = n$, then $\octx \oc i \Reduces \octx'$ for some $\octx'$ such that $\cval{\octx'} = n+1$.
%   If $\cval{\octx} = n$ and $\octx \oc i \Reduces \octx'$, then $\octx' \Reduces \octx''$ for some $\octx''$ such that $\cval{\octx''} = n+1$.
% \end{theorem}

% \begin{equation*}
%   \begin{lgathered}
%     \cnat{e} = 0 \\
%     \cnat{\octx \oc b_0} = 2\cnat{\octx} \\
%     \cnat{\octx \oc b_1} = 2\cnat{\octx} + 1 \\
%     \cnat{\octx \oc i} = \cnat{\octx} + 1
%   \end{lgathered}
% \end{equation*}

% \begin{theorem}[Preservation]
%   If $\cnat{\octx} = n$ and $\octx \Reduces \octx'$, then $\cnat{\octx'} = n$.
% \end{theorem}

% \begin{theorem}[Progress]
%   If $\cnat{\octx} = n$, then either: $\octx \reduces \octx'$ for some $\octx'$; or $\cval{\octx} = n$.
% \end{theorem}

\clearpage

\begin{inferences}
  \infer{\aval{e}{0}}{}
  \and
  \infer{\aval{\octx \oc b_0}{2n}}{
    \aval{\octx}{n}}
  \and
  \infer{\aval{\octx \oc b_1}{2n+1}}{
    \aval{\octx}{n}}
\end{inferences}

\begin{theorem}[Adequacy]
  If \(\aval{\octx}{n}\) and \(\octx \oc i \Reduces \octx'\), then \(\octx' \Reduces \aval{}{n+1}\).
\end{theorem}
\begin{proof}
  \begin{itemize}
  \item Suppose that \(e \oc i \Reduces \octx'\); we must show that \(\octx' \Reduces \aval{}{1}\).
  \item Suppose that \(\octx \oc b_0 \oc i \Reduces \octx'\) and \(\aval{\octx}{n}\); we must show that \(\octx' \Reduces \aval{}{2n}\).
  \end{itemize}
\end{proof}


\begin{inferences}
  \infer{\ainc{\octx}{n}}{
    \aval{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc i}{n+1}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc b_0}{2n}}{
    \ainc{\octx}{n}}
  \and
  \infer{\ainc{\octx \oc b_1}{2n+1}}{
    \ainc{\octx}{n}}
  \\
  \infer{\ainc{\octx_L \oc A \oc \octx_R}{n}}{
    \ainc{\octx_L \oc \alpha \oc \octx_R}{n} & (\alpha \defd A) \in \sig}
\end{inferences}

\begin{theorem}[Preservation]
  If \(\ainc{\octx}{n}\) and \(\octx \reduces \octx'\), then \(\octx' \Reduces \ainc{}{n}\).
\end{theorem}
%
\begin{proof}
  \begin{itemize}
  \item Suppose that \(\ainc{\octx_0}{n}\) and \(\octx = \octx_0 \oc i \reduces \octx'\); we must show that \(\octx' \Reduces \ainc{}{n+1}\).
    \begin{itemize}
    \item Consider the case in which \(\octx_0 \reduces \octx'_0\) and \(\octx' = \octx'_0 \oc i\).
      By the inductive hypothesis, \(\octx'_0 \Reduces \ainc{}{n}\).
      From the increment rule, it follows that \(\octx' = \octx'_0 \oc i \Reduces \ainc{}{n+1}\).
    \item Consider the case in which \(\octx_0 = \octx_L \oc (A_0 \pmir i)\) and \(\ainc{\octx_L \oc \alpha}{n}\) and \(\octx' = \octx_L \oc A_0\) such that \((\alpha \defd A_0 \pmir i) \in \sig\).
      There are three subcases:
      \begin{itemize}
      \item Consider the subcase in which \(\alpha = b_0\) and \(n = 2n_0\) and \(\ainc{\octx_L}{n_0}\).
        By inversion on the signature, \(A_0 = b_1\).
        It follows that \(\octx' = \ainc{\octx_L \oc b_1}{2n_0+1} = n+1\).
      \item Consider the subcase in which \(\alpha = b_1\) and \(n = 2n_0+1\) and \(\ainc{\octx_L}{n_0}\).
        By inversion on the signature, \(A_0 = i \fuse b_0\).
        It follows that \(\octx' = \octx_L \oc (i \fuse b_0) \reduces \ainc{\octx_L \oc i \oc b_0}{2(n_0+1)} = n+1\).
      \item Consider the subcase in which \(\alpha = e\) and \(n = 0\) and \(\octx_L = \octxe\).
        By inversion on the signature, \(A_0 = e \fuse b_1\).
        It follows that \(\octx' = e \fuse b_1 \reduces \ainc{e \oc b_1}{1} = n+1\).
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{proof}

\begin{theorem}[Progress]
  If \(\ainc{\octx}{n}\), then either: \(\octx \reduces \octx'\) for some \(\octx'\); or \(\aval{\octx}{n}\).
\end{theorem}



% \begin{equation*}
%   \begin{lgathered}
%     \cdec{\octx \oc b'_0} = 2\cdec{\octx} \\
%     \cdec{\octx \oc d} = \cnat{\octx} \\
%     \cdec{\octx \oc s} = \cnat{\octx} + 1 \\
%     \cdec{z} = 0
%   \end{lgathered}
% \end{equation*}

% \begin{theorem}
%   If \(\cinc{\octx} = n\) and \(\octx \oc d \Reduces \octx'\), then: \(\octx' \Reduces z\) if \(n = 0\); and \(\octx' \Reduces \octx'' \oc s\) for some \(\octx''\) such that \(\cinc{\octx''} = n-1\), if \(n > 0\).
% \end{theorem}

% \(\cdec{\octx'} = n\) if, and only if, \(\octx \oc d \Reduces \octx'\) for some \(\octx\) such that \(\cinc{\octx} = n\).


\begin{inferences}
  \infer{\adec{z}{0}}{}
  \and
  \infer{\adec{\octx \oc s}{n+1}}{
    \ainc{\octx}{n}}
  \and
  \infer{\adec{\octx \oc d}{n}}{
    \ainc{\octx}{n}}
  \and
  \infer{\adec{\octx \oc b'_0}{2n}}{
    \adec{\octx}{n}}
  \\
  \infer{\adec{\octx_L \oc A \oc \octx_R}{n}}{
    \adec{\octx_L \oc \alpha \oc \octx_R}{n} & (\alpha \defd A) \in \sig}
\end{inferences}

\(\adec{\octx'}{n}\) if, and only if, \(\octx \oc d \Reduces \octx'\) for some \(\octx\) such that \(\ainc{\octx}{n}\).

% \begin{theorem}
%   If \(\cinc{\octx} = n\) and \(\octx \oc d \Reduces \octx'\), then:
%   \begin{itemize}[nosep]
%   \item \(n = 2n_0\) and \(\octx' = \octx'_0 \oc b'_0 \reduces \octx''\)
%     and \(\cinc{\octx_0} = n_0\) and \(\octx_0 \oc d \Reduces \octx'_0\);
%   \item \(\cinc{\octx'_0} = n\) and \(\octx' = \octx'_0 \oc d \reduces \octx''\);
%   \item \(n = 0\) and \(\octx' = z\); or
%   \item \(n > 0\) and \(\octx' = \octx'' \oc s\) for some \(\octx''\) such that \(\cinc{\octx''} = n-1\).
%   \end{itemize}
% \end{theorem}
% %
% \begin{proof}
%   \begin{itemize}
%   \item Suppose \(\octx = e\) and \(n = 0\) and \(e \oc d \Reduces \octx'\).
%     \begin{itemize}
%     \item If the reduction is trivial, then choose \(\octx'_0 = e\) and \(\octx'' = (z \pmir d) \oc d\).
%     \end{itemize}
%   \end{itemize}
% \end{proof}


\begin{theorem}[Preservation]
  If $\adec{\octx}{n}$ and $\octx \Reduces \octx'$, then $\adec{\octx'}{n}$.
\end{theorem}

% \begin{theorem}[Preservation]
%   If $\cdec{\octx} = n$ and $\octx \Reduces \octx'$, then $\cdec{\octx'} = n$.
% \end{theorem}

% \begin{theorem}[Progress]
%   If $\cdec{\octx} = n$, then either:
%   \begin{itemize}[nosep]
%   \item $\octx \reduces \octx'$ for some $\octx'$;
%   \item $\octx = \octx' \oc s$ and $n = n' + 1$ and $\cnat{\octx'} = n'$ for some $\octx'$ and $n'$; or
%   \item $\octx = z$ and $n = 0$.
%   \end{itemize}
% \end{theorem}

\begin{theorem}[Progress]
  If $\adec{\octx}{n}$, then either:
  \begin{itemize}[nosep]
  \item $\octx \reduces \octx'$ for some $\octx'$;
  \item $\octx = \octx' \oc s$ and $n = n' + 1$ and $\ainc{\octx'}{n'}$ for some $\octx'$ and $n'$; or
  \item $\octx = z$ and $n = 0$.
  \end{itemize}
\end{theorem}


% \section{Propositional ordered rewriting}

% In this \lcnamecref{sec:ordered-rewriting:general}, we develop a rewriting interpretation of the ordered sequent calculus from the previous \lcnamecref{ch:ordered-logic}.
% This development closely follows \citeauthor{Cervesato+Scedrov:IC09}'s work on intuitionistic linear logic as a multiset rewriting framework.\autocite{Cervesato+Scedrov:IC09}

% Just as their linear logical rewriting framework is more expressive than multiset rewriting, ordered rewriting framework presented in this chapter can be seen as an extension of traditional notions of string rewriting.


% \begin{equation*}
%   \infer*{\oseq{\octx |- A}}{
%     \oseq{\octx' |- A'}}
% \end{equation*}


% Many of the ordered sequent calculus's left rules consist of a single major premise with the same consequent as in the rule's conclusion [sequent], as well as a minor premise in the case of the $\lrule{\limp}$ and $\lrule{\pmir}$ rules.
% \begin{inferences}
%   \infer[\lrule{\fuse}]{\oseq{\octx'_L \oc (A \fuse B) \oc \octx'_R |- C}}{
%     \oseq{\octx'_L \oc A \oc B \oc \octx'_R |- C}}
%   \and
%   \infer[\lrule{\with}_1]{\oseq{\octx'_L \oc (A \with B) \oc \octx'_R |- C}}{
%     \oseq{\octx'_L \oc A \oc \octx'_R |- C}}
% \end{inferences}
% Both rules, at their core, decompose resources -- the resource $A \fuse B$ into the separate resources $A \oc B$; and the resource $A \with B$ into the resource $A$.
% The resource decomposition is somewhat obscured 
% Notice that much of these two rules is devoted to shared scaffolding/boilerplate -- the framing contexts $\octx'_L$ and $\octx'_R$, and goal consequent $C$ that remain unchanged from conclusion to premise.

% Because so many rules share this scaffolding, it might be worthwhile to restructure the ordered sequent calculus to expose this shared scaffolding.
% \begin{equation*}
%   \infer{\oseq{\octx |- C}}{
%     \octx \reduces \octx' & \oseq{\octx' |- C}}
% \end{equation*}
% For instance, if $\octx_L \oc (A \fuse B) \oc \octx_R \reduces \octx_L \oc A \oc B \oc \octx_R$ holds, then the usual $\lrule{\fuse}$ rule is a derivable instance of this generalized left rule.


% \begin{theorem}
%   $\oseq{\octx |- A}$ in ... if and only if $\oseq{\octx |- A}$ in ...
% \end{theorem}
% \begin{proof}
%   The two directions are proved separately, each by induction on the structure of the given derivation.
%   \begin{gather*}
%     \infer[\lrule{\with}_1]{\oseq{\octx'_L \oc (A \with B) \oc \octx'_R |- C}}{
%       \oseq{\octx'_L \oc A \oc \octx'_R |- C}}
%     \\\rightsquigarrow\\
%     \infer[]{\oseq{\octx'_L \oc (A \with B) \oc \octx'_R |- C}}{
%       \infer[]{\octx'_L \oc (A \with B) \oc \octx'_R \reduces \octx'_L \oc A \oc \octx'_R}{
%         \infer[]{(A \with B) \oc \octx'_R \reduces A \oc \octx'_R}{
%         \infer[\lrule{\with}'_1]{A \with B \reduces A}{}}} &
%       \oseq{\octx'_L \oc A \oc \octx'_R |- C}}
%   \end{gather*}

%   \begin{equation*}
%     \begin{lgathered}
%       \bigfuse (\octx_1 \oc \octx_2) = (\bigfuse \octx_1) \fuse (\bigfuse \octx_2) \\
%       \bigfuse (\octxe) = \one \\
%       \bigfuse A = A
%     \end{lgathered}
%   \end{equation*}

%   \begin{lemma}
%     If\/ $\octx \reduces \octx'$, then $\oseq{\octx |- \bigfuse \octx'}$.
%     $\oseq{\octx' |- \bigfuse \octx'}$ for all $\octx'$.
%   \end{lemma}
% \end{proof}

% \begin{theorem}
%   If $\oseq{\octx |- A}$ and $\octx'_L \oc A \oc \octx'_R \reduces \octx'$, then $\oseq{\octx'_L \oc \octx \oc \octx'_R |- \bigfuse \octx'}$.
% \end{theorem}

% \begin{syntax*}
%   Propositions &
%     A & p \mid A \limp B \mid B \pmir A
%           \mid A \fuse B \mid \one
%           \mid A \with B \mid \top
%   \\
%   Ordered contexts & 
%     \octx & \octxe \mid \octx_1 \oc \octx_2 \mid A
% \end{syntax*}

% \begin{itemize}
% \item Lambek calculus and rewriting; compare to multiset rewriting; compare to string rewriting
% \item Explain why $\plus$ and $\zero$ (and $\bot$) are undesirable here.
% \item Connections to left rules
% \end{itemize}

% The rewriting relation is the smallest compatible relation that satisfies:
% \begin{inferences}
%   \infer{A \oc (A \limp B) \reduces B}{}
%   \and
%   \infer{(B \pmir A) \oc A \reduces B}{}
%   \\
%   \infer{A \with B \reduces A}{}
%   \and
%   \infer{A \with B \reduces B}{}
%   \and
%   \text{(no rule for $\top$)}
%   \\
%   \infer{A \fuse B \reduces A \oc B}{}
%   \and
%   \infer{\one \reduces \octxe}{}
% \end{inferences}
% We will also refer to this relation as \vocab{reduction}%
% \footnote{Input transitions are postponed to \cref{ch:ordered-bisimilarity}.}%
% .

% $\Reduces$ is the reflexive-transitive closure of $\reduces$


% \begin{equation*}
%   \infer[\lrule{\with}_1]{\oseq{\octx'_L \oc (A \with B) \oc \octx'_R |- \gamma}}{
%     \oseq{\octx'_L \oc A \oc \octx'_R |- \gamma}}
%   \leftrightsquigarrow
%   \infer{\octx'_L \oc (A \with B) \oc \octx'_R \reduces \octx'_L \oc A \oc \octx'_R}{
%     \infer{A \with B \reduces A}{}}
% \end{equation*}

% \begin{equation*}
%   \infer[\lrule{\limp}]{\oseq{\octx'_L \oc \octx \oc (A \limp B) \oc \octx'_R |- \gamma}}{
%     \oseq{\octx |- A} & \oseq{\octx'_L \oc B \oc \octx'_R |- \gamma}}
%   \rightsquigarrow
%   \infer[\lrule{\limp}']{\oseq{\octx'_L \oc A \oc (A \limp B) \oc \octx'_R |- \gamma}}{
%     \oseq{\octx'_L \oc B \oc \octx'_R |- \gamma}}
%   \leftrightsquigarrow
%   \infer{\octx'_L \oc A \oc (A \limp B) \oc \octx'_R \reduces \octx'_L \oc B \oc \octx'_R}{
%     \infer{A \oc (A \limp B) \reduces B}{}}
% \end{equation*}


% \subsection{Definitions}

% \begin{itemize}
% \item not very interesting without recursion
% \end{itemize}

\subsection{Examples}

% \paragraph*{Automata and transducers}

% \begin{equation*}
%   \begin{lgathered}[t]
%     q_0 \defd (a \limp q_0) \with (b \limp q_0 \with q_1) \\
%     q_1 \defd (a \limp q_2) \with (b \limp q_2) \with (\emp \limp \one) \\
%     q_2 \defd (a \limp q_2) \with (b \limp q_2)
%   \end{lgathered}
%   \qquad
%   \begin{lgathered}[t]
%     s_0 \defd (a \limp s_0) \with (b \limp s_1) \\
%     s_1 \defd (a \limp s_0) \with (b \limp s_1) \with (\emp \limp \one)
%   \end{lgathered}
% \end{equation*}

% \begin{equation*}
%   \nfa{q} \defd \bigwith_{a \in \ialph} \bigl({\textstyle a \limp \bigwith_{q'_a} \nfa{q}'_a}\bigr)
% \end{equation*}

% \begin{theorem}
%   Let $\aut{A} = (Q, \mathord{\nfareduces}, F)$ be \iac{NFA} over an input alphabet $\ialph$.
%   Then:
%   \begin{itemize}[nosep]
%   \item $q \nfareduces[a] q'$ if and only if $\atm{a} \oc \nfa{q} \Reduces \nfa{q}'$.
%   \item $q \in F$ if and only if $\atm{\emp} \oc \nfa{q} \Reduces \octxe$.
%   \item $q \notin F$ if and only if $\atm{\emp} \oc \nfa{q} \longarrownot\reduces$.\alertnote{Careful -- depends on focusing!}
%   \end{itemize}
%   % \item
%   %   If $\atm{a} \oc \nfa{q} \Reduces \nfa{q}'$, then $q \nfareduces[a] q'$.
%   %   If $\atm{\emp} \oc \nfa{q} \Reduces \octxe$, then $q \in F$.
% \end{theorem}


% \paragraph*{Binary counter}

% \begin{equation*}
%   \begin{lgathered}
%     e \defd (e \fuse b_1 \pmir i) \with (z \pmir d) \\
%     b_0 \defd (b_1 \pmir i) \with (d \fuse b'_0 \pmir d) \\
%     b_1 \defd (i \fuse b_0 \pmir i) \with (b_0 \fuse s \pmir d) \\
%     b'_0 \defd (z \limp z) \with (s \limp b_1 \fuse s)
%   \end{lgathered}
% \end{equation*}

\begin{itemize}
\item Alternative choreography -- how are these related?
\begin{equation*}
  \begin{lgathered}
    p \defd (i \fuse p \pmir \atmL{i}) \with (d \fuse p' \pmir \atmL{d}) \\
    p' \defd (\atmR{z} \limp \atmR{z}) \with (\atmR{s} \limp p \fuse \atmR{s}) \\
    i \defd (\atmR{e} \limp \atmR{e} \fuse \atmR{b}_1) \with (\atmR{b}_0 \limp \atmR{b}_1) \with (\atmR{b}_1 \limp i \fuse \atmR{b}_0) \\
    d \defd (\atmR{e} \limp \atmR{z}) \with (\atmR{b}_0 \limp d \fuse b'_0) \with (\atmR{b}_1 \limp \atmR{b}_0 \fuse \atmR{s}) \\
    b'_0 \defd (\atmR{z} \limp \atmR{z}) \with (\atmR{s} \limp \atmR{b}_1 \fuse \atmR{s})
  \end{lgathered}
\end{equation*}

\begin{inferences}
  \infer{\adec{\octx \oc d}{n}}{
    \ainc{\octx}{n}}
\end{inferences}

If $\octx \oc \atmL{i} \reduces \octx'$, then $\atmR{\octx} \oc i \reduces \atmR{\octx}'$.
\end{itemize}


\section{}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
